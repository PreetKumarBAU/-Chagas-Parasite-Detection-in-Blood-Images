{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Latest various-classification-models-chagasdataset (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AMfBZ9_6IIxK",
        "3H2S9kRuIIxM",
        "LMhCYnMoIIxO",
        "V2O_XGa5IIxP",
        "oQzcEkOLIIxV",
        "AZKlEYeBIIxW",
        "_FMNSxQGIIxX",
        "yWo63CmXIIxb",
        "H-Cy0z1uIIxc",
        "heSzGESgIIxd",
        "OvlE7pYYIIxf",
        "vI1CXq_HIIxh",
        "OMS8g96OIIxj",
        "ESLUYDNWIIxk",
        "YfoRW_25IIxl",
        "SnzUs7TlIIxm",
        "7c4-e1J5IIxo",
        "yAWXUi8zIIxs",
        "Ko-Vb99a2WSJ",
        "SOtrr1k5IIxt",
        "j2jsn9rRIIxu",
        "2u1VZZkHIIxw",
        "fD6VLjE0IIxx",
        "-ZdDYlHRIIxy",
        "y5ovuKPBIIxz",
        "cfbKzUUaaaVD",
        "jJskoPRwaTWa",
        "LnGoCG7CIIx1",
        "ofAYlD4VaGm0",
        "XPXgqVl3a1A_",
        "PkKi1La9IIx4",
        "r5ki5K9FnoPb",
        "xwEqpH4JIIx6",
        "OM5BLIowmsqx",
        "j07qUHfHIIyA",
        "T4prtxJ0IIyC",
        "hVn_Vjy-IIyD",
        "i2s6yqo7AFpG",
        "pEZC7FpnIIyG",
        "nKwZiiVJIIyH",
        "JxF4aX9jIIyI"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PreetKumarBAU/-Chagas-Parasite-Detection-in-Blood-Images/blob/main/Latest_various_classification_models_chagasdataset_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IqO0KErYgZz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfq-4ICSYXOD",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:55:54.400684Z",
          "iopub.execute_input": "2021-08-31T20:55:54.401175Z",
          "iopub.status.idle": "2021-08-31T20:55:59.180502Z",
          "shell.execute_reply.started": "2021-08-31T20:55:54.401079Z",
          "shell.execute_reply": "2021-08-31T20:55:59.179612Z"
        },
        "trusted": true
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from keras.regularizers import l2\n",
        "from datetime import datetime \n",
        "\n",
        "\n",
        "# extract folder of chages disease images and non chagas disease images\n",
        "## We should have two folders ( Chagas and Non-Chagas )\n",
        "#!unzip \"/content/drive/MyDrive/ChagasTest.zip\"\n",
        "\n",
        "#!unzip \"/content/drive/MyDrive/ChagasValidation.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4otd9I_WsKN",
        "execution": {
          "iopub.status.busy": "2021-08-31T18:25:25.608168Z",
          "iopub.execute_input": "2021-08-31T18:25:25.608449Z",
          "iopub.status.idle": "2021-08-31T18:25:25.614126Z",
          "shell.execute_reply.started": "2021-08-31T18:25:25.608423Z",
          "shell.execute_reply": "2021-08-31T18:25:25.613350Z"
        },
        "trusted": true
      },
      "source": [
        "#!unzip \"/content/drive/MyDrive/Non-ChagasData_Selected.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqHVkM_yNWeu",
        "execution": {
          "iopub.status.busy": "2021-08-31T18:25:25.617791Z",
          "iopub.execute_input": "2021-08-31T18:25:25.618073Z",
          "iopub.status.idle": "2021-08-31T18:25:25.622656Z",
          "shell.execute_reply.started": "2021-08-31T18:25:25.618043Z",
          "shell.execute_reply": "2021-08-31T18:25:25.621694Z"
        },
        "trusted": true
      },
      "source": [
        "#!unzip \"/content/drive/MyDrive/ChagasTraining.zip\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzusLIkPWzLc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upUkOo6AtFGB",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:56:02.561635Z",
          "iopub.execute_input": "2021-08-31T20:56:02.562039Z",
          "iopub.status.idle": "2021-08-31T20:56:03.096830Z",
          "shell.execute_reply.started": "2021-08-31T20:56:02.562003Z",
          "shell.execute_reply": "2021-08-31T20:56:03.095939Z"
        },
        "trusted": true
      },
      "source": [
        "import os \n",
        "import seaborn as sns\n",
        "from keras.applications.vgg16 import VGG16\n",
        "training_dir =  \"../input/training/training\"\n",
        "test_dir =      \"../input/testdata/Test\"\n",
        "validation_dir= \"../input/validation/Validation\"\n",
        "\n",
        "training_dir_images = os.path.join(training_dir , \"images\")\n",
        "test_dir_images = os.path.join(test_dir , \"images\")\n",
        "validation_dir_images = os.path.join(validation_dir , \"images\")\n",
        "\n",
        "\n",
        "Training_Non_ChagasFiles = [ \"i_0450,i_0389,i_0392 ,i_0395 , i_0440 ,i_0429 , i_0406 , i_0398 , i_0369 , i_0374, i_0348, i_0339,  i_0337 , i_0389 ,i_0334, i_0324 ,i_0279, i_0280, i_0281 , i_0263 , i_0264 , i_0254 , i_0253 , i_0245 , i_0240 , i_0238 , i_0235 , i_0226 , i_0201, i_0184, i_0156, i_0150, i_0148 , i_0152 , i_0099 , i_0018 , i_0001\" ]\n",
        "\n",
        "\n",
        "Validation_Non_ChagasFiles = [\"i842 , i806 , i_0583, i_0559 , i_0528 , i_0529 , i_0583 , i_0559 , i_0528 , i_0529 , i_0481, i_0394 , i_0183 , i_0078 , i_0042 , i_0022\" ]\n",
        "\n",
        "\n",
        "Test_Non_ChagasFiles = [\"i_0579 , i_0579d , i_0050dd , i_0046d , i_0046dd , i_0047dd , i_0047d , i_0048d , i_0048dd ,i_0049d , i_0049dd , i_0050d , i_0050dd\" ]\n",
        "\n",
        "Non_chagas_files_names = []\n",
        "\n",
        "Non_chagas_files_names.extend(Training_Non_ChagasFiles)\n",
        "Non_chagas_files_names.extend(Validation_Non_ChagasFiles)\n",
        "Non_chagas_files_names.extend(Test_Non_ChagasFiles)\n",
        "\n",
        "NC = []\n",
        "for string in Non_chagas_files_names:\n",
        "  \n",
        "  NC.extend(string.split(\",\"))\n",
        "\n",
        "Non_Chagas_Files = []\n",
        "for values in NC:\n",
        "  Non_Chagas_Files.append(values.strip())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy9B1OqiyGEm",
        "execution": {
          "iopub.status.busy": "2021-08-31T18:25:26.151504Z",
          "iopub.execute_input": "2021-08-31T18:25:26.151780Z",
          "iopub.status.idle": "2021-08-31T18:25:26.161887Z",
          "shell.execute_reply.started": "2021-08-31T18:25:26.151730Z",
          "shell.execute_reply": "2021-08-31T18:25:26.160991Z"
        },
        "trusted": true,
        "outputId": "9991153c-b5ed-40ad-8b25-4289f2cbf0c7"
      },
      "source": [
        "training_dir_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'../input/training/training/images'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id_iHL0RyNf9",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:56:10.169187Z",
          "iopub.execute_input": "2021-08-31T20:56:10.169539Z",
          "iopub.status.idle": "2021-08-31T20:56:28.078690Z",
          "shell.execute_reply.started": "2021-08-31T20:56:10.169503Z",
          "shell.execute_reply": "2021-08-31T20:56:28.077715Z"
        },
        "trusted": true
      },
      "source": [
        "import cv2\n",
        "from skimage import io\n",
        "\n",
        "\n",
        "###Extract the Each Image and Label them as 0 or 1  ( label the chagas images as 1 and non chagas as 0)\n",
        "# we can have seperate list(or any array) for each of them[images and their corresponding labels ] ( one containing the arrays representing Each Image and another containing values/labels )\n",
        "\n",
        "labels = []\n",
        "images = []\n",
        "file_name= []\n",
        "for file in os.listdir(training_dir_images):\n",
        "  if file.endswith(\".png\"):\n",
        "      \n",
        "    file_name.append(file.split(\".\")[0])\n",
        "    if file.split(\".\")[0] in Non_Chagas_Files:\n",
        "      labels.append(0)\n",
        "      \n",
        "      images.append(cv2.resize(cv2.imread(os.path.join(training_dir_images , file)), (256, 256)))\n",
        "      \n",
        "    else:\n",
        "      labels.append(1)\n",
        "      images.append(cv2.resize(cv2.imread(os.path.join(training_dir_images , file)), (256, 256)))\n",
        "\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "for file in os.listdir(test_dir_images):\n",
        "  if file.endswith(\".png\"):\n",
        "\n",
        "\n",
        "    file_name.append(file.split(\".\")[0])\n",
        "    if file.split(\".\")[0] in Non_Chagas_Files:\n",
        "      labels.append(0)\n",
        "      images.append(cv2.resize(cv2.imread(os.path.join(test_dir_images , file)), (256, 256)))\n",
        "      \n",
        "    else:\n",
        "      labels.append(1)\n",
        "      images.append(cv2.resize(cv2.imread(os.path.join(test_dir_images , file)), (256, 256)))\n",
        "  \n",
        "  else:\n",
        "    pass\n",
        "\n",
        "\n",
        "for file in os.listdir(validation_dir_images):\n",
        "  if file.endswith(\".png\"):\n",
        "    \n",
        "\n",
        "    file_name.append(file.split(\".\")[0])\n",
        "    if file.split(\".\")[0] in Non_Chagas_Files:\n",
        "      labels.append(0)\n",
        "      images.append(cv2.resize(cv2.imread(os.path.join(validation_dir_images , file)), (256, 256)))\n",
        "    else:\n",
        "      labels.append(1)\n",
        "      images.append(cv2.resize(cv2.imread(os.path.join(validation_dir_images , file)), (256, 256)))\n",
        "  else:\n",
        "    pass\n",
        "# Where X is Array containing Arrays( representing Images)\n",
        "# Where Y is Array containing Labels(values as 0 and 1 ) ( representing labels for each Image)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoFI2Aea9M7j",
        "execution": {
          "iopub.status.busy": "2021-08-31T18:25:42.809889Z",
          "iopub.execute_input": "2021-08-31T18:25:42.810234Z",
          "iopub.status.idle": "2021-08-31T18:25:42.818202Z",
          "shell.execute_reply.started": "2021-08-31T18:25:42.810198Z",
          "shell.execute_reply": "2021-08-31T18:25:42.817256Z"
        },
        "trusted": true,
        "outputId": "508c67d7-250f-41a4-d7bc-a82f79310f6b"
      },
      "source": [
        "import numpy as np\n",
        "filename_to_label_dict = dict(zip(file_name , labels))\n",
        "from collections import Counter\n",
        "Counter(filename_to_label_dict.values() )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Counter({1: 918, 0: 60})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr5iUwxIUGuy",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:56:32.277581Z",
          "iopub.execute_input": "2021-08-31T20:56:32.277993Z",
          "iopub.status.idle": "2021-08-31T20:56:36.228867Z",
          "shell.execute_reply.started": "2021-08-31T20:56:32.277957Z",
          "shell.execute_reply": "2021-08-31T20:56:36.227857Z"
        },
        "trusted": true
      },
      "source": [
        "for file_path in os.listdir(\"../input/non-chagas/Non-ChagasData_Selected\"):\n",
        "  if file_path.endswith(\".png\"):\n",
        "    labels.append(0)\n",
        "      \n",
        "    images.append(cv2.resize(cv2.imread(os.path.join(\"../input/non-chagas/Non-ChagasData_Selected\" , file_path)), (256, 256)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BDcUpryZfjV",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:56:36.230336Z",
          "iopub.execute_input": "2021-08-31T20:56:36.230720Z",
          "iopub.status.idle": "2021-08-31T20:56:36.242170Z",
          "shell.execute_reply.started": "2021-08-31T20:56:36.230651Z",
          "shell.execute_reply": "2021-08-31T20:56:36.241064Z"
        },
        "trusted": true,
        "outputId": "941d611b-4b45-4658-9b56-18628daceba3"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(np.array(labels) ,return_counts = True )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(array([0, 1]), array([559, 940]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6kQpBEuFRkl",
        "execution": {
          "iopub.status.busy": "2021-08-31T18:25:46.278596Z",
          "iopub.execute_input": "2021-08-31T18:25:46.278961Z",
          "iopub.status.idle": "2021-08-31T18:25:46.287549Z",
          "shell.execute_reply.started": "2021-08-31T18:25:46.278924Z",
          "shell.execute_reply": "2021-08-31T18:25:46.286744Z"
        },
        "trusted": true
      },
      "source": [
        "#imagess = []\n",
        "#for imagesss in images:\n",
        "#  imagess.append(cv2.resize(imagesss , (256 , 256 )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uLnafPI5TRB",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:56:44.406551Z",
          "iopub.execute_input": "2021-08-31T20:56:44.406967Z",
          "iopub.status.idle": "2021-08-31T20:56:44.716858Z",
          "shell.execute_reply.started": "2021-08-31T20:56:44.406934Z",
          "shell.execute_reply": "2021-08-31T20:56:44.715846Z"
        },
        "trusted": true,
        "outputId": "e41faa62-08bb-4b14-eb10-af660ebcd0d5"
      },
      "source": [
        "\n",
        "# Split the Images and labels into Train , Test and Validation Data\n",
        "print(type(images))\n",
        "images = np.array(images , dtype = \"float32\")\n",
        "labels = np.array(labels, dtype = 'int32')\n",
        "print(type(images))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'list'>\n<class 'numpy.ndarray'>\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UvBwwC-89TG",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:56:50.944587Z",
          "iopub.execute_input": "2021-08-31T20:56:50.944952Z",
          "iopub.status.idle": "2021-08-31T20:56:50.951340Z",
          "shell.execute_reply.started": "2021-08-31T20:56:50.944917Z",
          "shell.execute_reply": "2021-08-31T20:56:50.950152Z"
        },
        "trusted": true,
        "outputId": "ef48c311-7773-4cca-d160-e9120c9d93f7"
      },
      "source": [
        "print(images.shape[0])\n",
        "print(labels.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1499\n1499\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIRLlkKV9GpG",
        "execution": {
          "iopub.status.busy": "2021-08-31T18:25:46.603308Z",
          "iopub.execute_input": "2021-08-31T18:25:46.603578Z",
          "iopub.status.idle": "2021-08-31T18:25:46.607866Z",
          "shell.execute_reply.started": "2021-08-31T18:25:46.603552Z",
          "shell.execute_reply": "2021-08-31T18:25:46.606808Z"
        },
        "trusted": true
      },
      "source": [
        "\n",
        "#n = np.arange(images.shape[0])\n",
        "#np.random.shuffle(n)\n",
        "#images = images[n]\n",
        "#labels = labels[n]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5b2hNue_n8l",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:57:07.154350Z",
          "iopub.execute_input": "2021-08-31T20:57:07.154697Z",
          "iopub.status.idle": "2021-08-31T20:57:07.709455Z",
          "shell.execute_reply.started": "2021-08-31T20:57:07.154664Z",
          "shell.execute_reply": "2021-08-31T20:57:07.708522Z"
        },
        "trusted": true
      },
      "source": [
        "import random\n",
        "\n",
        "# Shuffle\n",
        "from sklearn.utils import shuffle\n",
        "#images, labels = shuffle(images, labels, random_state=10)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size = 0.2 , random_state=10)\n",
        "test_images, val_images, test_labels, val_labels = train_test_split(test_images, test_labels, test_size = 0.5 , random_state=10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:57:23.418586Z",
          "iopub.execute_input": "2021-08-31T20:57:23.419013Z",
          "iopub.status.idle": "2021-08-31T20:57:23.429377Z",
          "shell.execute_reply.started": "2021-08-31T20:57:23.418977Z",
          "shell.execute_reply": "2021-08-31T20:57:23.428227Z"
        },
        "trusted": true,
        "id": "7ZABYMcVIIxF",
        "outputId": "118e29fa-6e81-4704-ce1c-14c2bc939b66"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1], dtype=int32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNEEJfV3BJeF",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:58:06.855149Z",
          "iopub.execute_input": "2021-08-31T20:58:06.855567Z",
          "iopub.status.idle": "2021-08-31T20:58:06.867018Z",
          "shell.execute_reply.started": "2021-08-31T20:58:06.855531Z",
          "shell.execute_reply": "2021-08-31T20:58:06.863138Z"
        },
        "trusted": true,
        "outputId": "f75bf0b8-481b-498c-bafb-e87a08f3403d"
      },
      "source": [
        "n_train = train_labels.shape[0]\n",
        "n_val = val_labels.shape[0]\n",
        "n_test = test_labels.shape[0]\n",
        "\n",
        "print(\"Number of training examples: {}\".format(n_train))\n",
        "print(\"Number of validation examples: {}\".format(n_val))\n",
        "print(\"Number of testing examples: {}\".format(n_test))\n",
        "\n",
        "print(\"Training images are of shape: {}\".format(train_images.shape))\n",
        "print(\"Training labels are of shape: {}\".format(train_labels.shape))\n",
        "print(\"Validation images are of shape: {}\".format(val_images.shape))\n",
        "print(\"Validation labels are of shape: {}\".format(val_labels.shape))\n",
        "print(\"Test images are of shape: {}\".format(test_images.shape))\n",
        "print(\"Test labels are of shape: {}\".format(test_labels.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of training examples: 1199\nNumber of validation examples: 150\nNumber of testing examples: 150\nTraining images are of shape: (1199, 256, 256, 3)\nTraining labels are of shape: (1199,)\nValidation images are of shape: (150, 256, 256, 3)\nValidation labels are of shape: (150,)\nTest images are of shape: (150, 256, 256, 3)\nTest labels are of shape: (150,)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DsBcyImBQE3",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:58:14.609493Z",
          "iopub.execute_input": "2021-08-31T20:58:14.609849Z",
          "iopub.status.idle": "2021-08-31T20:58:14.966517Z",
          "shell.execute_reply.started": "2021-08-31T20:58:14.609814Z",
          "shell.execute_reply": "2021-08-31T20:58:14.965602Z"
        },
        "trusted": true
      },
      "source": [
        "train_images = train_images / 255.0 \n",
        "val_images = val_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX4grPtaDNzG",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:58:18.073492Z",
          "iopub.execute_input": "2021-08-31T20:58:18.073861Z",
          "iopub.status.idle": "2021-08-31T20:58:18.084356Z",
          "shell.execute_reply.started": "2021-08-31T20:58:18.073821Z",
          "shell.execute_reply": "2021-08-31T20:58:18.083315Z"
        },
        "trusted": true
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply ,  Dense, Conv2D, Activation, Flatten\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "#import keras.backend as K\n",
        "from keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add,average,concatenate , Conv2DTranspose\n",
        "from keras.layers.core import Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "#%tensorflow_version 1.x\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.callbacks import CSVLogger\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "#import keras.backend.tensorflow_backend as K\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:58:25.624256Z",
          "iopub.execute_input": "2021-08-31T20:58:25.624602Z",
          "iopub.status.idle": "2021-08-31T20:58:25.929363Z",
          "shell.execute_reply.started": "2021-08-31T20:58:25.624570Z",
          "shell.execute_reply": "2021-08-31T20:58:25.928526Z"
        },
        "trusted": true,
        "id": "xpg3ex-MIIxJ"
      },
      "source": [
        "\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers import Lambda, SeparableConv2D, BatchNormalization, Dropout, MaxPooling2D, Input, Dense, Conv2D, Activation, Flatten \n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMfBZ9_6IIxK"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:58:33.297329Z",
          "iopub.execute_input": "2021-08-31T20:58:33.297794Z",
          "iopub.status.idle": "2021-08-31T20:58:33.305348Z",
          "shell.execute_reply.started": "2021-08-31T20:58:33.297721Z",
          "shell.execute_reply": "2021-08-31T20:58:33.304159Z"
        },
        "trusted": true,
        "id": "NKHmFHuXIIxM"
      },
      "source": [
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H2S9kRuIIxM"
      },
      "source": [
        "# One Hot Encodeing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:58:48.722587Z",
          "iopub.execute_input": "2021-08-31T20:58:48.722961Z",
          "iopub.status.idle": "2021-08-31T20:58:48.728317Z",
          "shell.execute_reply.started": "2021-08-31T20:58:48.722926Z",
          "shell.execute_reply": "2021-08-31T20:58:48.727106Z"
        },
        "trusted": true,
        "id": "GghJbn7xIIxN"
      },
      "source": [
        "#One hot encode y values for neural network. \n",
        "from keras.utils import to_categorical\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "val_labels_one_hot = to_categorical(val_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMhCYnMoIIxO"
      },
      "source": [
        "# **Data_Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:58:54.805603Z",
          "iopub.execute_input": "2021-08-31T20:58:54.806002Z",
          "iopub.status.idle": "2021-08-31T20:58:56.654824Z",
          "shell.execute_reply.started": "2021-08-31T20:58:54.805967Z",
          "shell.execute_reply": "2021-08-31T20:58:56.653924Z"
        },
        "trusted": true,
        "id": "zsmDDcXZIIxO"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2O_XGa5IIxP"
      },
      "source": [
        "# Fine Tunning on Inception Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:25:49.784786Z",
          "iopub.execute_input": "2021-08-31T18:25:49.785049Z",
          "iopub.status.idle": "2021-08-31T18:27:54.442568Z",
          "shell.execute_reply.started": "2021-08-31T18:25:49.785022Z",
          "shell.execute_reply": "2021-08-31T18:27:54.441708Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "_j1vpCxDIIxQ",
        "outputId": "473fe93d-cc0e-4f61-b49f-e02754267ab0"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "def Fine_Tunned_Inception_Model(pretrained_weights = None):\n",
        "    IMG_SIZE = 256\n",
        "\n",
        "    # create the base pre-trained model\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False , input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # let's add a fully-connected layer\n",
        "\n",
        "    x = Dense(units = 512 , activation = 'relu'  )(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(units = 128 , activation = 'relu'  )(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x=  Dense(units = 64 , activation = 'relu' )(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    # Output layer\n",
        "    # For dense = 1  or for binary classification, we use activation = \"linear\"\n",
        "    output  = Dense(units = 1 ,kernel_regularizer = tf.keras.regularizers.l2(0.01), activation = 'linear')(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # first: train only the top layers (which were randomly initialized)\n",
        "    # i.e. freeze all convolutional InceptionV3 layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "                \n",
        "    if (pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    # For SVM as last layer we use Different Loss Function \"squared_hinge\" for multi-class and \"hinge\" loss for binary class \n",
        "    model.compile(optimizer=Adam(lr=7.00E-05), loss = 'hinge', metrics = ['accuracy',precision,recall])\n",
        "    return model\n",
        "\n",
        "            \n",
        "Inception_Fine_tunned_Model = Fine_Tunned_Inception_Model()\n",
        "Inception_Fine_tunned_Model.summary()\n",
        "                \n",
        "model_checkpoint1 = keras.callbacks.ModelCheckpoint('Inception_Fune_Tuned_Weights.hdf5', monitor='val_loss',verbose=1, mode='min',save_best_only=True)\n",
        "csv_logger = CSVLogger('training_model_metrics_values1.log', append=True, separator=';')\n",
        "\n",
        "# Implement callbacks \n",
        "#checkpoint = ModelCheckpoint(filepath='best_model.hdf5', save_best_only=True, save_weights_only=False)\n",
        "\n",
        "# Train\n",
        "\n",
        "history = Inception_Fine_tunned_Model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 10, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger   ])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87916544/87910968 [==============================] - 0s 0us/step\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\naverage_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nmixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n                                                                 activation_7[0][0]               \n                                                                 activation_10[0][0]              \n                                                                 activation_11[0][0]              \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n__________________________________________________________________________________________________\nmixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n                                                                 activation_14[0][0]              \n                                                                 activation_17[0][0]              \n                                                                 activation_18[0][0]              \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nmixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n                                                                 activation_21[0][0]              \n                                                                 activation_24[0][0]              \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n__________________________________________________________________________________________________\nmixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n                                                                 activation_29[0][0]              \n                                                                 max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n__________________________________________________________________________________________________\nmixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n                                                                 activation_33[0][0]              \n                                                                 activation_38[0][0]              \n                                                                 activation_39[0][0]              \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n__________________________________________________________________________________________________\nconv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n__________________________________________________________________________________________________\nconv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n__________________________________________________________________________________________________\nmixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n                                                                 activation_43[0][0]              \n                                                                 activation_48[0][0]              \n                                                                 activation_49[0][0]              \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n__________________________________________________________________________________________________\nactivation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n__________________________________________________________________________________________________\nconv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n__________________________________________________________________________________________________\nconv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n__________________________________________________________________________________________________\nactivation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n__________________________________________________________________________________________________\nactivation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n__________________________________________________________________________________________________\nmixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n                                                                 activation_53[0][0]              \n                                                                 activation_58[0][0]              \n                                                                 activation_59[0][0]              \n__________________________________________________________________________________________________\nconv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n__________________________________________________________________________________________________\nactivation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n__________________________________________________________________________________________________\nconv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n__________________________________________________________________________________________________\nactivation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n__________________________________________________________________________________________________\nconv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n__________________________________________________________________________________________________\nconv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n__________________________________________________________________________________________________\nactivation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n__________________________________________________________________________________________________\nactivation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n__________________________________________________________________________________________________\nconv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n__________________________________________________________________________________________________\nconv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n__________________________________________________________________________________________________\nactivation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n__________________________________________________________________________________________________\nactivation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n__________________________________________________________________________________________________\nconv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n__________________________________________________________________________________________________\nconv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n__________________________________________________________________________________________________\nconv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n__________________________________________________________________________________________________\nactivation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n__________________________________________________________________________________________________\nactivation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n__________________________________________________________________________________________________\nactivation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n__________________________________________________________________________________________________\nactivation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n__________________________________________________________________________________________________\nmixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n                                                                 activation_63[0][0]              \n                                                                 activation_68[0][0]              \n                                                                 activation_69[0][0]              \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nactivation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nactivation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n__________________________________________________________________________________________________\nactivation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n__________________________________________________________________________________________________\nactivation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n__________________________________________________________________________________________________\nmixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n                                                                 activation_75[0][0]              \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nmixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n                                                                 activation_79[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n                                                                 activation_83[0][0]              \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nmixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n                                                                 mixed9_0[0][0]                   \n                                                                 concatenate[0][0]                \n                                                                 activation_84[0][0]              \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nmixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n                                                                 activation_88[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n                                                                 activation_92[0][0]              \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nmixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n                                                                 mixed9_1[0][0]                   \n                                                                 concatenate_1[0][0]              \n                                                                 activation_93[0][0]              \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 512)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 128)          65664       dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n==================================================================================================\nTotal params: 22,925,857\nTrainable params: 1,123,073\nNon-trainable params: 21,802,784\n__________________________________________________________________________________________________\nEpoch 1/10\n600/600 [==============================] - 23s 21ms/step - loss: 0.7181 - accuracy: 0.6449 - precision: 0.4529 - recall: 0.4120 - val_loss: 0.1891 - val_accuracy: 0.9733 - val_precision: 0.8667 - val_recall: 0.8800\n\nEpoch 00001: val_loss improved from inf to 0.18910, saving model to Inception_Fune_Tuned_Weights.hdf5\nEpoch 2/10\n600/600 [==============================] - 11s 19ms/step - loss: 0.2883 - accuracy: 0.8814 - precision: 0.7996 - recall: 0.7732 - val_loss: 0.0910 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00002: val_loss improved from 0.18910 to 0.09101, saving model to Inception_Fune_Tuned_Weights.hdf5\nEpoch 3/10\n600/600 [==============================] - 11s 18ms/step - loss: 0.2602 - accuracy: 0.9069 - precision: 0.8058 - recall: 0.8017 - val_loss: 0.1353 - val_accuracy: 0.9733 - val_precision: 0.8667 - val_recall: 0.8800\n\nEpoch 00003: val_loss did not improve from 0.09101\nEpoch 4/10\n600/600 [==============================] - 11s 18ms/step - loss: 0.2382 - accuracy: 0.9061 - precision: 0.7909 - recall: 0.8046 - val_loss: 0.1006 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00004: val_loss did not improve from 0.09101\nEpoch 5/10\n600/600 [==============================] - 11s 19ms/step - loss: 0.2097 - accuracy: 0.9269 - precision: 0.8033 - recall: 0.8135 - val_loss: 0.0919 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00005: val_loss did not improve from 0.09101\nEpoch 6/10\n600/600 [==============================] - 11s 18ms/step - loss: 0.1921 - accuracy: 0.9308 - precision: 0.8138 - recall: 0.8372 - val_loss: 0.0768 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00006: val_loss improved from 0.09101 to 0.07684, saving model to Inception_Fune_Tuned_Weights.hdf5\nEpoch 7/10\n600/600 [==============================] - 11s 18ms/step - loss: 0.1537 - accuracy: 0.9407 - precision: 0.8146 - recall: 0.8222 - val_loss: 0.0939 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00007: val_loss did not improve from 0.07684\nEpoch 8/10\n600/600 [==============================] - 11s 18ms/step - loss: 0.1511 - accuracy: 0.9470 - precision: 0.8080 - recall: 0.8201 - val_loss: 0.0807 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00008: val_loss did not improve from 0.07684\nEpoch 9/10\n600/600 [==============================] - 10s 18ms/step - loss: 0.1572 - accuracy: 0.9415 - precision: 0.8458 - recall: 0.8585 - val_loss: 0.0879 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00009: val_loss did not improve from 0.07684\nEpoch 10/10\n600/600 [==============================] - 11s 18ms/step - loss: 0.1519 - accuracy: 0.9476 - precision: 0.8268 - recall: 0.8467 - val_loss: 0.0777 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00010: val_loss did not improve from 0.07684\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:27:54.446128Z",
          "iopub.execute_input": "2021-08-31T18:27:54.446395Z",
          "iopub.status.idle": "2021-08-31T18:27:54.462371Z",
          "shell.execute_reply.started": "2021-08-31T18:27:54.446366Z",
          "shell.execute_reply": "2021-08-31T18:27:54.461586Z"
        },
        "trusted": true,
        "id": "vC63q6WTIIxS"
      },
      "source": [
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. \n",
        "#We will freeze the bottom N layers and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers we should freeze:\n",
        "#for i, layer in enumerate(base_model.layers):\n",
        "#   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in Inception_Fine_tunned_Model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in Inception_Fine_tunned_Model.layers[249:]:\n",
        "   layer.trainable = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:27:54.463573Z",
          "iopub.execute_input": "2021-08-31T18:27:54.463988Z",
          "iopub.status.idle": "2021-08-31T18:27:54.606402Z",
          "shell.execute_reply.started": "2021-08-31T18:27:54.463948Z",
          "shell.execute_reply": "2021-08-31T18:27:54.605644Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "PgWPj0hIIIxS",
        "outputId": "e6c7e72b-4190-45a4-c743-66f41f8c2e21"
      },
      "source": [
        "Inception_Fine_tunned_Model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\naverage_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nmixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n                                                                 activation_7[0][0]               \n                                                                 activation_10[0][0]              \n                                                                 activation_11[0][0]              \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n__________________________________________________________________________________________________\nmixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n                                                                 activation_14[0][0]              \n                                                                 activation_17[0][0]              \n                                                                 activation_18[0][0]              \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nmixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n                                                                 activation_21[0][0]              \n                                                                 activation_24[0][0]              \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n__________________________________________________________________________________________________\nmixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n                                                                 activation_29[0][0]              \n                                                                 max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n__________________________________________________________________________________________________\nmixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n                                                                 activation_33[0][0]              \n                                                                 activation_38[0][0]              \n                                                                 activation_39[0][0]              \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n__________________________________________________________________________________________________\nconv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n__________________________________________________________________________________________________\nconv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n__________________________________________________________________________________________________\nmixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n                                                                 activation_43[0][0]              \n                                                                 activation_48[0][0]              \n                                                                 activation_49[0][0]              \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n__________________________________________________________________________________________________\nactivation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n__________________________________________________________________________________________________\nconv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n__________________________________________________________________________________________________\nconv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n__________________________________________________________________________________________________\nactivation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n__________________________________________________________________________________________________\nactivation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n__________________________________________________________________________________________________\nmixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n                                                                 activation_53[0][0]              \n                                                                 activation_58[0][0]              \n                                                                 activation_59[0][0]              \n__________________________________________________________________________________________________\nconv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n__________________________________________________________________________________________________\nactivation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n__________________________________________________________________________________________________\nconv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n__________________________________________________________________________________________________\nactivation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n__________________________________________________________________________________________________\nconv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n__________________________________________________________________________________________________\nconv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n__________________________________________________________________________________________________\nactivation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n__________________________________________________________________________________________________\nactivation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n__________________________________________________________________________________________________\nconv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n__________________________________________________________________________________________________\nconv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n__________________________________________________________________________________________________\nactivation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n__________________________________________________________________________________________________\nactivation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n__________________________________________________________________________________________________\nconv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n__________________________________________________________________________________________________\nconv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n__________________________________________________________________________________________________\nconv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n__________________________________________________________________________________________________\nactivation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n__________________________________________________________________________________________________\nactivation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n__________________________________________________________________________________________________\nactivation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n__________________________________________________________________________________________________\nactivation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n__________________________________________________________________________________________________\nmixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n                                                                 activation_63[0][0]              \n                                                                 activation_68[0][0]              \n                                                                 activation_69[0][0]              \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nactivation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nactivation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n__________________________________________________________________________________________________\nactivation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n__________________________________________________________________________________________________\nactivation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n__________________________________________________________________________________________________\nmixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n                                                                 activation_75[0][0]              \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nmixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n                                                                 activation_79[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n                                                                 activation_83[0][0]              \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nmixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n                                                                 mixed9_0[0][0]                   \n                                                                 concatenate[0][0]                \n                                                                 activation_84[0][0]              \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nmixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n                                                                 activation_88[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n                                                                 activation_92[0][0]              \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nmixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n                                                                 mixed9_1[0][0]                   \n                                                                 concatenate_1[0][0]              \n                                                                 activation_93[0][0]              \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 512)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 128)          65664       dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n==================================================================================================\nTotal params: 22,925,857\nTrainable params: 12,237,953\nNon-trainable params: 10,687,904\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:27:54.608983Z",
          "iopub.execute_input": "2021-08-31T18:27:54.609214Z",
          "iopub.status.idle": "2021-08-31T18:31:30.606634Z",
          "shell.execute_reply.started": "2021-08-31T18:27:54.609191Z",
          "shell.execute_reply": "2021-08-31T18:31:30.605816Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "ZKmVJl5VIIxU",
        "outputId": "32f064d1-14e0-43eb-de18-1097bce6a325"
      },
      "source": [
        "\n",
        "history = Inception_Fine_tunned_Model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 20, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger   ])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1542 - accuracy: 0.9450 - precision: 0.8117 - recall: 0.8283 - val_loss: 0.0700 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00001: val_loss improved from 0.07684 to 0.06995, saving model to Inception_Fune_Tuned_Weights.hdf5\nEpoch 2/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1406 - accuracy: 0.9475 - precision: 0.8200 - recall: 0.8392 - val_loss: 0.0843 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00002: val_loss did not improve from 0.06995\nEpoch 3/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1353 - accuracy: 0.9533 - precision: 0.8142 - recall: 0.8333 - val_loss: 0.0908 - val_accuracy: 0.9733 - val_precision: 0.8667 - val_recall: 0.8800\n\nEpoch 00003: val_loss did not improve from 0.06995\nEpoch 4/20\n600/600 [==============================] - 11s 19ms/step - loss: 0.1368 - accuracy: 0.9550 - precision: 0.8292 - recall: 0.8400 - val_loss: 0.0736 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00004: val_loss did not improve from 0.06995\nEpoch 5/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1384 - accuracy: 0.9491 - precision: 0.8392 - recall: 0.8592 - val_loss: 0.0785 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00005: val_loss did not improve from 0.06995\nEpoch 6/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1330 - accuracy: 0.9516 - precision: 0.8325 - recall: 0.8550 - val_loss: 0.0747 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n\nEpoch 00006: val_loss did not improve from 0.06995\nEpoch 7/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1380 - accuracy: 0.9458 - precision: 0.8267 - recall: 0.8417 - val_loss: 0.0774 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00007: val_loss did not improve from 0.06995\nEpoch 8/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1326 - accuracy: 0.9483 - precision: 0.8458 - recall: 0.8675 - val_loss: 0.0773 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00008: val_loss did not improve from 0.06995\nEpoch 9/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1325 - accuracy: 0.9533 - precision: 0.8283 - recall: 0.8492 - val_loss: 0.0724 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00009: val_loss did not improve from 0.06995\nEpoch 10/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1277 - accuracy: 0.9525 - precision: 0.8350 - recall: 0.8583 - val_loss: 0.0655 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00010: val_loss improved from 0.06995 to 0.06547, saving model to Inception_Fune_Tuned_Weights.hdf5\nEpoch 11/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1313 - accuracy: 0.9550 - precision: 0.8333 - recall: 0.8525 - val_loss: 0.0763 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00011: val_loss did not improve from 0.06547\nEpoch 12/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1208 - accuracy: 0.9483 - precision: 0.8508 - recall: 0.8725 - val_loss: 0.0792 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00012: val_loss did not improve from 0.06547\nEpoch 13/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1219 - accuracy: 0.9533 - precision: 0.8258 - recall: 0.8417 - val_loss: 0.0854 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00013: val_loss did not improve from 0.06547\nEpoch 14/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1142 - accuracy: 0.9566 - precision: 0.8492 - recall: 0.8650 - val_loss: 0.0679 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00014: val_loss did not improve from 0.06547\nEpoch 15/20\n600/600 [==============================] - 10s 17ms/step - loss: 0.1107 - accuracy: 0.9525 - precision: 0.8242 - recall: 0.8450 - val_loss: 0.0751 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00015: val_loss did not improve from 0.06547\nEpoch 16/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1165 - accuracy: 0.9550 - precision: 0.8525 - recall: 0.8700 - val_loss: 0.0825 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00016: val_loss did not improve from 0.06547\nEpoch 17/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1179 - accuracy: 0.9566 - precision: 0.8175 - recall: 0.8358 - val_loss: 0.0682 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00017: val_loss did not improve from 0.06547\nEpoch 18/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1102 - accuracy: 0.9608 - precision: 0.8367 - recall: 0.8600 - val_loss: 0.0759 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00018: val_loss did not improve from 0.06547\nEpoch 19/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1083 - accuracy: 0.9575 - precision: 0.8550 - recall: 0.8733 - val_loss: 0.0870 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00019: val_loss did not improve from 0.06547\nEpoch 20/20\n600/600 [==============================] - 11s 18ms/step - loss: 0.1063 - accuracy: 0.9591 - precision: 0.8392 - recall: 0.8600 - val_loss: 0.0897 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00020: val_loss did not improve from 0.06547\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQzcEkOLIIxV"
      },
      "source": [
        "### Accuracy on Test Images (Fine Tunned Inception Based Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:32:48.901481Z",
          "iopub.execute_input": "2021-08-31T18:32:48.901837Z",
          "iopub.status.idle": "2021-08-31T18:32:53.516718Z",
          "shell.execute_reply.started": "2021-08-31T18:32:48.901803Z",
          "shell.execute_reply": "2021-08-31T18:32:53.515913Z"
        },
        "trusted": true,
        "id": "VTw4pc7CIIxV",
        "outputId": "f1d89e2c-8ffb-4682-df36-be9e2b3205a1"
      },
      "source": [
        "# Before Training the Last Layers of Inception Model Test accuracy was 94.67% and then\n",
        "#after it increased to 96%\n",
        "\n",
        "print(\"Train_Accuracy\" )\n",
        "results = Inception_Fine_tunned_Model.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = Inception_Fine_tunned_Model.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "results = Inception_Fine_tunned_Model.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 3s 70ms/step - loss: 0.0855 - accuracy: 0.9658 - precision: 0.9488 - recall: 1.0000\nVal_Accuracy\n5/5 [==============================] - 1s 141ms/step - loss: 0.0897 - accuracy: 0.9667 - precision: 0.9727 - recall: 0.9832\nTest_Accuracy\n5/5 [==============================] - 0s 56ms/step - loss: 0.0604 - accuracy: 0.9800 - precision: 0.9628 - recall: 1.0000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:31:33.300729Z",
          "iopub.status.idle": "2021-08-31T18:31:33.301133Z"
        },
        "trusted": true,
        "id": "tnf0q66SIIxW"
      },
      "source": [
        "\n",
        "\n",
        "# Test Accuracy was 96%\n",
        "# Validation Accuracy 96%\n",
        "# Training Accuracy was above 96% \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZKlEYeBIIxW"
      },
      "source": [
        "#### Predication Inception Model (Fine Tunned)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:33:50.856427Z",
          "iopub.execute_input": "2021-08-31T18:33:50.856785Z",
          "iopub.status.idle": "2021-08-31T18:33:52.447555Z",
          "shell.execute_reply.started": "2021-08-31T18:33:50.856746Z",
          "shell.execute_reply": "2021-08-31T18:33:52.446719Z"
        },
        "trusted": true,
        "id": "UXftV9MvIIxX",
        "outputId": "1b31edee-222d-440a-db8e-99395d87907a"
      },
      "source": [
        "Inception_predictions = Inception_Fine_tunned_Model.predict(test_images)\n",
        "#predictions = np.argmax(predictions,axis=1)\n",
        "pred = [1 if x > 0 else 0 for x in list(Inception_predictions[: , 0])]\n",
        "Inception_predictions = np.array(pred)\n",
        "Inception_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FMNSxQGIIxX"
      },
      "source": [
        "# Transfer Learning ( ResNet50 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:35:54.203973Z",
          "iopub.execute_input": "2021-08-31T18:35:54.204336Z",
          "iopub.status.idle": "2021-08-31T18:38:51.099434Z",
          "shell.execute_reply.started": "2021-08-31T18:35:54.204305Z",
          "shell.execute_reply": "2021-08-31T18:38:51.098570Z"
        },
        "trusted": true,
        "id": "Bbxd77wqIIxY",
        "outputId": "4a792766-dfbc-4563-bc8c-73f7c8dc99b0"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.layers import Input, Lambda, Dense, Flatten , GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def ResNet_Model(pretrained_weights = None):\n",
        "    IMAGE_SIZE = [256, 256]\n",
        "    ResNet_Model = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "    # don't train existing weights\n",
        "    for layer in ResNet_Model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "    x = ResNet_Model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "\n",
        "\n",
        "    x = Dense(units = 128 , activation = 'relu'  )(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x=  Dense(units = 64 , activation = 'relu' )(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Output layer\n",
        "    # For dense = 1  or for binary classification, we use activation = \"linear\"\n",
        "    #output  = Dense(units = 1 ,kernel_regularizer = tf.keras.regularizers.l2(0.01), activation = 'linear')(x)\n",
        "    output = = Dense(1, activation = 'sigmoid')(x)\n",
        "    \n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=ResNet_Model.input, outputs=output)\n",
        "                \n",
        "    if (pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    # For SVM as last layer we use Different Loss Function \"squared_hinge\" for multi-class and \"hinge\" loss for binary class \n",
        "    #model.compile(optimizer=Adam(lr=7.00E-05), loss = 'hinge', metrics = ['accuracy',precision,recall])\n",
        "    model.compile(optimizer=Adam(lr=7.00E-05), loss = 'binary_crossentropy', metrics = ['accuracy',precision,recall])\n",
        "\n",
        "    return model\n",
        "\n",
        "            \n",
        "ResNet50_Transfer_learning_Model = ResNet_Model()\n",
        "ResNet50_Transfer_learning_Model.summary()\n",
        "                \n",
        "model_checkpoint1 = keras.callbacks.ModelCheckpoint('ResNet50_Transfer_learning_Weights.hdf5', monitor='val_loss',verbose=1, mode='min',save_best_only=True)\n",
        "csv_logger = CSVLogger('training_model_metrics_values1.log', append=True, separator=';')\n",
        "\n",
        "# Implement callbacks \n",
        "#checkpoint = ModelCheckpoint(filepath='best_model.hdf5', save_best_only=True, save_weights_only=False)\n",
        "\n",
        "# Train\n",
        "\n",
        "history = ResNet50_Transfer_learning_Model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 20, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger   ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 0s 0us/step\nModel: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n__________________________________________________________________________________________________\nconv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n                                                                 conv2_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n                                                                 conv2_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n                                                                 conv3_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n                                                                 conv3_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n                                                                 conv4_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n                                                                 conv5_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 128)          262272      global_average_pooling2d_1[0][0] \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 1)            65          dropout_4[0][0]                  \n==================================================================================================\nTotal params: 23,858,305\nTrainable params: 270,593\nNon-trainable params: 23,587,712\n__________________________________________________________________________________________________\nEpoch 1/20\n600/600 [==============================] - 13s 16ms/step - loss: 0.9140 - accuracy: 0.5390 - precision: 0.5587 - recall: 0.5964 - val_loss: 0.7444 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00001: val_loss improved from inf to 0.74438, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 2/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.8294 - accuracy: 0.5930 - precision: 0.6092 - recall: 0.7238 - val_loss: 0.7572 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00002: val_loss did not improve from 0.74438\nEpoch 3/20\n600/600 [==============================] - 9s 14ms/step - loss: 0.8318 - accuracy: 0.6115 - precision: 0.6236 - recall: 0.8165 - val_loss: 0.7643 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00003: val_loss did not improve from 0.74438\nEpoch 4/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.8069 - accuracy: 0.6060 - precision: 0.6273 - recall: 0.8058 - val_loss: 0.7643 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00004: val_loss did not improve from 0.74438\nEpoch 5/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7665 - accuracy: 0.6376 - precision: 0.6484 - recall: 0.8287 - val_loss: 0.7971 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00005: val_loss did not improve from 0.74438\nEpoch 6/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7927 - accuracy: 0.6143 - precision: 0.6220 - recall: 0.7860 - val_loss: 0.7145 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00006: val_loss improved from 0.74438 to 0.71450, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 7/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.8009 - accuracy: 0.6168 - precision: 0.6204 - recall: 0.8284 - val_loss: 0.7235 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00007: val_loss did not improve from 0.71450\nEpoch 8/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7881 - accuracy: 0.6255 - precision: 0.6353 - recall: 0.8382 - val_loss: 0.6918 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00008: val_loss improved from 0.71450 to 0.69184, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 9/20\n600/600 [==============================] - 8s 13ms/step - loss: 0.7767 - accuracy: 0.6271 - precision: 0.6345 - recall: 0.8446 - val_loss: 0.7063 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00009: val_loss did not improve from 0.69184\nEpoch 10/20\n600/600 [==============================] - 9s 14ms/step - loss: 0.7885 - accuracy: 0.6204 - precision: 0.6259 - recall: 0.8566 - val_loss: 0.6772 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00010: val_loss improved from 0.69184 to 0.67724, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 11/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7757 - accuracy: 0.6275 - precision: 0.6311 - recall: 0.8477 - val_loss: 0.6984 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00011: val_loss did not improve from 0.67724\nEpoch 12/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7718 - accuracy: 0.6289 - precision: 0.6198 - recall: 0.8097 - val_loss: 0.6912 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00012: val_loss did not improve from 0.67724\nEpoch 13/20\n600/600 [==============================] - 8s 13ms/step - loss: 0.7469 - accuracy: 0.6410 - precision: 0.6388 - recall: 0.8608 - val_loss: 0.6964 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00013: val_loss did not improve from 0.67724\nEpoch 14/20\n600/600 [==============================] - 9s 14ms/step - loss: 0.7413 - accuracy: 0.6569 - precision: 0.6554 - recall: 0.8826 - val_loss: 0.6689 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00014: val_loss improved from 0.67724 to 0.66889, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 15/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7362 - accuracy: 0.6532 - precision: 0.6460 - recall: 0.8621 - val_loss: 0.6717 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00015: val_loss did not improve from 0.66889\nEpoch 16/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.6966 - accuracy: 0.6752 - precision: 0.6584 - recall: 0.8518 - val_loss: 0.6441 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00016: val_loss improved from 0.66889 to 0.64406, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 17/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7084 - accuracy: 0.6525 - precision: 0.6590 - recall: 0.8619 - val_loss: 0.6397 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00017: val_loss improved from 0.64406 to 0.63967, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 18/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.7201 - accuracy: 0.7014 - precision: 0.6761 - recall: 0.8532 - val_loss: 0.6145 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00018: val_loss improved from 0.63967 to 0.61449, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 19/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.6625 - accuracy: 0.7470 - precision: 0.7061 - recall: 0.8449 - val_loss: 0.5876 - val_accuracy: 0.7267 - val_precision: 0.6933 - val_recall: 0.8800\n\nEpoch 00019: val_loss improved from 0.61449 to 0.58761, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 20/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.6764 - accuracy: 0.7592 - precision: 0.7210 - recall: 0.8469 - val_loss: 0.6552 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00020: val_loss did not improve from 0.58761\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:38:54.328269Z",
          "iopub.execute_input": "2021-08-31T18:38:54.328629Z",
          "iopub.status.idle": "2021-08-31T18:41:46.472595Z",
          "shell.execute_reply.started": "2021-08-31T18:38:54.328598Z",
          "shell.execute_reply": "2021-08-31T18:41:46.471484Z"
        },
        "trusted": true,
        "id": "fyqVqdLcIIxZ",
        "outputId": "4c4b3224-2ce6-4e50-e770-ce16d137163d"
      },
      "source": [
        "history = ResNet50_Transfer_learning_Model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 20, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger   ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20\n600/600 [==============================] - 9s 15ms/step - loss: 0.6577 - accuracy: 0.8157 - precision: 0.7333 - recall: 0.7975 - val_loss: 0.5568 - val_accuracy: 0.8467 - val_precision: 0.7733 - val_recall: 0.8800\n\nEpoch 00001: val_loss improved from 0.58761 to 0.55681, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 2/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.6298 - accuracy: 0.8399 - precision: 0.7608 - recall: 0.8033 - val_loss: 0.5433 - val_accuracy: 0.8533 - val_precision: 0.7800 - val_recall: 0.8800\n\nEpoch 00002: val_loss improved from 0.55681 to 0.54328, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 3/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.5907 - accuracy: 0.8907 - precision: 0.7775 - recall: 0.8050 - val_loss: 0.5089 - val_accuracy: 0.9467 - val_precision: 0.8467 - val_recall: 0.8800\n\nEpoch 00003: val_loss improved from 0.54328 to 0.50894, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 4/20\n600/600 [==============================] - 8s 13ms/step - loss: 0.5764 - accuracy: 0.8866 - precision: 0.7950 - recall: 0.7992 - val_loss: 0.4715 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00004: val_loss improved from 0.50894 to 0.47149, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 5/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.5427 - accuracy: 0.8816 - precision: 0.7858 - recall: 0.7917 - val_loss: 0.6387 - val_accuracy: 0.6600 - val_precision: 0.5600 - val_recall: 0.4467\n\nEpoch 00005: val_loss did not improve from 0.47149\nEpoch 6/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.5210 - accuracy: 0.8991 - precision: 0.7842 - recall: 0.7950 - val_loss: 0.4165 - val_accuracy: 0.9533 - val_precision: 0.8600 - val_recall: 0.8467\n\nEpoch 00006: val_loss improved from 0.47149 to 0.41650, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 7/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.5000 - accuracy: 0.8824 - precision: 0.7825 - recall: 0.7675 - val_loss: 0.3742 - val_accuracy: 0.9000 - val_precision: 0.8067 - val_recall: 0.7667\n\nEpoch 00007: val_loss improved from 0.41650 to 0.37424, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 8/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.4507 - accuracy: 0.8507 - precision: 0.7417 - recall: 0.7258 - val_loss: 0.3035 - val_accuracy: 0.8933 - val_precision: 0.7933 - val_recall: 0.7533\n\nEpoch 00008: val_loss improved from 0.37424 to 0.30351, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 9/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.4032 - accuracy: 0.8490 - precision: 0.7483 - recall: 0.7225 - val_loss: 0.2726 - val_accuracy: 0.9200 - val_precision: 0.8333 - val_recall: 0.7933\n\nEpoch 00009: val_loss improved from 0.30351 to 0.27265, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 10/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3864 - accuracy: 0.8465 - precision: 0.7458 - recall: 0.7108 - val_loss: 0.2343 - val_accuracy: 0.9067 - val_precision: 0.8067 - val_recall: 0.7733\n\nEpoch 00010: val_loss improved from 0.27265 to 0.23432, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 11/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3659 - accuracy: 0.8599 - precision: 0.7533 - recall: 0.7200 - val_loss: 0.3703 - val_accuracy: 0.9533 - val_precision: 0.8533 - val_recall: 0.8800\n\nEpoch 00011: val_loss did not improve from 0.23432\nEpoch 12/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3501 - accuracy: 0.8649 - precision: 0.7658 - recall: 0.7400 - val_loss: 0.3131 - val_accuracy: 0.7800 - val_precision: 0.6667 - val_recall: 0.5800\n\nEpoch 00012: val_loss did not improve from 0.23432\nEpoch 13/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3242 - accuracy: 0.8590 - precision: 0.7308 - recall: 0.7042 - val_loss: 0.1812 - val_accuracy: 0.9467 - val_precision: 0.8467 - val_recall: 0.8333\n\nEpoch 00013: val_loss improved from 0.23432 to 0.18121, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 14/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3367 - accuracy: 0.8632 - precision: 0.7500 - recall: 0.7117 - val_loss: 0.1868 - val_accuracy: 0.9267 - val_precision: 0.8467 - val_recall: 0.8133\n\nEpoch 00014: val_loss did not improve from 0.18121\nEpoch 15/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3317 - accuracy: 0.8724 - precision: 0.7833 - recall: 0.7475 - val_loss: 0.2017 - val_accuracy: 0.8867 - val_precision: 0.7800 - val_recall: 0.7400\n\nEpoch 00015: val_loss did not improve from 0.18121\nEpoch 16/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3234 - accuracy: 0.8741 - precision: 0.7492 - recall: 0.7275 - val_loss: 0.3068 - val_accuracy: 0.7933 - val_precision: 0.6800 - val_recall: 0.6000\n\nEpoch 00016: val_loss did not improve from 0.18121\nEpoch 17/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.3161 - accuracy: 0.8724 - precision: 0.7850 - recall: 0.7550 - val_loss: 0.1764 - val_accuracy: 0.9533 - val_precision: 0.8600 - val_recall: 0.8467\n\nEpoch 00017: val_loss improved from 0.18121 to 0.17636, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 18/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.2786 - accuracy: 0.8832 - precision: 0.7717 - recall: 0.7583 - val_loss: 0.3010 - val_accuracy: 0.8000 - val_precision: 0.6933 - val_recall: 0.6133\n\nEpoch 00018: val_loss did not improve from 0.17636\nEpoch 19/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.2985 - accuracy: 0.8699 - precision: 0.7633 - recall: 0.7375 - val_loss: 0.1546 - val_accuracy: 0.9467 - val_precision: 0.8467 - val_recall: 0.8333\n\nEpoch 00019: val_loss improved from 0.17636 to 0.15465, saving model to ResNet50_Transfer_learning_Weights.hdf5\nEpoch 20/20\n600/600 [==============================] - 8s 14ms/step - loss: 0.2793 - accuracy: 0.8866 - precision: 0.7625 - recall: 0.7558 - val_loss: 0.1664 - val_accuracy: 0.9467 - val_precision: 0.8467 - val_recall: 0.8333\n\nEpoch 00020: val_loss did not improve from 0.15465\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:44:30.584696Z",
          "iopub.execute_input": "2021-08-31T18:44:30.585057Z",
          "iopub.status.idle": "2021-08-31T18:45:59.317760Z",
          "shell.execute_reply.started": "2021-08-31T18:44:30.585029Z",
          "shell.execute_reply": "2021-08-31T18:45:59.316537Z"
        },
        "trusted": true,
        "id": "vI85aLb_IIxa",
        "outputId": "6ee8a5ca-a6da-4b8c-9824-bc3247cd7e5c"
      },
      "source": [
        "history = ResNet50_Transfer_learning_Model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 10, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger   ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n600/600 [==============================] - 13s 16ms/step - loss: 0.2759 - accuracy: 0.8866 - precision: 0.7717 - recall: 0.7608 - val_loss: 0.1799 - val_accuracy: 0.9200 - val_precision: 0.8333 - val_recall: 0.7933\n\nEpoch 00001: val_loss did not improve from 0.15169\nEpoch 2/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2730 - accuracy: 0.8882 - precision: 0.7725 - recall: 0.7667 - val_loss: 0.1933 - val_accuracy: 0.8933 - val_precision: 0.7933 - val_recall: 0.7533\n\nEpoch 00002: val_loss did not improve from 0.15169\nEpoch 3/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2770 - accuracy: 0.8882 - precision: 0.7875 - recall: 0.7650 - val_loss: 0.1612 - val_accuracy: 0.9133 - val_precision: 0.8333 - val_recall: 0.7933\n\nEpoch 00003: val_loss did not improve from 0.15169\nEpoch 4/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2926 - accuracy: 0.8741 - precision: 0.7767 - recall: 0.7600 - val_loss: 0.1645 - val_accuracy: 0.9467 - val_precision: 0.8467 - val_recall: 0.8333\n\nEpoch 00004: val_loss did not improve from 0.15169\nEpoch 5/10\n600/600 [==============================] - 9s 14ms/step - loss: 0.2725 - accuracy: 0.8849 - precision: 0.7867 - recall: 0.7600 - val_loss: 0.1652 - val_accuracy: 0.9467 - val_precision: 0.8467 - val_recall: 0.8333\n\nEpoch 00005: val_loss did not improve from 0.15169\nEpoch 6/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2655 - accuracy: 0.8932 - precision: 0.7875 - recall: 0.7675 - val_loss: 0.1536 - val_accuracy: 0.9333 - val_precision: 0.8467 - val_recall: 0.8200\n\nEpoch 00006: val_loss did not improve from 0.15169\nEpoch 7/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2839 - accuracy: 0.8824 - precision: 0.7892 - recall: 0.7717 - val_loss: 0.2173 - val_accuracy: 0.8733 - val_precision: 0.7667 - val_recall: 0.7200\n\nEpoch 00007: val_loss did not improve from 0.15169\nEpoch 8/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2751 - accuracy: 0.8882 - precision: 0.7725 - recall: 0.7542 - val_loss: 0.2124 - val_accuracy: 0.8733 - val_precision: 0.7667 - val_recall: 0.7200\n\nEpoch 00008: val_loss did not improve from 0.15169\nEpoch 9/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2656 - accuracy: 0.8941 - precision: 0.7925 - recall: 0.7683 - val_loss: 0.3253 - val_accuracy: 0.8000 - val_precision: 0.6933 - val_recall: 0.6133\n\nEpoch 00009: val_loss did not improve from 0.15169\nEpoch 10/10\n600/600 [==============================] - 8s 14ms/step - loss: 0.2700 - accuracy: 0.8932 - precision: 0.7858 - recall: 0.7517 - val_loss: 0.1581 - val_accuracy: 0.9333 - val_precision: 0.8467 - val_recall: 0.8200\n\nEpoch 00010: val_loss did not improve from 0.15169\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWo63CmXIIxb"
      },
      "source": [
        "### Accuracy on Test Data (ResNet50 Transfer Learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:45:59.319539Z",
          "iopub.execute_input": "2021-08-31T18:45:59.319903Z",
          "iopub.status.idle": "2021-08-31T18:46:06.955564Z",
          "shell.execute_reply.started": "2021-08-31T18:45:59.319865Z",
          "shell.execute_reply": "2021-08-31T18:46:06.954773Z"
        },
        "trusted": true,
        "id": "kFOLcoNXIIxb",
        "outputId": "c2a1393d-6a0b-4332-e334-b8c750db060f"
      },
      "source": [
        "ResNet50_Transfer_learning_Model = ResNet_Model(pretrained_weights = \"./ResNet50_Transfer_learning_Weights.hdf5\")\n",
        "\n",
        "print(\"Train_Accuracy\" )\n",
        "train_results = ResNet50_Transfer_learning_Model.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = ResNet50_Transfer_learning_Model.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "test_results = ResNet50_Transfer_learning_Model.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 4s 72ms/step - loss: 0.2232 - accuracy: 0.9275 - precision: 0.9273 - recall: 0.9544\nVal_Accuracy\n5/5 [==============================] - 0s 66ms/step - loss: 0.1517 - accuracy: 0.9400 - precision: 0.9715 - recall: 0.9338\nTest_Accuracy\n5/5 [==============================] - 0s 65ms/step - loss: 0.1868 - accuracy: 0.9533 - precision: 0.9317 - recall: 0.9900\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Cy0z1uIIxc"
      },
      "source": [
        "#### Predication for ResNet50 Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:46:12.330142Z",
          "iopub.execute_input": "2021-08-31T18:46:12.330472Z",
          "iopub.status.idle": "2021-08-31T18:46:13.534788Z",
          "shell.execute_reply.started": "2021-08-31T18:46:12.330442Z",
          "shell.execute_reply": "2021-08-31T18:46:13.533985Z"
        },
        "trusted": true,
        "id": "Sv-WwGcLIIxc",
        "outputId": "fd3315a0-e1ea-4335-9138-c004ed6e449f"
      },
      "source": [
        "\n",
        "ResNet50_predictions = ResNet50_Transfer_learning_Model.predict(test_images)\n",
        "#predictions = np.argmax(predictions,axis=1)\n",
        "pred = [1 if x > 0 else 0 for x in list(ResNet50_predictions[: , 0])]\n",
        "ResNet50_predictions = np.array(pred)\n",
        "ResNet50_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heSzGESgIIxd"
      },
      "source": [
        "# ****Pre-Trained Xception Model****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:43:29.553229Z",
          "iopub.execute_input": "2021-08-31T18:43:29.553570Z",
          "iopub.status.idle": "2021-08-31T18:43:31.344381Z",
          "shell.execute_reply.started": "2021-08-31T18:43:29.553534Z",
          "shell.execute_reply": "2021-08-31T18:43:31.343529Z"
        },
        "trusted": true,
        "id": "JFjmWsKoIIxd",
        "outputId": "3e6b8bff-9fa2-4fd6-be82-4556367f3a68"
      },
      "source": [
        "IMG_SIZE = 256\n",
        "\n",
        "base_model = keras.applications.Xception(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE , 3),\n",
        "    include_top=False,\n",
        ")  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be normalized\n",
        "# from (0, 255) to a range (-1., +1.), the normalization layer\n",
        "# does the following, outputs = (inputs - mean) / sqrt(var)\n",
        "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2\n",
        "# Scale inputs to [-1, +1]\n",
        "x = norm_layer(x)\n",
        "norm_layer.set_weights([mean, var])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 0s 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:46:25.777926Z",
          "iopub.execute_input": "2021-08-31T18:46:25.778264Z",
          "iopub.status.idle": "2021-08-31T18:46:25.842457Z",
          "shell.execute_reply.started": "2021-08-31T18:46:25.778234Z",
          "shell.execute_reply": "2021-08-31T18:46:25.841705Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "Gzc8YuwdIIxe",
        "outputId": "eedf1e6e-98c6-4ff6-a6b8-445daa6e60a8"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"xception\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_4[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_94 (Conv2D)              (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 63, 63, 128)  512         conv2d_94[0][0]                  \n__________________________________________________________________________________________________\nadd (Add)                       (None, 63, 63, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 63, 63, 128)  0           add[0][0]                        \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_95 (Conv2D)              (None, 32, 32, 256)  32768       add[0][0]                        \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 32, 32, 256)  1024        conv2d_95[0][0]                  \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_96 (Conv2D)              (None, 16, 16, 728)  186368      add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 16, 16, 728)  2912        conv2d_96[0][0]                  \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n                                                                 batch_normalization_96[0][0]     \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_2[0][0]                      \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n                                                                 add_2[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_97 (Conv2D)              (None, 8, 8, 1024)   745472      add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_97 (BatchNo (None, 8, 8, 1024)   4096        conv2d_97[0][0]                  \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_97[0][0]     \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 0\nNon-trainable params: 20,861,480\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvlE7pYYIIxf"
      },
      "source": [
        "## Extract features from an arbitrary intermediate layer ( XCEPTION Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:47:17.299269Z",
          "iopub.execute_input": "2021-08-31T18:47:17.299599Z",
          "iopub.status.idle": "2021-08-31T18:47:17.328524Z",
          "shell.execute_reply.started": "2021-08-31T18:47:17.299562Z",
          "shell.execute_reply": "2021-08-31T18:47:17.327062Z"
        },
        "trusted": true,
        "id": "IETdINfzIIxf",
        "outputId": "32f4ae78-f3dc-48a2-ad26-6c5941483446"
      },
      "source": [
        "Xception_Intermediatry_model = Model(inputs=base_model.input, outputs=base_model.get_layer('add_2').output)\n",
        "Xception_Intermediatry_model.trainable = True\n",
        "Xception_Intermediatry_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_4[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_94 (Conv2D)              (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 63, 63, 128)  512         conv2d_94[0][0]                  \n__________________________________________________________________________________________________\nadd (Add)                       (None, 63, 63, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 63, 63, 128)  0           add[0][0]                        \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_95 (Conv2D)              (None, 32, 32, 256)  32768       add[0][0]                        \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 32, 32, 256)  1024        conv2d_95[0][0]                  \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_96 (Conv2D)              (None, 16, 16, 728)  186368      add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 16, 16, 728)  2912        conv2d_96[0][0]                  \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n                                                                 batch_normalization_96[0][0]     \n==================================================================================================\nTotal params: 1,113,624\nTrainable params: 1,106,760\nNon-trainable params: 6,864\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:47:24.782277Z",
          "iopub.execute_input": "2021-08-31T18:47:24.782601Z",
          "iopub.status.idle": "2021-08-31T18:47:24.904774Z",
          "shell.execute_reply.started": "2021-08-31T18:47:24.782570Z",
          "shell.execute_reply": "2021-08-31T18:47:24.904002Z"
        },
        "trusted": true,
        "id": "CI-dw-_5IIxf",
        "outputId": "46683513-2193-4f45-ca15-eeeefbafb5cf"
      },
      "source": [
        "\n",
        "x = Xception_Intermediatry_model(inputs)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "x = Dense(units = 128 , activation = 'relu'  )(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x=  Dense(units = 64 , activation = 'relu' )(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output  = Dense(units = 1 ,kernel_regularizer = tf.keras.regularizers.l2(0.01), activation = 'linear')(x)\n",
        "\n",
        "model = keras.Model(inputs, output)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_5 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nmodel_4 (Functional)         (None, 16, 16, 728)       1113624   \n_________________________________________________________________\nglobal_average_pooling2d_4 ( (None, 728)               0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 728)               0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 128)               93312     \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 1,215,257\nTrainable params: 1,208,393\nNon-trainable params: 6,864\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:48:15.592569Z",
          "iopub.execute_input": "2021-08-31T18:48:15.592942Z",
          "iopub.status.idle": "2021-08-31T18:48:15.607759Z",
          "shell.execute_reply.started": "2021-08-31T18:48:15.592911Z",
          "shell.execute_reply": "2021-08-31T18:48:15.606935Z"
        },
        "trusted": true,
        "id": "cJ6y7kRtIIxg",
        "outputId": "97805c44-5853-4aec-88bf-e06b7efeba26"
      },
      "source": [
        "Xception_Intermediatry_model1 = model\n",
        "Xception_Intermediatry_model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_5 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nmodel_4 (Functional)         (None, 16, 16, 728)       1113624   \n_________________________________________________________________\nglobal_average_pooling2d_4 ( (None, 728)               0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 728)               0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 128)               93312     \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 1,215,257\nTrainable params: 1,208,393\nNon-trainable params: 6,864\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:48:23.765304Z",
          "iopub.execute_input": "2021-08-31T18:48:23.765630Z",
          "iopub.status.idle": "2021-08-31T18:57:48.379527Z",
          "shell.execute_reply.started": "2021-08-31T18:48:23.765599Z",
          "shell.execute_reply": "2021-08-31T18:57:48.378718Z"
        },
        "trusted": true,
        "id": "PttMim4mIIxh",
        "outputId": "d46b745d-bb89-4e96-f17e-99bb2c5dccc8"
      },
      "source": [
        "Xception_Intermediatry_model1.compile(optimizer=Adam(lr=7.00E-05), loss = 'hinge', metrics = ['accuracy',precision,recall])\n",
        "#model.compile(optimizer=Adam(lr=7.00E-05), loss = 'binary_crossentropy', metrics = ['accuracy',precision,recall])\n",
        "\n",
        "Xception_Intermediatry_model1.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 30, \n",
        "    validation_data=(val_images, val_labels)\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/30\n600/600 [==============================] - 21s 32ms/step - loss: 0.6109 - accuracy: 0.7210 - precision: 0.7341 - recall: 0.6656 - val_loss: 0.0939 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 2/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.2897 - accuracy: 0.8902 - precision: 0.8461 - recall: 0.8191 - val_loss: 0.0893 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 3/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.2182 - accuracy: 0.9192 - precision: 0.8173 - recall: 0.8156 - val_loss: 0.0783 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 4/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1779 - accuracy: 0.9483 - precision: 0.8756 - recall: 0.9003 - val_loss: 0.0784 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 5/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1886 - accuracy: 0.9295 - precision: 0.8178 - recall: 0.8400 - val_loss: 0.0786 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 6/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1294 - accuracy: 0.9559 - precision: 0.8469 - recall: 0.8617 - val_loss: 0.0662 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 7/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1570 - accuracy: 0.9477 - precision: 0.8313 - recall: 0.8499 - val_loss: 0.0800 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 8/30\n600/600 [==============================] - 19s 32ms/step - loss: 0.1650 - accuracy: 0.9405 - precision: 0.8487 - recall: 0.8824 - val_loss: 0.0703 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 9/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1437 - accuracy: 0.9462 - precision: 0.8195 - recall: 0.8352 - val_loss: 0.0751 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 10/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1724 - accuracy: 0.9384 - precision: 0.8262 - recall: 0.8571 - val_loss: 0.0701 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 11/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1418 - accuracy: 0.9590 - precision: 0.8479 - recall: 0.8730 - val_loss: 0.0669 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 12/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1543 - accuracy: 0.9466 - precision: 0.8117 - recall: 0.8381 - val_loss: 0.0652 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 13/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1493 - accuracy: 0.9506 - precision: 0.8531 - recall: 0.8838 - val_loss: 0.0664 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 14/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1558 - accuracy: 0.9509 - precision: 0.8584 - recall: 0.8856 - val_loss: 0.0673 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 15/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1328 - accuracy: 0.9518 - precision: 0.8382 - recall: 0.8639 - val_loss: 0.0620 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 16/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1205 - accuracy: 0.9588 - precision: 0.8315 - recall: 0.8577 - val_loss: 0.0585 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 17/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1309 - accuracy: 0.9482 - precision: 0.8295 - recall: 0.8508 - val_loss: 0.0591 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 18/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1246 - accuracy: 0.9547 - precision: 0.8258 - recall: 0.8531 - val_loss: 0.0599 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 19/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1266 - accuracy: 0.9572 - precision: 0.8464 - recall: 0.8649 - val_loss: 0.0591 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 20/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1168 - accuracy: 0.9545 - precision: 0.8299 - recall: 0.8517 - val_loss: 0.0578 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 21/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1263 - accuracy: 0.9527 - precision: 0.8279 - recall: 0.8495 - val_loss: 0.0589 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 22/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1398 - accuracy: 0.9428 - precision: 0.8156 - recall: 0.8375 - val_loss: 0.0654 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 23/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1248 - accuracy: 0.9497 - precision: 0.8373 - recall: 0.8631 - val_loss: 0.0633 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 24/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1196 - accuracy: 0.9508 - precision: 0.8479 - recall: 0.8705 - val_loss: 0.0577 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 25/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1108 - accuracy: 0.9610 - precision: 0.8169 - recall: 0.8412 - val_loss: 0.0653 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 26/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.0909 - accuracy: 0.9656 - precision: 0.8398 - recall: 0.8602 - val_loss: 0.0568 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 27/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1035 - accuracy: 0.9631 - precision: 0.8592 - recall: 0.8765 - val_loss: 0.1375 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 28/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1282 - accuracy: 0.9495 - precision: 0.8537 - recall: 0.8831 - val_loss: 0.1001 - val_accuracy: 0.9667 - val_precision: 0.8467 - val_recall: 0.8533\nEpoch 29/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.1144 - accuracy: 0.9580 - precision: 0.8296 - recall: 0.8563 - val_loss: 0.0582 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 30/30\n600/600 [==============================] - 19s 31ms/step - loss: 0.0984 - accuracy: 0.9631 - precision: 0.8355 - recall: 0.8535 - val_loss: 0.0580 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n",
          "output_type": "stream"
        },
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f588b842610>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI1CXq_HIIxh"
      },
      "source": [
        "### Accuracy by Xception Intermediatry_Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:57:48.380971Z",
          "iopub.execute_input": "2021-08-31T18:57:48.381310Z",
          "iopub.status.idle": "2021-08-31T18:57:53.088354Z",
          "shell.execute_reply.started": "2021-08-31T18:57:48.381276Z",
          "shell.execute_reply": "2021-08-31T18:57:53.087537Z"
        },
        "trusted": true,
        "id": "diHkdYNrIIxi",
        "outputId": "3d246810-e6b0-4e04-df31-671cce479b3c"
      },
      "source": [
        "\n",
        "print(\"Train_Accuracy\" )\n",
        "train_results = Xception_Intermediatry_model1.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = Xception_Intermediatry_model1.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "test_results = Xception_Intermediatry_model1.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 3s 60ms/step - loss: 0.0948 - accuracy: 0.9583 - precision: 0.9379 - recall: 1.0000\nVal_Accuracy\n5/5 [==============================] - 0s 96ms/step - loss: 0.0580 - accuracy: 0.9800 - precision: 0.9734 - recall: 1.0000\nTest_Accuracy\n5/5 [==============================] - 0s 47ms/step - loss: 0.0613 - accuracy: 0.9800 - precision: 0.9628 - recall: 1.0000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMS8g96OIIxj"
      },
      "source": [
        "### Predication by Xception Intermediatry_Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:59:56.762972Z",
          "iopub.execute_input": "2021-08-31T18:59:56.763295Z",
          "iopub.status.idle": "2021-08-31T18:59:57.132692Z",
          "shell.execute_reply.started": "2021-08-31T18:59:56.763267Z",
          "shell.execute_reply": "2021-08-31T18:59:57.131894Z"
        },
        "trusted": true,
        "id": "k3HorGfKIIxj",
        "outputId": "0d6ac76e-191a-48e6-9f00-624aff7dcb46"
      },
      "source": [
        "Xception_Intermediatry_model_predictions = Xception_Intermediatry_model1.predict(test_images)\n",
        "pred = [1 if x > 0 else 0 for x in list(Xception_Intermediatry_model_predictions[: , 0])]\n",
        "Xception_Intermediatry_model_predictions = np.array(pred)\n",
        "Xception_Intermediatry_model_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LVP0rwG0IIxk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESLUYDNWIIxk"
      },
      "source": [
        "# VGG-Net Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqOLXkOpBUA0",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:00:14.254127Z",
          "iopub.execute_input": "2021-08-31T19:00:14.254459Z",
          "iopub.status.idle": "2021-08-31T19:00:16.339520Z",
          "shell.execute_reply.started": "2021-08-31T19:00:14.254427Z",
          "shell.execute_reply": "2021-08-31T19:00:16.338708Z"
        },
        "trusted": true,
        "outputId": "e3a65060-ef08-4ca1-f7e4-492eed1a2a3f"
      },
      "source": [
        "#One hot encode y values for neural network. If we have Multiple Class Problem and we don't use sparse_categorical_loss\n",
        "# It is used when we use categorical_loss function for multi class problem\n",
        "\n",
        "\n",
        "IMG_SIZE = 256\n",
        "#############################\n",
        "#Load model wothout classifier/fully connected layers\n",
        "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE , 3))\n",
        "\n",
        "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
        "for layer in VGG_model.layers:\n",
        "\tlayer.trainable = False\n",
        "    \n",
        "VGG_model.summary()  #Trainable parameters will be 0\n",
        "\n",
        "#for layer in VGG_model.layers:\n",
        "#    print(layer)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 0\nNon-trainable params: 14,714,688\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfoRW_25IIxl"
      },
      "source": [
        "### Training Some Layers of VGGNet and Freeze the Weights of other Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:01:46.418659Z",
          "iopub.execute_input": "2021-08-31T19:01:46.419020Z",
          "iopub.status.idle": "2021-08-31T19:01:46.423787Z",
          "shell.execute_reply.started": "2021-08-31T19:01:46.418989Z",
          "shell.execute_reply": "2021-08-31T19:01:46.422841Z"
        },
        "trusted": true,
        "id": "_borZxrMIIxl"
      },
      "source": [
        "VGG_model.layers[-1].trainable = True\n",
        "VGG_model.layers[-2].trainable = True\n",
        "VGG_model.layers[-3].trainable = True\n",
        "VGG_model.layers[-4].trainable = True\n",
        "#VGG_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnzUs7TlIIxm"
      },
      "source": [
        "#### Input goes to VGG and We extract Some Features from it\n",
        "#### We also add some layers to VGG Model and Make a New Model\n",
        "#### We train that New Model with our Chagas Image Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:01:56.187588Z",
          "iopub.execute_input": "2021-08-31T19:01:56.187939Z",
          "iopub.status.idle": "2021-08-31T19:01:56.332721Z",
          "shell.execute_reply.started": "2021-08-31T19:01:56.187908Z",
          "shell.execute_reply": "2021-08-31T19:01:56.331865Z"
        },
        "trusted": true,
        "id": "KxMYl3MeIIxm",
        "outputId": "9c4d0908-8f36-4952-9ef1-f6dd8bda9fb4"
      },
      "source": [
        "# Freeze the base_model\n",
        "#VGG_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "x = VGG_model(x)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "#x = keras.layers.Dropout(0.5)(x)  # Regularize with dropout\n",
        "\n",
        "x = Dense(units = 512 , activation = 'relu' , kernel_regularizer=l2(0.01) )(x)\n",
        "x = Dropout(0.7)(x)\n",
        "x = Dense(units = 128 , activation = 'relu' ,  kernel_regularizer=l2(0.01) )(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x=  Dense(units = 64 , activation = 'relu' ,  kernel_regularizer=l2(0.01) )(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_8 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nsequential (Sequential)      (None, 256, 256, 3)       0         \n_________________________________________________________________\nvgg16 (Functional)           (None, 8, 8, 512)         14714688  \n_________________________________________________________________\nglobal_average_pooling2d_5 ( (None, 512)               0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 512)               262656    \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 15,051,329\nTrainable params: 7,416,065\nNon-trainable params: 7,635,264\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:02:05.513202Z",
          "iopub.execute_input": "2021-08-31T19:02:05.513524Z",
          "iopub.status.idle": "2021-08-31T19:05:18.473125Z",
          "shell.execute_reply.started": "2021-08-31T19:02:05.513494Z",
          "shell.execute_reply": "2021-08-31T19:05:18.472319Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "_q0Xu8ASIIxn",
        "outputId": "5347d396-3b0d-46e3-ac7d-e5eb5cdf7d0a"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(8.00E-05),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\" , precision, recall],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 20, \n",
        "    validation_data=(val_images, val_labels),\n",
        "    \n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20\n600/600 [==============================] - 12s 17ms/step - loss: 7.0901 - accuracy: 0.7182 - precision: 0.6064 - recall: 0.5952 - val_loss: 4.1466 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 2/20\n600/600 [==============================] - 9s 16ms/step - loss: 3.9509 - accuracy: 0.8935 - precision: 0.7761 - recall: 0.7807 - val_loss: 2.9888 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 3/20\n600/600 [==============================] - 9s 16ms/step - loss: 2.9681 - accuracy: 0.9174 - precision: 0.8043 - recall: 0.8091 - val_loss: 2.4313 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 4/20\n600/600 [==============================] - 9s 16ms/step - loss: 2.4068 - accuracy: 0.9307 - precision: 0.8190 - recall: 0.8404 - val_loss: 1.9836 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 5/20\n600/600 [==============================] - 10s 16ms/step - loss: 1.9283 - accuracy: 0.9589 - precision: 0.8112 - recall: 0.8306 - val_loss: 1.6258 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 6/20\n600/600 [==============================] - 9s 16ms/step - loss: 1.6075 - accuracy: 0.9552 - precision: 0.8599 - recall: 0.8719 - val_loss: 1.3487 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 7/20\n600/600 [==============================] - 9s 16ms/step - loss: 1.3612 - accuracy: 0.9498 - precision: 0.8435 - recall: 0.8547 - val_loss: 1.1148 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 8/20\n600/600 [==============================] - 10s 16ms/step - loss: 1.1497 - accuracy: 0.9442 - precision: 0.8235 - recall: 0.8457 - val_loss: 0.9267 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 9/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.9262 - accuracy: 0.9522 - precision: 0.8621 - recall: 0.8817 - val_loss: 0.7826 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 10/20\n600/600 [==============================] - 10s 16ms/step - loss: 0.8190 - accuracy: 0.9458 - precision: 0.8449 - recall: 0.8725 - val_loss: 0.6381 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 11/20\n600/600 [==============================] - 10s 16ms/step - loss: 0.6867 - accuracy: 0.9457 - precision: 0.8238 - recall: 0.8508 - val_loss: 0.5535 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 12/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.5777 - accuracy: 0.9487 - precision: 0.8298 - recall: 0.8500 - val_loss: 0.5227 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 13/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.5162 - accuracy: 0.9527 - precision: 0.8378 - recall: 0.8583 - val_loss: 0.4151 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 14/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.4095 - accuracy: 0.9560 - precision: 0.8205 - recall: 0.8399 - val_loss: 0.3428 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 15/20\n600/600 [==============================] - 10s 16ms/step - loss: 0.3664 - accuracy: 0.9532 - precision: 0.8364 - recall: 0.8651 - val_loss: 0.3216 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 16/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.3424 - accuracy: 0.9480 - precision: 0.8202 - recall: 0.8471 - val_loss: 0.2627 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 17/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.3223 - accuracy: 0.9502 - precision: 0.8207 - recall: 0.8427 - val_loss: 0.2680 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\nEpoch 18/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.2872 - accuracy: 0.9515 - precision: 0.8424 - recall: 0.8646 - val_loss: 0.2533 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 19/20\n600/600 [==============================] - 10s 16ms/step - loss: 0.2925 - accuracy: 0.9391 - precision: 0.8379 - recall: 0.8673 - val_loss: 0.2244 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 20/20\n600/600 [==============================] - 9s 16ms/step - loss: 0.2387 - accuracy: 0.9581 - precision: 0.8374 - recall: 0.8563 - val_loss: 0.2142 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n",
          "output_type": "stream"
        },
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f58888d1790>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:06:22.506106Z",
          "iopub.execute_input": "2021-08-31T19:06:22.506421Z",
          "iopub.status.idle": "2021-08-31T19:08:46.072876Z",
          "shell.execute_reply.started": "2021-08-31T19:06:22.506394Z",
          "shell.execute_reply": "2021-08-31T19:08:46.072068Z"
        },
        "trusted": true,
        "id": "dK2HFoe4IIxn",
        "outputId": "22f8b092-264b-4538-f1bf-0dbb45d29ac4"
      },
      "source": [
        "model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 15, \n",
        "    validation_data=(val_images, val_labels),\n",
        "    \n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/15\n600/600 [==============================] - 10s 16ms/step - loss: 0.2355 - accuracy: 0.9475 - precision: 0.8258 - recall: 0.8458 - val_loss: 0.2187 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 2/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.2189 - accuracy: 0.9475 - precision: 0.8208 - recall: 0.8375 - val_loss: 0.1953 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 3/15\n600/600 [==============================] - 10s 16ms/step - loss: 0.1986 - accuracy: 0.9508 - precision: 0.8375 - recall: 0.8633 - val_loss: 0.2170 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 4/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1865 - accuracy: 0.9525 - precision: 0.8300 - recall: 0.8517 - val_loss: 0.3032 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 5/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1763 - accuracy: 0.9475 - precision: 0.8275 - recall: 0.8442 - val_loss: 0.1806 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 6/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1855 - accuracy: 0.9500 - precision: 0.8508 - recall: 0.8667 - val_loss: 0.1845 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\nEpoch 7/15\n600/600 [==============================] - 10s 16ms/step - loss: 0.1762 - accuracy: 0.9450 - precision: 0.8292 - recall: 0.8400 - val_loss: 0.1916 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 8/15\n600/600 [==============================] - 10s 16ms/step - loss: 0.1557 - accuracy: 0.9508 - precision: 0.8217 - recall: 0.8433 - val_loss: 0.2196 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 9/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1466 - accuracy: 0.9475 - precision: 0.8317 - recall: 0.8375 - val_loss: 0.1787 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\nEpoch 10/15\n600/600 [==============================] - 10s 16ms/step - loss: 0.1551 - accuracy: 0.9483 - precision: 0.8233 - recall: 0.8358 - val_loss: 0.1652 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 11/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1295 - accuracy: 0.9458 - precision: 0.8292 - recall: 0.8317 - val_loss: 0.1948 - val_accuracy: 0.9467 - val_precision: 0.8600 - val_recall: 0.8400\nEpoch 12/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1546 - accuracy: 0.9383 - precision: 0.8258 - recall: 0.8317 - val_loss: 0.1901 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 13/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1509 - accuracy: 0.9458 - precision: 0.8333 - recall: 0.8517 - val_loss: 0.2060 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 14/15\n600/600 [==============================] - 10s 16ms/step - loss: 0.1428 - accuracy: 0.9558 - precision: 0.8300 - recall: 0.8550 - val_loss: 0.1599 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\nEpoch 15/15\n600/600 [==============================] - 9s 16ms/step - loss: 0.1307 - accuracy: 0.9483 - precision: 0.8275 - recall: 0.8375 - val_loss: 0.1571 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8800\n",
          "output_type": "stream"
        },
        {
          "execution_count": 53,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f5888912e50>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c4-e1J5IIxo"
      },
      "source": [
        "### Accuracy and Predication of VGGNet (Training Last Layers Only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:09:08.828750Z",
          "iopub.execute_input": "2021-08-31T19:09:08.829122Z",
          "iopub.status.idle": "2021-08-31T19:09:13.755692Z",
          "shell.execute_reply.started": "2021-08-31T19:09:08.829079Z",
          "shell.execute_reply": "2021-08-31T19:09:13.754905Z"
        },
        "trusted": true,
        "id": "HwkjhCIgIIxo",
        "outputId": "77375441-305a-4603-b0df-1de99ece9150"
      },
      "source": [
        "print(\"Train_Accuracy\" )\n",
        "train_results = model.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = model.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "test_results = model.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 3s 81ms/step - loss: 0.1179 - accuracy: 0.9558 - precision: 0.9348 - recall: 1.0000\nVal_Accuracy\n5/5 [==============================] - 0s 75ms/step - loss: 0.1571 - accuracy: 0.9800 - precision: 0.9734 - recall: 1.0000\nTest_Accuracy\n5/5 [==============================] - 0s 76ms/step - loss: 0.1521 - accuracy: 0.9733 - precision: 0.9628 - recall: 0.9895\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:09:18.461779Z",
          "iopub.execute_input": "2021-08-31T19:09:18.462105Z",
          "iopub.status.idle": "2021-08-31T19:09:18.957633Z",
          "shell.execute_reply.started": "2021-08-31T19:09:18.462075Z",
          "shell.execute_reply": "2021-08-31T19:09:18.956767Z"
        },
        "trusted": true,
        "id": "590M4TvRIIxp",
        "outputId": "5de55da4-8256-4477-acad-c5f14b0a010e"
      },
      "source": [
        "\n",
        "vgg_model_pred = model.predict(test_images)\n",
        "pred = [1 if x > 0 else 0 for x in list(vgg_model_pred[: , 0])]\n",
        "vgg_model_pred = np.array(pred)\n",
        "vgg_model_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:25:47.401417Z",
          "iopub.execute_input": "2021-08-31T19:25:47.401749Z",
          "iopub.status.idle": "2021-08-31T19:25:47.413902Z",
          "shell.execute_reply.started": "2021-08-31T19:25:47.401704Z",
          "shell.execute_reply": "2021-08-31T19:25:47.413040Z"
        },
        "trusted": true,
        "id": "NheK2B-_IIxq",
        "outputId": "2631f81f-e47f-4d08-c2e7-9796b90b1eef"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_8 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nsequential (Sequential)      (None, 256, 256, 3)       0         \n_________________________________________________________________\nvgg16 (Functional)           (None, 8, 8, 512)         14714688  \n_________________________________________________________________\nglobal_average_pooling2d_5 ( (None, 512)               0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 512)               262656    \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 15,051,329\nTrainable params: 7,416,065\nNon-trainable params: 7,635,264\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:40:56.966176Z",
          "iopub.execute_input": "2021-08-31T19:40:56.966503Z",
          "iopub.status.idle": "2021-08-31T19:40:56.999461Z",
          "shell.execute_reply.started": "2021-08-31T19:40:56.966472Z",
          "shell.execute_reply": "2021-08-31T19:40:56.998702Z"
        },
        "trusted": true,
        "id": "WX6SZh15IIxr",
        "outputId": "f8930ff1-0bae-4a46-fa47-12aef7c1a518"
      },
      "source": [
        "VGG_model.inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 7,079,424\nNon-trainable params: 7,635,264\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:42:09.096856Z",
          "iopub.execute_input": "2021-08-31T19:42:09.097194Z",
          "iopub.status.idle": "2021-08-31T19:42:09.117491Z",
          "shell.execute_reply.started": "2021-08-31T19:42:09.097166Z",
          "shell.execute_reply": "2021-08-31T19:42:09.116338Z"
        },
        "trusted": true,
        "id": "VrvwPSQ2IIxr",
        "outputId": "61c7d4cf-1ce9-4248-dbfb-591846092c1b"
      },
      "source": [
        "VGG_Fine_tunned = Model(VGG_model.inputs , model.get_layer(\"vgg16\").output)\n",
        "VGG_Fine_tunned.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 7,079,424\nNon-trainable params: 7,635,264\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAWXUi8zIIxs"
      },
      "source": [
        "# Extracting Features From Transfer Learned VGGNet Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl2tvbxoj33w",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:42:58.582851Z",
          "iopub.execute_input": "2021-08-31T19:42:58.583187Z",
          "iopub.status.idle": "2021-08-31T19:43:02.326937Z",
          "shell.execute_reply.started": "2021-08-31T19:42:58.583158Z",
          "shell.execute_reply": "2021-08-31T19:43:02.326044Z"
        },
        "trusted": true
      },
      "source": [
        "\n",
        "#Now, let us use features from convolutional network for RF\n",
        "feature_extractor=VGG_Fine_tunned.predict(train_images)\n",
        "\n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "\n",
        "X_for_training = features #This is our X input to Machine learning Model or PCA or to Dense Layer\n",
        "## Features shape would be ( No_of_train_images    ,   Width_of_last_channel * Height_of_last_channel* Number_of_Filters_in_last_layer )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko-Vb99a2WSJ"
      },
      "source": [
        "# ****Feature Reduction Techniques****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walLvPpI2VPT",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:44:15.901401Z",
          "iopub.execute_input": "2021-08-31T19:44:15.901757Z",
          "iopub.status.idle": "2021-08-31T19:44:16.026105Z",
          "shell.execute_reply.started": "2021-08-31T19:44:15.901709Z",
          "shell.execute_reply": "2021-08-31T19:44:16.025120Z"
        },
        "trusted": true,
        "outputId": "c14cfe97-5273-458a-ebd3-e619a64aba50"
      },
      "source": [
        "## \n",
        "# features are of shape (1199 ,  w * h * number_filters ) these are all for the Last Layer of the CNN\n",
        "print(train_images.shape[0] )\n",
        "labels = np.reshape( train_labels , ( train_images.shape[0] , 1)) \n",
        "\n",
        "#labels = np.reshape( train_labels , (1199 , 1)) \n",
        "\n",
        "import pandas as pd\n",
        "#### Creating DataFrame of Features Only\n",
        "Train_data_Features_DataFrame = pd.DataFrame(features)\n",
        "\n",
        "#### Creating DataFrame of Features and Labels\n",
        "# Concatenate the features and labels \n",
        "final_train_data_with_features_and_labels = np.concatenate( [ features , labels ] , axis = 1 ) ## We get a shape of (1199 , 1 + w * h * number_filters in last layer)\n",
        "\n",
        "Train_data_DataFrame = pd.DataFrame(final_train_data_with_features_and_labels)\n",
        "\n",
        "Train_data_DataFrame.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1199\n",
          "output_type": "stream"
        },
        {
          "execution_count": 72,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   0      1      2      3      4      5      6      7      8      9      ...  \\\n0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n\n   32759  32760  32761  32762  32763  32764  32765  32766  32767  32768  \n0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n\n[5 rows x 32769 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>32759</th>\n      <th>32760</th>\n      <th>32761</th>\n      <th>32762</th>\n      <th>32763</th>\n      <th>32764</th>\n      <th>32765</th>\n      <th>32766</th>\n      <th>32767</th>\n      <th>32768</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32769 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOtrr1k5IIxt"
      },
      "source": [
        "### Scaled Features using StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH6EjrXm7vhO",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:45:03.258481Z",
          "iopub.execute_input": "2021-08-31T19:45:03.258823Z",
          "iopub.status.idle": "2021-08-31T19:45:04.081064Z",
          "shell.execute_reply.started": "2021-08-31T19:45:03.258792Z",
          "shell.execute_reply": "2021-08-31T19:45:04.079994Z"
        },
        "trusted": true,
        "outputId": "ced1d473-93a9-4595-f63f-ff60c46aa8b2"
      },
      "source": [
        "#Standard Scaler will scale the distribution to a mean of zero and a standard deviation of one for each of the Feature\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train_features = Train_data_Features_DataFrame.values\n",
        "\n",
        "\n",
        "# Fit on training set only.\n",
        "scaler.fit(train_features)\n",
        "\n",
        "# Apply transform to both the training set and the test set.\n",
        "Standarized_Train_Features = scaler.transform(train_features)\n",
        "#test_img = scaler.transform(test_img)\n",
        "\n",
        "\n",
        "print( np.mean(Standarized_Train_Features),np.std(Standarized_Train_Features))\n",
        "\n",
        "feat_cols = ['feature'+str(i) for i in range(Standarized_Train_Features.shape[1])]\n",
        "normalised_Features_DataFrame = pd.DataFrame(Standarized_Train_Features ,columns=feat_cols)\n",
        "\n",
        "normalised_Features_DataFrame.tail()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1.1745422e-09 0.63677895\n",
          "output_type": "stream"
        },
        {
          "execution_count": 73,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n1194       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n1195       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n1196       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n1197       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n1198       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n\n      feature7  feature8  feature9  ...  feature32758  feature32759  \\\n1194       0.0 -0.033046       0.0  ...     -0.039624           0.0   \n1195       0.0 -0.033046       0.0  ...     -0.039624           0.0   \n1196       0.0 -0.033046       0.0  ...     -0.039624           0.0   \n1197       0.0 -0.033046       0.0  ...     -0.039624           0.0   \n1198       0.0 -0.033046       0.0  ...     -0.039624           0.0   \n\n      feature32760  feature32761  feature32762  feature32763  feature32764  \\\n1194     -0.091525           0.0           0.0           0.0     -0.028892   \n1195     -0.091525           0.0           0.0           0.0     -0.028892   \n1196     -0.091525           0.0           0.0           0.0     -0.028892   \n1197     -0.091525           0.0           0.0           0.0     -0.028892   \n1198     -0.091525           0.0           0.0           0.0     -0.028892   \n\n      feature32765  feature32766  feature32767  \n1194           0.0           0.0           0.0  \n1195           0.0           0.0           0.0  \n1196           0.0           0.0           0.0  \n1197           0.0           0.0           0.0  \n1198           0.0           0.0           0.0  \n\n[5 rows x 32768 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature0</th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n      <th>feature5</th>\n      <th>feature6</th>\n      <th>feature7</th>\n      <th>feature8</th>\n      <th>feature9</th>\n      <th>...</th>\n      <th>feature32758</th>\n      <th>feature32759</th>\n      <th>feature32760</th>\n      <th>feature32761</th>\n      <th>feature32762</th>\n      <th>feature32763</th>\n      <th>feature32764</th>\n      <th>feature32765</th>\n      <th>feature32766</th>\n      <th>feature32767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1194</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.033046</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.039624</td>\n      <td>0.0</td>\n      <td>-0.091525</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.028892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.033046</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.039624</td>\n      <td>0.0</td>\n      <td>-0.091525</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.028892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.033046</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.039624</td>\n      <td>0.0</td>\n      <td>-0.091525</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.028892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.033046</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.039624</td>\n      <td>0.0</td>\n      <td>-0.091525</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.028892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.033046</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.039624</td>\n      <td>0.0</td>\n      <td>-0.091525</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.028892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32768 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2jsn9rRIIxu"
      },
      "source": [
        "## Feature Reduction Using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3xIgqVP9o8A",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:46:54.530184Z",
          "iopub.execute_input": "2021-08-31T19:46:54.530594Z",
          "iopub.status.idle": "2021-08-31T19:47:01.275146Z",
          "shell.execute_reply.started": "2021-08-31T19:46:54.530556Z",
          "shell.execute_reply": "2021-08-31T19:47:01.274030Z"
        },
        "trusted": true,
        "outputId": "01716f72-ee81-4f93-e387-1728d0eddec9"
      },
      "source": [
        "## \n",
        "Total_Num_of_Features_Extracted = Standarized_Train_Features.shape[1]\n",
        "print(Total_Num_of_Features_Extracted)\n",
        "from sklearn.decomposition import PCA\n",
        "#pca = PCA(n_components= 20)\n",
        "pca = PCA( 0.9 )\n",
        "\n",
        "# Fit the PCA on Train_Data_Features \n",
        "pca.fit(Standarized_Train_Features)\n",
        "\n",
        "Train_Features_Reduced_PCA = pca.transform(Standarized_Train_Features)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "32768\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flWfIQRf-lne",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:47:06.610173Z",
          "iopub.execute_input": "2021-08-31T19:47:06.610504Z",
          "iopub.status.idle": "2021-08-31T19:47:06.614780Z",
          "shell.execute_reply.started": "2021-08-31T19:47:06.610466Z",
          "shell.execute_reply": "2021-08-31T19:47:06.613897Z"
        },
        "trusted": true,
        "outputId": "c6b7fa1c-71a6-414f-d85a-022343e950e1"
      },
      "source": [
        "#print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "print( \"90% of variance is explained by {} number of Principle Components \".format(pca.n_components_))\n",
        "#print( pca.n_components_ )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "90% of variance is explained by 73 number of Principle Components \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u1VZZkHIIxw"
      },
      "source": [
        "# Test Data Features from VGG Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xR2oc3CAASu",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:48:13.565210Z",
          "iopub.execute_input": "2021-08-31T19:48:13.565547Z",
          "iopub.status.idle": "2021-08-31T19:48:14.083192Z",
          "shell.execute_reply.started": "2021-08-31T19:48:13.565514Z",
          "shell.execute_reply": "2021-08-31T19:48:14.082246Z"
        },
        "trusted": true
      },
      "source": [
        "## Test Data Features ( X Data)\n",
        "test_features = VGG_Fine_tunned.predict(test_images)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD6VLjE0IIxx"
      },
      "source": [
        "### Scaling Test Features as we will apply PCA Feature Reduction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfre34AcR4P5",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:48:32.272115Z",
          "iopub.execute_input": "2021-08-31T19:48:32.272447Z",
          "iopub.status.idle": "2021-08-31T19:48:32.321576Z",
          "shell.execute_reply.started": "2021-08-31T19:48:32.272416Z",
          "shell.execute_reply": "2021-08-31T19:48:32.320490Z"
        },
        "trusted": true
      },
      "source": [
        "test_features_reshaped = test_features.reshape(test_features.shape[0], -1)\n",
        "\n",
        "#test_feature_values = test_features.values\n",
        "\n",
        "# Standard Scalar\n",
        "Standarized_test_features = scaler.transform(test_features_reshaped)\n",
        "\n",
        "## PCA on test data \n",
        "Test_Features_Reduced_PCA = pca.transform(Standarized_test_features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZdDYlHRIIxy"
      },
      "source": [
        "## Extracting Test and Validation Features from VggNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:48:59.683437Z",
          "iopub.execute_input": "2021-08-31T19:48:59.683793Z",
          "iopub.status.idle": "2021-08-31T19:49:00.701700Z",
          "shell.execute_reply.started": "2021-08-31T19:48:59.683757Z",
          "shell.execute_reply": "2021-08-31T19:49:00.700761Z"
        },
        "trusted": true,
        "id": "gc_Bg7ZbIIxy"
      },
      "source": [
        "# VGG_model\n",
        "#Send test data through same feature extractor process\n",
        "X_test_feature = VGG_Fine_tunned.predict(test_images)\n",
        "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
        "\n",
        "\n",
        "#Send test data through same feature extractor process\n",
        "X_val_feature = VGG_Fine_tunned.predict(val_images)\n",
        "X_val_features = X_val_feature.reshape(X_val_feature.shape[0], -1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5ovuKPBIIxz"
      },
      "source": [
        "## PCA Feature Reduction on Validation Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T19:49:11.162773Z",
          "iopub.execute_input": "2021-08-31T19:49:11.163098Z",
          "iopub.status.idle": "2021-08-31T19:49:11.209305Z",
          "shell.execute_reply.started": "2021-08-31T19:49:11.163067Z",
          "shell.execute_reply": "2021-08-31T19:49:11.208313Z"
        },
        "trusted": true,
        "id": "VgChHkBRIIxz"
      },
      "source": [
        "\n",
        "\n",
        "# Standard Scalar\n",
        "Standarized_val_features = scaler.transform(X_val_features)\n",
        "\n",
        "## PCA on test data \n",
        "Val_Features_Reduced_PCA = pca.transform(Standarized_val_features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfbKzUUaaaVD"
      },
      "source": [
        "# XGBoost on Reduced PCA Training Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg2usMkONRg7",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:49:19.954403Z",
          "iopub.execute_input": "2021-08-31T19:49:19.954814Z",
          "iopub.status.idle": "2021-08-31T19:49:23.695529Z",
          "shell.execute_reply.started": "2021-08-31T19:49:19.954776Z",
          "shell.execute_reply": "2021-08-31T19:49:23.694684Z"
        },
        "trusted": true,
        "outputId": "fd76ef80-1e89-4547-bf82-a72ca5348c95"
      },
      "source": [
        "### XGBoost on Reduced Features after Applying PCA\n",
        "import xgboost as xgb\n",
        "\n",
        "#XGBOOST after PCA\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(Train_Features_Reduced_PCA, train_labels) #For sklearn no one hot encoding\n",
        "\n",
        "\n",
        "#Now predict using the trained RF model. \n",
        "prediction = model.predict(Test_Features_Reduced_PCA)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Test Accuracy = \", metrics.accuracy_score(test_labels, prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[19:49:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nTest Accuracy =  0.98\n",
          "output_type": "stream"
        },
        {
          "execution_count": 86,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJskoPRwaTWa"
      },
      "source": [
        "# SVM on REDUCED PCA Training Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owH1hMVuYbG7",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:49:50.835499Z",
          "iopub.execute_input": "2021-08-31T19:49:50.835867Z",
          "iopub.status.idle": "2021-08-31T19:49:51.100598Z",
          "shell.execute_reply.started": "2021-08-31T19:49:50.835836Z",
          "shell.execute_reply": "2021-08-31T19:49:51.099668Z"
        },
        "trusted": true,
        "outputId": "4b3bec5d-03db-46e3-f24c-e55f679f50d6"
      },
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(Train_Features_Reduced_PCA, train_labels)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(Test_Features_Reduced_PCA)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, y_pred))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy =  0.9533333333333334\n",
          "output_type": "stream"
        },
        {
          "execution_count": 87,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAATKUlEQVR4nO3dfZBddX3H8ffXPBhIoDwE1jWxhEKEIhWqyCioRSIULW3SFhG0NtV04nTUam0t1NYydDqd2LFVajt2VgikIwQiCkFHEIg8iA+BIAiEgGBKkJgHwCCB8rR7v/1jj7rGzZ5dcn977568X8yZvefcc3/3u8zOZ375nqfITCRJ5byk0wVIUtMZtJJUmEErSYUZtJJUmEErSYUZtJJUmEErSTsREX8VEWsj4p6IWB4R0yLi4IhYHREPRsRlETG1bhyDVpKGERGzgL8EjsnMI4FJwBnAJ4FPZ+ahwDZgUd1YBq0k7dxkYI+ImAzsCWwCTgQur95fBiwYzSBF/d/nPuSlZ/oVe3/4y50uQV2o//mNsatjvPDY+lFnztQDDnk/sHjIpr7M7APIzI0R8SngYeAZ4FrgduCJzOyv9n8EmFX3PcWDVpLGVWtg1LtWodo33HsRsS8wHzgYeAL4InDKiynJoJXULNlq10hvBf43Mx8FiIgvA8cD+0TE5GpWOxvYWDeQPVpJzdJqjX4Z2cPA6yNiz4gIYB5wL3ADcFq1z0JgZd1ABq2kRslsjXoZeZxczeBBr+8BdzOYl33AWcBHI+JBYH/ggrqabB1IapaB/vp9RikzzwHO2WHzeuDYsYxj0EpqljEcDBsvBq2kZmnfwbC2MWglNUv9Qa5xZ9BKapS6g1ydYNBKahZntJJU2MALna7gVxi0kprF1oEkFWbrQJIKc0YrSYU5o5WksrLlwTBJKssZrSQVZo9WkgrzpjKSVJgzWkkqzB6tJBXWxht/t4tBK6lZnNFKUlmZ3XcwzIczSmqWNj0FNyIOi4g7hyxPRsRHImK/iLguIh6ofu5bV5JBK6lZsjX6ZaRhMu/PzKMz82jgtcD/AVcAZwOrMnMusKpaH5FBK6lZ2jSj3cE84IeZuQGYDyyrti8DFtR92B6tpGYZw1kHEbEYWDxkU19m9g2z6xnA8up1T2Zuql5vBnrqvsegldQsY7hgoQrV4YL15yJiKvAHwN8N8/mMiKz7HoNWUrO0//SutwHfy8wt1fqWiOjNzE0R0QtsrRvAHq2kZml/j/ZMftE2ALgKWFi9XgisrBvAGa2kZmnjvQ4iYjpwEvD+IZuXACsiYhGwATi9bhyDVlKztPES3Mx8Gth/h22PM3gWwqgZtJKaxUtwJakwb5MoSYU5o5WkwgxaSSosa68fGHcGraRm6ffG35JUlgfDJKkwe7SSVJg9WkkqzBmtJBVm0EpSWTnQfQ9nNGglNYszWkkqzNO7JKmwlmcdSFJZtg4kqTAPhu1etj/7Audev5YfPv4UQXDOSa/iloce46b1WwmC/facyrknv4oDZ0zrdKnqgNmzX85FS8/jwJ6ZZCbnn38xn/3PCzpd1sTnjHb38q833cdxc2byqVOP5oWBFs++MMAh+8/gA8cdCsAld2ygb/V6/mHeER2uVJ3Q39/Px/72XO648x5mzJjOrauv4fpVN7Nu3QOdLm1im4g92og4HJgPzKo2bQSuysx1JQub6LY/9wLf27iNfzr5SACmTHoJUyb98kOHn3lhgOhEceoKmzdvZfPmwSdVP/XU09x33wPMevnLDNpd1d6HM+4DnA8cCSTwPuB+4DJgDvAQcHpmbhtpnBEfNx4RZwGXAgHcWi0BLI+Is3flF2i6H//0GfbdYyrnXLuWMy7+Dudet5ZnXhi8fdt/fusBTjn/Jq6+fxN/8YZDO1ypusFBB83m6KOOZPWtd3S6lImvlaNf6p0HXJOZhwNHAeuAs4FVmTkXWFWtj2jEoAUWAa/LzCWZ+YVqWQIcW703rIhYHBFrImLN0lvuGc0v0zj9mdy3dTvvePVsLn33G9hjyiSW3vYQAB88fi7X/Pnv8LbDerns+w93tlB13PTpe7Liss/z0b85h+3bn+p0ORNetlqjXkYSEb8GvBm4ACAzn8/MJxj8F/6yardlwIK6muqCtgW8fJjtvdV7w8rMvsw8JjOPed8bj6yroZF6ZkzjwBkv5bd69wHgrXN7uG/rk7+0z9sP72XVg1s6UJ26xeTJk/niZZ9n+fIruPLKqztdTjMMDIx6GToprJbFQ0Y6GHgUuDAi7oiI8yNiOtCTmZuqfTYDPXUl1fVoPwKsiogHgB9V234dOBT44Bh+9d3OzOkv5WV7TeOhnzzNnP2mc+vDj/Mb+09nw7anOWjf6QDcuP5R5lSvtXv6fN+/se6+B/nMeX2dLqU5xnAwLDP7gJ39z58MvAb4UGaujojz2KFNkJkZEbVfOGLQZuY1EfFKBlsFQw+G3ZaZ3XeyWpc564TD+fg1d9PfajFr7z049+QjOff6tWzY9jQviaB3r2n8vWcc7LaOP+51vOdPTuOuu+9lzW3XAvCJTyzh6mu+0eHKJrj2nd71CPBIZq6u1i9nMGi3RERvZm6KiF5ga91AtWcdZGYL+O6uVLu7OuzAvbnkXa//pW3/durRnSlGXedb376NyVNn1e+osWnT6V2ZuTkifhQRh2Xm/cA84N5qWQgsqX6urBvL82glNUt7byrzIeDiiJgKrAfey+CxrRURsQjYAJxeN4hBK6lZ2njBQmbeCRwzzFvzxjKOQSupUbK/+w4fGbSSmmUiXoIrSROKN/6WpMKc0UpSWWnQSlJhHgyTpMKc0UpSYQatJJWVadBKUlnOaCWpMINWksrKfi9YkKSyui9nDVpJzeIFC5JUmkErSYXZOpCksmwdSFJh2W/QSlJZtg4kqax23vc7Ih4CtgMDQH9mHhMR+wGXAXOAh4DTM3PbSOO8pH0lSVIXaI1hGZ23ZObRmfmzhzSeDazKzLnAqmp9RAatpEbJ1uiXF2k+sKx6vQxYUPcBg1ZSo2T/6JeIWBwRa4Ysi3ccDrg2Im4f8l5PZm6qXm8GeupqskcrqVHGMlPNzD6gb4Rd3piZGyPiQOC6iLhvh89nRNSe5uCMVlKjtLN1kJkbq59bgSuAY4EtEdELUP3cWjeOQSupWTJGv4wgIqZHxF4/ew2cDNwDXAUsrHZbCKysK8nWgaRGaePpXT3AFREBg1l5SWZeExG3ASsiYhGwATi9biCDVlKjZGvkmeqox8lcDxw1zPbHgXljGcugldQorYH2BG07GbSSGqWdV4a1i0ErqVHa1TpoJ4NWUqN04dPGDVpJzeKMVpIK82CYJBXmjFaSCsuaK746waCV1Cie3iVJhbWc0UpSWbYOJKkwzzqQpMI860CSCrNHK0mF2aOVpMK814EkFWbrQJIKa3kwTJLK2i1ntL0f+1rpr9AE9MyPv9npEtRQ7T4YFhGTgDXAxsw8NSIOBi4F9gduB96Tmc+PNIaPG5fUKK2MUS+j9GFg3ZD1TwKfzsxDgW3AoroBDFpJjZJjWOpExGzg94Dzq/UATgQur3ZZBiyoG8ceraRGGWiNfv4YEYuBxUM29WVm35D1zwB/C+xVre8PPJGZ/dX6I8Csuu8xaCU1yljukliFat9w70XEqcDWzLw9Ik7YlZoMWkmNkrTtYNjxwB9ExNuBacDewHnAPhExuZrVzgY21g1kj1ZSo7Ry9MtIMvPvMnN2Zs4BzgC+kZnvBm4ATqt2WwisrKvJoJXUKC1i1MuLdBbw0Yh4kMGe7QV1H7B1IKlR2tg6+MWYmTcCN1av1wPHjuXzBq2kRhkoELS7yqCV1Chd+GxGg1ZSsxi0klRYiR7trjJoJTVKF94l0aCV1Cy7cNpWMQatpEYZ6HQBwzBoJTVKK5zRSlJRXfhsRoNWUrN4epckFeZZB5JUmJfgSlJhzmglqTB7tJJUmGcdSFJhtg4kqTBbB5JU2IAzWkkqqxtntD6cUVKjtMawjCQipkXErRHx/YhYGxHnVtsPjojVEfFgRFwWEVPrajJoJTVKjmGp8RxwYmYeBRwNnBIRrwc+CXw6Mw8FtgGL6gYyaCU1SitGv4wkBz1VrU6plgROBC6vti8DFtTVZNBKapSxtA4iYnFErBmyLB46VkRMiog7ga3AdcAPgScys7/a5RFgVl1NHgyT1ChjufF3ZvYBfSO8PwAcHRH7AFcAh7+YmgxaSY1S4oKFzHwiIm4A3gDsExGTq1ntbGBj3edtHUhqlDaedXBANZMlIvYATgLWATcAp1W7LQRW1tXkjFZSo7TxXge9wLKImMTgpHRFZn41Iu4FLo2IfwbuAC6oG8igldQorTZFbWbeBfz2MNvXA8eOZSyDVlKj+BRcSSqsGy/BNWglNYq3SZSkwtrVo20ng1ZSo3RfzBq0khrGHq0kFTbQhXNag1ZSozijlaTCPBgmSYV1X8watJIaxtaBJBXmwTBJKswe7W7srrU38dRTTzMwMMBA/wAnvHlBp0tSB/zPpVfwpa9cQ0Qw95A5/PPHP8qjj/+Ej52zhCd++iRHHDaXJf/4N0yZMqXTpU5Y3Rez3vh7XJ369nfzpuN+35DdTW159DEuvnwlly39D678wn/TarW4+vqb+PTnlvKedy7g6hVL2XuvGXzpq1/vdKkTWosc9TJeDFppHPUPDPDcc8/T3z/AM88+xwEz92P17d/n5BPeBMD8t7+Vb9z8nQ5XObG16wkL7WTrYLxkcuXKi8iEC5cu56ILL+10RRpnPQfM5M/O/GPe+kd/yrSXTuW4172GIw47lL1mTGfy5Ek/32fro493uNKJLbuwefCigzYi3puZF+7kvcXAYoBpU2cydcreL/ZrGuN3T3onmzZtYeYB+3PlVcv4wQ9+yLe/dVuny9I4+umT27nhm9/l61+8kL32msFf/8O/cMvq2ztdVuN041kHu9I6OHdnb2RmX2Yek5nHGLKDNm3aAsBjjz7OV79yLa997VEdrkjj7btr7mTWy3vYb999mDJ5MvN+5zjuuGst2596mv7+wecCbHn0MQ48YP8OVzqxtfHhjK+IiBsi4t6IWBsRH6627xcR10XEA9XPfetqGjFoI+KunSx3Az11g2vQnnvuwYwZ03/++sQT38S99/6gw1VpvPX2HMBd99zHM88+S2ayes2dHDLn1zn2Na/m2hu/CcDKr13PiW96Q4crndhamaNeavQDf52ZRwCvBz4QEUcAZwOrMnMusKpaH1Fd66AH+F1g2w7bA/h23eAadOCBM/nC8s8BMHnyJC5f8RVWXX9zh6vSeHv1qw7npLe8kdPf+yEmTZrE4a88hHfMfxtvPu5YPnbOEj7b9z/85isP4Y9OPbnTpU5o7WocZOYmYFP1entErANmAfOBE6rdlgE3AmeNNFbkCKkeERcAF2bmLcO8d0lmvquu2F+bcUj3NUzUcY89dF2nS1AXmjLzN3b5QTTvOugPR505l2y4YlTfFxFzgJuBI4GHM3OfansA2362vjMjzmgzc9EI79WGrCSNt7GcdTD0wH2lLzP7dthnBvAl4COZ+eRgtlbflZkRUfuFnt4lqVH6xxC0Vaj27ez9iJjCYMhenJlfrjZviYjezNwUEb3A1rrv8YIFSY2SY/hvJFVb4AJgXWb++5C3rgIWVq8XAivranJGK6lR2njF1/HAe4C7I+LOatvHgSXAiohYBGwATq8byKCV1CgjHeAf4zi3MHiG1XDmjWUsg1ZSo3ibREkqrBsvwTVoJTWKM1pJKqxdPdp2MmglNYoPZ5Skwhp1P1pJ6kb2aCWpsIHsvuaBQSupUWwdSFJho7ih97gzaCU1SvfFrEErqWE8GCZJhRm0klSYZx1IUmGedSBJhXmvA0kqzB6tJBXmjFaSChvowvt3+RRcSY3Syhz1UicilkbE1oi4Z8i2/SLiuoh4oPq5b904Bq2kRmnX48YrFwGn7LDtbGBVZs4FVlXrIzJoJTVKO2e0mXkz8JMdNs8HllWvlwEL6sYxaCU1ylhmtBGxOCLWDFkWj+IrejJzU/V6M9BT9wEPhklqlLHcvSsz+4C+F/tdmZkRUfuFBq2kRhmHS3C3RERvZm6KiF5ga90HbB1IapQ2HwwbzlXAwur1QmBl3Qec0UpqlGzjjDYilgMnADMj4hHgHGAJsCIiFgEbgNPrxjFoJTVKOy/Bzcwzd/LWvLGMY9BKahQvwZWkwrypjCQVNtDqvnsdGLSSGsUbf0tSYfZoJakwe7SSVJgzWkkqzINhklSYrQNJKszWgSQVNpbbJI4Xg1ZSo3gerSQV5oxWkgprlb/x95gZtJIaxYNhklSYQStJhXVfzEJ0Y/o3VUQsrp66Kf2cfxfN58MZx9donhmv3Y9/Fw1n0EpSYQatJBVm0I4v+3Aajn8XDefBMEkqzBmtJBVm0EpSYQbtOImIUyLi/oh4MCLO7nQ96ryIWBoRWyPink7XorIM2nEQEZOA/wLeBhwBnBkRR3S2KnWBi4BTOl2EyjNox8exwIOZuT4znwcuBeZ3uCZ1WGbeDPyk03WoPIN2fMwCfjRk/ZFqm6TdgEErSYUZtONjI/CKIeuzq22SdgMG7fi4DZgbEQdHxFTgDOCqDtckaZwYtOMgM/uBDwJfB9YBKzJzbWerUqdFxHLgO8BhEfFIRCzqdE0qw0twJakwZ7SSVJhBK0mFGbSSVJhBK0mFGbSSVJhBK0mFGbSSVNj/A7+pdf1z4Gz9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnGoCG7CIIx1"
      },
      "source": [
        "# SVM model(rbf) On REDUCED PCA Training Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hTMd7DAZA7v",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:50:05.134133Z",
          "iopub.execute_input": "2021-08-31T19:50:05.134558Z",
          "iopub.status.idle": "2021-08-31T19:50:05.635926Z",
          "shell.execute_reply.started": "2021-08-31T19:50:05.134520Z",
          "shell.execute_reply": "2021-08-31T19:50:05.635117Z"
        },
        "trusted": true,
        "outputId": "4f004f47-545e-4e3a-d3c5-00cfeec7eb8a"
      },
      "source": [
        "#Import svm model On REDUCED PCA Training Features\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='rbf') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(Train_Features_Reduced_PCA, train_labels)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(Test_Features_Reduced_PCA)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, y_pred))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy =  0.98\n",
          "output_type": "stream"
        },
        {
          "execution_count": 88,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofAYlD4VaGm0"
      },
      "source": [
        "# SVM on ALL Training Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-XXGmYcZbch",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:50:25.993617Z",
          "iopub.execute_input": "2021-08-31T19:50:25.993973Z",
          "iopub.status.idle": "2021-08-31T19:50:48.675326Z",
          "shell.execute_reply.started": "2021-08-31T19:50:25.993943Z",
          "shell.execute_reply": "2021-08-31T19:50:48.674546Z"
        },
        "trusted": true,
        "outputId": "0d534df2-c259-4a93-eeda-2b75028e774b"
      },
      "source": [
        "\n",
        "\n",
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='poly') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_for_training, train_labels)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test_features)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, y_pred))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy =  0.8866666666666667\n",
          "output_type": "stream"
        },
        {
          "execution_count": 89,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAATsUlEQVR4nO3de5BcZZnH8e8zCeESZSFcxpCwAhJlZdW4QoAVrxHFG8FVU4ArWTblqMUdVsErpaW7KC6ILH84yiVbcosIm4AXxIjglhqJmhVIcLmHhIQQSBAQSWb62T9ywNkwzOlJ+kz3nHw/1FvpPqf77afK1C+v73nPeyIzkSRVp6vdBUhS3Rm0klQxg1aSKmbQSlLFDFpJqtjYqn/g/qmHuaxBz3PiY9u2uwR1oOuWXR9b2seGNfc2nTnb7LrPFv9eMyoPWkkaUY3+dlfwPAatpHrJRrsreB6DVlK9NAxaSapUOqKVpIr197W7gucxaCXVixfDJKliTh1IUsW8GCZJ1erEi2HegiupXhqN5luJiDg1Iu6IiNsj4oqI2C4i9o6IhRFxd0RcFRHjyvoxaCXVS/+G5tsQImIScBJwQGb+LTAGOAr4CnBeZu4LrAVml5Vk0Eqql2w038qNBbaPiLHADsBK4K3A1cX5OcCRZZ0YtJLqZRhTBxHRExGLBrSeZ7vJzBXA14BlbAzYx4HfAOsy89nFusuBSWUleTFMUr0M42JYZvYCvYOdi4idgRnA3sA64LvA4ZtTkkErqV5at7zrbcB9mfkIQERcA7we2Ckixhaj2snAirKOnDqQVCvZ2NB0K7EMODgidoiIAKYDS4CbgA8Un5kFzCvryKCVVC8tWt6VmQvZeNHrt8BtbMzLXuAM4LSIuBvYBbiorCSnDiTVSwtvWMjMs4CzNjl8LzBtOP0YtJLqxU1lJKliHXgLrkErqV7cVEaSKubG35JUMUe0klStTC+GSVK1HNFKUsVcdSBJFXNEK0kVc9WBJFXMqQNJqphTB5JUMYNWkirm1IEkVcyLYZJUMacOJKliHTh14KNsJNVLix5lExGviIjFA9ofI+KUiJgQETdGxF3FnzuXlWTQSqqX1j0z7A+ZOTUzpwKvA/4EXAucCSzIzCnAguL9kAxaSfWS2Xxr3nTgnsx8AJgBzCmOzwGOLPuyc7SS6qWv+VUHEdED9Aw41JuZvYN89CjgiuJ1d2auLF6vArrLfseglVQvw7gYVoTqYMH6nIgYBxwBfGqQ72dElA6NDVpJ9dL65V3vBH6bmQ8X7x+OiImZuTIiJgKryzpwjlZSvbR+jvZo/jJtADAfmFW8ngXMK+vAEa2kemnhiDYixgOHAR8dcPhsYG5EzAYeAGaW9WPQSqqXFgZtZj4F7LLJsUfZuAqhaQatpFrJfh/OKEnVcq8DSapYB+51YNBKqpfGsO74GhEGraR6cepAkirmxbCtTFcXEy+/kP7Va1h90ufYbtpr2fnUjxBdXTT+9DRrPn8OfQ8+1O4qNYJOOudkDpx+II8/+jgnHHY8AJ+88JNM2mcyAON3HM9Tf3yKk995UjvLHN0c0W5ddjzmfWy4bxld43cAYJfPnMTqU85iw33LePHM97LTRz7Ems+f0+YqNZIWfPcnfH/O9Zx63mnPHfvq8V997vU/f3Y2f3riqXaUVh8dOEdbegtuROwXEWdExDeKdkZE/M1IFDeajdl9V7Z/w0E8ec0P/3IwkyhCt+tF4+l75NE2Vad2uePXd/DEuide8Pyh7zmUm+fdMoIV1VA2mm8jZMgRbUScwcb7fK8Efl0cngxcERFXZubZFdc3ak34xMdZ+/Vv0TV+++eOrfnCuXT/x5fJZ56h8eSfWHms//dQf7H/tP1Zt2YdK+93OmmLjMIR7WzgwMw8OzO/U7SzgWnFuUFFRE9ELIqIRZc/uryV9Y4K27/hIPrXrmP90rv+3/Ed//H9PHzCZ1j+jmN4cv4NTDj9Y22qUJ3ojTPexC2OZrdYNhpNt5FSNkfbAPZg48YJA00szg1q4B6P9089rPP+eanYtlP3Z4c3HcIOh04jxo0jxu/A7hd8iW322pP1t98JwFM3/IzuC/+tzZWqU3SN6eKQww/h1Hef0u5SRr9RuOrgFGBBRNwFPFgc+2tgX+CECusa1dZdcDHrLrgYgO0OeDU7HvtBVp96Fnv+ZC5j/3oSfctWsP3Br2PDfcvaXKk6xdRDp7LinuU8usp5+y3WgVMHQwZtZv4oIl7OxqmCScXhFcCtmdl5/2x0sv4Gj37xPHb/97Og0aDxxJOsOetr7a5KI+xfLvgErzrkVey4845csvBSLj/3Mm686kbeeMQbuXm+0wYt0YHLuyKH94CyYdsapw5U7sTHtm13CepA1y27Pra0j6c+f1TTmTP+i1du8e81w3W0kuqlAzeV8VE2kuqlkc23EhGxU0RcHRF3RsTSiDgkIiZExI0RcVfx585l/Ri0kmol+/qbbk04H/hRZu4HvAZYCpwJLMjMKcCC4v2QDFpJ9dKiEW1E/BXwRuAigMxcn5nrgBnAnOJjc4Ajy0oyaCXVyzBuwR14c1XRegb0tDfwCHBJRPwuIr5dPKyxOzNXFp9ZBXSXleTFMEn1Mox1tANvrhrEWODvgBMzc2FEnM8m0wSZmRFR+oOOaCXVSjay6VZiObA8MxcW769mY/A+HBETAYo/V5d1ZNBKqpe+/ubbEDJzFfBgRLyiODQdWALMB2YVx2YB88pKcupAUr209hbcE4HLImIccC9wHBsHqHMjYjYb94GZWdaJQSupXloYtJm5GDhgkFPTh9OPQSupVqreVmBzGLSS6mW07d4lSaOOQStJ1cq+zttUxqCVVC+dl7MGraR6aeJGhBFn0EqqF4NWkirm1IEkVcupA0mqWPYZtJJULacOJKlaHfhsRoNWUs0YtJJULUe0klSx7Gt3Bc9n0EqqFUe0klQxg1aSqpbRsq4i4n7gCaAf6MvMAyJiAnAVsBdwPzAzM9cO1Y8PZ5RUK9lovjXpLZk5NTOffaTNmcCCzJwCLGCTR5APxqCVVCvZiKbbZpoBzClezwGOLPuCQSupVhr90XSLiJ6IWDSg9WzSXQI/jojfDDjXnZkri9ergO6ympyjlVQrw7kYlpm9QO8QHzk0M1dExO7AjRFx5ybfz4go3VzBoJVUK1swJfD8vjJXFH+ujohrgWnAwxExMTNXRsREYHVZP04dSKqVzObbUCJifES8+NnXwNuB24H5wKziY7OAeWU1OaKVVCstHNF2A9dGBGzMyssz80cRcSswNyJmAw8AM8s6Mmgl1UqjvzVBm5n3Aq8Z5PijwPTh9GXQSqqVVs7RtopBK6lWsoV3hrWKQSupVtzrQJIq1nBEK0nVcupAkirWqlUHrWTQSqoVVx1IUsWco5WkijlHK0kVK9vDoB0MWkm14tSBJFWs4cUwSarWVjmi3XfJkqp/QqPQ0w/9vN0lqKa8GCZJFdsqR7SSNJI6cNGBj7KRVC/9ja6mWzMiYkxE/C4iri/e7x0RCyPi7oi4KiLGlfVh0EqqlcYwWpNOBpYOeP8V4LzM3BdYC8wu68CglVQrSTTdykTEZODdwLeL9wG8Fbi6+Mgc4MiyfgxaSbXSyOZbRPRExKIBrWeT7r4OfJK/DIB3AdZlZl/xfjkwqawmL4ZJqpVGEyPVZ2VmL9A72LmIeA+wOjN/ExFv3pKaDFpJtdLMlECTXg8cERHvArYDdgTOB3aKiLHFqHYysKKsI6cOJNVKP9F0G0pmfiozJ2fmXsBRwE8z80PATcAHio/NAuaV1WTQSqqVClYdbOoM4LSIuJuNc7YXlX3BqQNJtVLFQ3Az82fAz4rX9wLThvN9g1ZSrbRwjrZlDFpJtdKBuyQatJLqZTjLu0aKQSupVvrbXcAgDFpJtdIIR7SSVKlO3CbRoJVUK1Us79pSBq2kWnHVgSRVrOzW2nYwaCXViiNaSaqYc7SSVDFXHUhSxZw6kKSKOXUgSRXrd0QrSdVyRCtJFevEoPVRNpJqJYfRhhIR20XEryPifyLijoj4QnF874hYGBF3R8RVETGurCaDVlKtNKL5VuIZ4K2Z+RpgKnB4RBwMfAU4LzP3BdYCs8s6Mmgl1UqrHs6YGz1ZvN2maAm8Fbi6OD4HOLKsJoNWUq30D6NFRE9ELBrQegb2FRFjImIxsBq4EbgHWJeZfcVHlgOTymryYpikWhnODQuZ2Qv0DnG+H5gaETsB1wL7bU5NBq2kWqnocePrIuIm4BBgp4gYW4xqJwMryr7v1IGkWmnhqoPdipEsEbE9cBiwFLgJ+EDxsVnAvLKaHNFKqpVG67aVmQjMiYgxbByUzs3M6yNiCXBlRHwJ+B1wUVlHBq2kWmnVU3Az8/fAawc5fi8wbTh9GbSSaqUT7wwzaCXVitskSlLFWjhH2zIGraRa6byYNWgl1YxztJJUsf4OHNMatJJqxRGtJFXMi2GSVLHOi1mDVlLNOHUgSRXzYpgkVcw52q3YO97+Zs4994uM6eri4kuu4KvnXNjuktQG/3nltXzvuh8REUx52V586dOn8cVzLmDR4tt40fjxAHz5M6ex38tf1uZKR6/Oi1mDdkR0dXXxjfO/zOHvOprly1fyq1/+gOuu/zFLl97V7tI0gh5+ZA2XXT2PeZd9k+223ZbTP/ev/PAnNwNw+vGzeftb3tDmCuuhE0e0bvw9AqYd+Fruued+7rtvGRs2bGDu3Hkc8d53tLsstUFffz/PPLOevr5+nv7zM+y264R2l1Q7rXo4YysZtCNgj0kv4cHlDz33fvmKleyxx0vaWJHaoXu3Xfmno9/P2/7hWN4y4xhePH4HXn/Q6wD4xjfn8L5jP85Xzv8m69evb3Olo1sO47+RstlBGxHHDXHuuSdLNhpPbe5PSLXy+B+f4Kaf/4obvnsJP513GU//+Rmuu+GnnPKx47juim9x1bfP5/E/PsFF3/luu0sd1frJpttQImLPiLgpIpZExB0RcXJxfEJE3BgRdxV/7lxW05aMaL/wQicyszczD8jMA7q6xm/BT9TDQytWsefkPZ57P3nSRB56aFUbK1I7/GrRYibt0c2EnXdim7Fjmf6mv2fxbUvYbdcJRATjxo3jyHe/nduW/m+7Sx3VWjh10AecnpmvBA4Gjo+IVwJnAgsycwqwoHg/pCEvhkXE71/oFNBdXqcAbl20mH333Zu99tqTFStWMXPmDD587PHtLksjbGL3bvz+9jt5+s9/Zrttt2XhosXsv98UHlnzGLvtOoHM5Ke3/IIp+7y03aWOao1szZRAZq4EVhavn4iIpcAkYAbw5uJjc4CfAWcM1VfZqoNu4B3A2k2OB/CL4RS9Nevv7+fkUz7LD75/OWO6urh0zlUsWeKoZWvz6v3347C3HMrM405kzJgx7Pfyl/HBGe/kY6d/nrXrHiczecWUfTjrEye2u9RRrYqZ14jYi43PD1sIdBchDLCKJgadkUOkf0RcBFySmf89yLnLM/OYsh8YO25S5621UNs9/dDP212COtA2u+6zxQ+iOeal72s6c65Y9l8fBXoGHOrNzN6Bn4mIFwE3A1/OzGsiYl1m7jTg/NrMHHKedsgRbWbOHuJcachK0kgbzmqCIlR7X+h8RGwDfA+4LDOvKQ4/HBETM3NlREwEVpf9jsu7JNVKH9l0G0pEBHARsDQzzx1waj4wq3g9C5hXVpN3hkmqlRauj3098GHgtohYXBz7NHA2MDciZgMPADPLOjJoJdVKq+74Kq5NvdCc8fTh9GXQSqqVoS7wt4tBK6lWOnFTGYNWUq248bckVcwRrSRVzDlaSaqYD2eUpIqN5D6zzTJoJdWKc7SSVLH+7LzJA4NWUq04dSBJFWvVxt+tZNBKqpXOi1mDVlLNeDFMkipm0EpSxVx1IEkVc9WBJFWsE/c68JlhkmqlQTbdykTExRGxOiJuH3BsQkTcGBF3FX8O+QRcMGgl1UxmNt2acClw+CbHzgQWZOYUYEHxfkgGraRa6afRdCuTmbcAj21yeAYwp3g9BziyrB/naCXVynDuDIuIHqBnwKHezOwt+Vp3Zq4sXq8Cust+x6CVVCvDWXVQhGpZsA71/YyI0h80aCXVygjsdfBwREzMzJURMRFYXfYF52gl1UoO47/NNB+YVbyeBcwr+4IjWkm10soRbURcAbwZ2DUilgNnAWcDcyNiNvAAMLOsH4NWUq208hbczDz6BU5NH04/Bq2kWvEWXEmqWLqpjCRVy20SJalinbipjEErqVYc0UpSxfobztFKUqVcdSBJFXOOVpIq5hytJFXMEa0kVcyLYZJUMacOJKliTh1IUsVGYOPvYTNoJdWK62glqWKOaCWpYo0O3CbRZ4ZJqpXMbLqViYjDI+IPEXF3RJy5uTU5opVUK61adRARY4ALgcOA5cCtETE/M5cMty9HtJJqJYfRSkwD7s7MezNzPXAlMGNzaqp8RNu3fkVU/RujRUT0ZGZvu+tQZ/HvRWsNJ3MiogfoGXCod8D/FpOABwecWw4ctDk1OaIdWT3lH9FWyL8XbZKZvZl5wIBWyT94Bq0kDW4FsOeA95OLY8Nm0ErS4G4FpkTE3hExDjgKmL85HbnqYGQ5D6fB+PeiA2VmX0ScANwAjAEuzsw7Nqev6MQNGCSpTpw6kKSKGbSSVDGDdoS06lY+1UdEXBwRqyPi9nbXomoZtCNgwK187wReCRwdEa9sb1XqAJcCh7e7CFXPoB0ZLbuVT/WRmbcAj7W7DlXPoB0Zg93KN6lNtUgaYQatJFXMoB0ZLbuVT9LoY9COjJbdyidp9DFoR0Bm9gHP3sq3FJi7ubfyqT4i4grgl8ArImJ5RMxud02qhrfgSlLFHNFKUsUMWkmqmEErSRUzaCWpYgatJFXMoJWkihm0klSx/wM+IGqv4oZVjAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPXgqVl3a1A_"
      },
      "source": [
        "# XGBoost on Reduced  Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fR_bmyyXxrH",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:50:48.676809Z",
          "iopub.execute_input": "2021-08-31T19:50:48.677160Z",
          "iopub.status.idle": "2021-08-31T19:50:49.705853Z",
          "shell.execute_reply.started": "2021-08-31T19:50:48.677124Z",
          "shell.execute_reply": "2021-08-31T19:50:49.705046Z"
        },
        "trusted": true,
        "outputId": "37afc3a9-6cb6-45a7-e5b4-2773a941a6ca"
      },
      "source": [
        "#XGBOOST after PCA\n",
        "\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(Train_Features_Reduced_PCA, train_labels) #For sklearn no one hot encoding\n",
        "\n",
        "\n",
        "#Now predict using the trained XGBOOST model. \n",
        "prediction = model.predict(Test_Features_Reduced_PCA)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[19:50:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nAccuracy =  0.98\n",
          "output_type": "stream"
        },
        {
          "execution_count": 90,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkKi1La9IIx4"
      },
      "source": [
        "# Random Forest on Reduced Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHEvFhhjUELF",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:51:00.412761Z",
          "iopub.execute_input": "2021-08-31T19:51:00.413114Z",
          "iopub.status.idle": "2021-08-31T19:51:00.872876Z",
          "shell.execute_reply.started": "2021-08-31T19:51:00.413084Z",
          "shell.execute_reply": "2021-08-31T19:51:00.872059Z"
        },
        "trusted": true,
        "outputId": "aa0a910f-4fbf-4bb7-b611-2702c766b16c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Now predict using the trained RF model.\n",
        "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "RF_model.fit(Train_Features_Reduced_PCA, train_labels) #For sklearn no one hot encoding\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = RF_model.predict(Test_Features_Reduced_PCA)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, y_pred))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy =  0.98\n",
          "output_type": "stream"
        },
        {
          "execution_count": 91,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ki5K9FnoPb"
      },
      "source": [
        "# XGBoost on All training Features extracted\n",
        "## Predicting on Training Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fhf5OjPUZUv",
        "execution": {
          "iopub.status.busy": "2021-08-31T18:31:33.369030Z",
          "iopub.status.idle": "2021-08-31T18:31:33.369615Z"
        },
        "trusted": true
      },
      "source": [
        "#Now predict using the trained  \n",
        "\n",
        "#XGBOOST\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_for_training, train_labels) #For sklearn no one hot encoding\n",
        "\n",
        "train_prediction = model.predict(X_for_training)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(train_labels, train_prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(train_labels, train_prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwEqpH4JIIx6"
      },
      "source": [
        "## XGBOOST Predicting on Test Data (For ALL Features Extracted)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9pXmxs0lpvx",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:51:33.426488Z",
          "iopub.execute_input": "2021-08-31T19:51:33.426845Z",
          "iopub.status.idle": "2021-08-31T19:52:44.268514Z",
          "shell.execute_reply.started": "2021-08-31T19:51:33.426809Z",
          "shell.execute_reply": "2021-08-31T19:52:44.267763Z"
        },
        "trusted": true,
        "outputId": "a496d63a-a6c1-40ec-dced-ca5595367700"
      },
      "source": [
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_for_training, train_labels) #For sklearn no one hot encoding\n",
        "#Now predict using the trained RF model. \n",
        "prediction = model.predict(X_test_features)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[19:51:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nAccuracy =  0.96\n",
          "output_type": "stream"
        },
        {
          "execution_count": 92,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM5BLIowmsqx"
      },
      "source": [
        "## Random Forest Predicting on Test Data (For ALL Features Extracted)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoOlztuRmcH2",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:52:44.269959Z",
          "iopub.execute_input": "2021-08-31T19:52:44.270311Z",
          "iopub.status.idle": "2021-08-31T19:52:44.838825Z",
          "shell.execute_reply.started": "2021-08-31T19:52:44.270273Z",
          "shell.execute_reply": "2021-08-31T19:52:44.837816Z"
        },
        "trusted": true,
        "outputId": "8fbd6c9f-9b82-4afa-a23e-fb5f84d15ca7"
      },
      "source": [
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "RF_model.fit(X_for_training, train_labels) #For sklearn no one hot encoding\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 93,
          "output_type": "execute_result",
          "data": {
            "text/plain": "RandomForestClassifier(n_estimators=50, random_state=42)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqYRUnnGm8o0",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:52:44.840705Z",
          "iopub.execute_input": "2021-08-31T19:52:44.841092Z",
          "iopub.status.idle": "2021-08-31T19:52:45.073639Z",
          "shell.execute_reply.started": "2021-08-31T19:52:44.841053Z",
          "shell.execute_reply": "2021-08-31T19:52:45.072876Z"
        },
        "trusted": true,
        "outputId": "2ee0e465-3558-4b5b-a0ff-91a7fcb4ee32"
      },
      "source": [
        "\n",
        "#Now predict using the trained RF model. \n",
        "RF_model_prediction = RF_model.predict(X_test_features)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, RF_model_prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "RF_model_prediction_Confusion_Matrix = confusion_matrix(test_labels, RF_model_prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(RF_model_prediction_Confusion_Matrix, annot=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy =  0.9733333333333334\n",
          "output_type": "stream"
        },
        {
          "execution_count": 94,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJfFooLdBnSN",
        "execution": {
          "iopub.status.busy": "2021-08-31T21:00:12.828856Z",
          "iopub.execute_input": "2021-08-31T21:00:12.829250Z",
          "iopub.status.idle": "2021-08-31T21:00:12.840029Z",
          "shell.execute_reply.started": "2021-08-31T21:00:12.829217Z",
          "shell.execute_reply": "2021-08-31T21:00:12.838898Z"
        },
        "trusted": true
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import scipy.stats # for creating a simple dataset \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply ,  Dense, Conv2D, Activation, Flatten\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "#import keras.backend as K\n",
        "from keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add,average,concatenate , Conv2DTranspose\n",
        "from keras.layers.core import Lambda\n",
        "#from keras.optimizers import *\n",
        "from keras.losses import binary_crossentropy\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "#import keras.backend.tensorflow_backend as K\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import cv2\n",
        "import warnings\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgO6FgySTWXW"
      },
      "source": [
        "# ****##Model 1:****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzQIPrZBAYkd",
        "execution": {
          "iopub.status.busy": "2021-08-31T19:55:03.602398Z",
          "iopub.execute_input": "2021-08-31T19:55:03.602770Z",
          "iopub.status.idle": "2021-08-31T20:01:23.843758Z",
          "shell.execute_reply.started": "2021-08-31T19:55:03.602716Z",
          "shell.execute_reply": "2021-08-31T20:01:23.842912Z"
        },
        "trusted": true,
        "outputId": "e3204884-0f4d-4fa4-b760-10b861dca8b4"
      },
      "source": [
        "\n",
        "model1 = Sequential()\n",
        "\n",
        "# First Conv block\n",
        "model1.add(Conv2D(16 , (3,3) , padding = 'same' , activation = 'relu' , input_shape = (256,256,3)))\n",
        "model1.add(Conv2D(16 , (3,3), padding = 'same' , activation = 'relu'))\n",
        "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
        "#model1.add(Dropout(0.2))\n",
        "\n",
        "# Second Conv block\n",
        "model1.add(SeparableConv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
        "model1.add(SeparableConv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "# Third Conv block\n",
        "model1.add(SeparableConv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
        "model1.add(SeparableConv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# FC layer \n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(units = 512 , activation = 'relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(units = 128 , activation = 'relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(units = 64 , activation = 'relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model1.add(Dense(units = 1 , activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "# Compile\n",
        "model1.compile(optimizer = \"adam\" , loss = 'binary_crossentropy' , metrics = ['accuracy',precision,recall])\n",
        "model1.summary()\n",
        "\n",
        "# Implement callbacks \n",
        "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3, verbose = 1, mode='min', restore_best_weights = True)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=5, verbose = 1, mode='min', restore_best_weights = True)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "    monitor = 'val_accuracy', \n",
        "    patience = 3, \n",
        "    verbose = 1, \n",
        "    factor = 0.3, \n",
        "    min_lr = 0.000001\n",
        "    )\n",
        "\n",
        "\n",
        "model_checkpoint1 = keras.callbacks.ModelCheckpoint('Model_Weights1.hdf5', monitor='val_loss',verbose=1, mode='min',save_best_only=True)\n",
        "csv_logger = CSVLogger('training_model_metrics_values.log', append=True, separator=';')\n",
        "\n",
        "# Implement callbacks \n",
        "#checkpoint = ModelCheckpoint(filepath='best_model.hdf5', save_best_only=True, save_weights_only=False)\n",
        "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3, verbose = 1, mode='min', restore_best_weights = True)\n",
        "\n",
        "\n",
        "# Train\n",
        "history1 = model1.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 30, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger  ,  learning_rate_reduction ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_98 (Conv2D)           (None, 256, 256, 16)      448       \n_________________________________________________________________\nconv2d_99 (Conv2D)           (None, 256, 256, 16)      2320      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 128, 128, 16)      0         \n_________________________________________________________________\nseparable_conv2d (SeparableC (None, 128, 128, 32)      688       \n_________________________________________________________________\nseparable_conv2d_1 (Separabl (None, 128, 128, 32)      1344      \n_________________________________________________________________\nbatch_normalization_98 (Batc (None, 128, 128, 32)      128       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 64, 64, 32)        0         \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 64, 64, 32)        0         \n_________________________________________________________________\nseparable_conv2d_2 (Separabl (None, 64, 64, 64)        2400      \n_________________________________________________________________\nseparable_conv2d_3 (Separabl (None, 64, 64, 64)        4736      \n_________________________________________________________________\nbatch_normalization_99 (Batc (None, 64, 64, 64)        256       \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 32, 32, 64)        0         \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 32, 32, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 65536)             0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 512)               33554944  \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_21 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_22 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_23 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 33,641,249\nTrainable params: 33,641,057\nNon-trainable params: 192\n_________________________________________________________________\nEpoch 1/30\n600/600 [==============================] - 14s 21ms/step - loss: 0.5254 - accuracy: 0.7568 - precision: 0.7075 - recall: 0.7713 - val_loss: 0.7370 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00001: val_loss improved from inf to 0.73696, saving model to Model_Weights1.hdf5\nEpoch 2/30\n600/600 [==============================] - 13s 21ms/step - loss: 0.3854 - accuracy: 0.8575 - precision: 0.7615 - recall: 0.7979 - val_loss: 1.0507 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00002: val_loss did not improve from 0.73696\nEpoch 3/30\n600/600 [==============================] - 13s 21ms/step - loss: 0.2560 - accuracy: 0.9183 - precision: 0.8088 - recall: 0.8236 - val_loss: 0.1919 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00003: val_loss improved from 0.73696 to 0.19192, saving model to Model_Weights1.hdf5\nEpoch 4/30\n600/600 [==============================] - 13s 21ms/step - loss: 0.1872 - accuracy: 0.9434 - precision: 0.8382 - recall: 0.8642 - val_loss: 3.1866 - val_accuracy: 0.6600 - val_precision: 0.6600 - val_recall: 0.8800\n\nEpoch 00004: val_loss did not improve from 0.19192\nEpoch 5/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.2095 - accuracy: 0.9140 - precision: 0.8096 - recall: 0.8533 - val_loss: 2.9499 - val_accuracy: 0.7400 - val_precision: 0.6267 - val_recall: 0.5333\n\nEpoch 00005: val_loss did not improve from 0.19192\nEpoch 6/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.1719 - accuracy: 0.9404 - precision: 0.8658 - recall: 0.8656 - val_loss: 0.2967 - val_accuracy: 0.9400 - val_precision: 0.8533 - val_recall: 0.8133\n\nEpoch 00006: val_loss did not improve from 0.19192\n\nEpoch 00006: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\nEpoch 7/30\n600/600 [==============================] - 13s 21ms/step - loss: 0.0514 - accuracy: 0.9887 - precision: 0.8081 - recall: 0.8075 - val_loss: 0.2180 - val_accuracy: 0.9867 - val_precision: 0.8800 - val_recall: 0.8733\n\nEpoch 00007: val_loss did not improve from 0.19192\nEpoch 8/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0119 - accuracy: 0.9926 - precision: 0.8586 - recall: 0.8615 - val_loss: 0.2426 - val_accuracy: 0.9667 - val_precision: 0.8600 - val_recall: 0.8800\n\nEpoch 00008: val_loss did not improve from 0.19192\nEpoch 9/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0064 - accuracy: 0.9978 - precision: 0.8644 - recall: 0.8644 - val_loss: 0.2853 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00009: val_loss did not improve from 0.19192\nEpoch 10/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0592 - accuracy: 0.9899 - precision: 0.8613 - recall: 0.8582 - val_loss: 0.2081 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00010: val_loss did not improve from 0.19192\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\nEpoch 11/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0021 - accuracy: 0.9997 - precision: 0.8493 - recall: 0.8489 - val_loss: 0.2285 - val_accuracy: 0.9733 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00011: val_loss did not improve from 0.19192\nEpoch 12/30\n600/600 [==============================] - 13s 21ms/step - loss: 0.0126 - accuracy: 0.9961 - precision: 0.8596 - recall: 0.8602 - val_loss: 0.2065 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00012: val_loss did not improve from 0.19192\nEpoch 13/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0016 - accuracy: 1.0000 - precision: 0.8603 - recall: 0.8603 - val_loss: 0.2143 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00013: val_loss did not improve from 0.19192\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\nEpoch 14/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 0.8361 - recall: 0.8361 - val_loss: 0.2180 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00014: val_loss did not improve from 0.19192\nEpoch 15/30\n600/600 [==============================] - 13s 21ms/step - loss: 5.1052e-04 - accuracy: 1.0000 - precision: 0.8319 - recall: 0.8319 - val_loss: 0.2253 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00015: val_loss did not improve from 0.19192\nEpoch 16/30\n600/600 [==============================] - 12s 21ms/step - loss: 4.1032e-04 - accuracy: 1.0000 - precision: 0.8651 - recall: 0.8651 - val_loss: 0.2299 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00016: val_loss did not improve from 0.19192\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\nEpoch 17/30\n600/600 [==============================] - 13s 21ms/step - loss: 0.0041 - accuracy: 0.9993 - precision: 0.8606 - recall: 0.8600 - val_loss: 0.2330 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00017: val_loss did not improve from 0.19192\nEpoch 18/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0084 - accuracy: 0.9989 - precision: 0.8675 - recall: 0.8686 - val_loss: 0.2352 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00018: val_loss did not improve from 0.19192\nEpoch 19/30\n600/600 [==============================] - 12s 21ms/step - loss: 5.1136e-04 - accuracy: 1.0000 - precision: 0.8538 - recall: 0.8538 - val_loss: 0.2355 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00019: val_loss did not improve from 0.19192\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\nEpoch 20/30\n600/600 [==============================] - 12s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 0.8485 - recall: 0.8484 - val_loss: 0.2358 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00020: val_loss did not improve from 0.19192\nEpoch 21/30\n600/600 [==============================] - 12s 21ms/step - loss: 3.7370e-04 - accuracy: 1.0000 - precision: 0.8562 - recall: 0.8562 - val_loss: 0.2371 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00021: val_loss did not improve from 0.19192\nEpoch 22/30\n600/600 [==============================] - 12s 21ms/step - loss: 5.0539e-04 - accuracy: 1.0000 - precision: 0.8814 - recall: 0.8814 - val_loss: 0.2392 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00022: val_loss did not improve from 0.19192\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 1e-06.\nEpoch 23/30\n600/600 [==============================] - 13s 21ms/step - loss: 5.6819e-04 - accuracy: 1.0000 - precision: 0.8731 - recall: 0.8731 - val_loss: 0.2389 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00023: val_loss did not improve from 0.19192\nEpoch 24/30\n600/600 [==============================] - 12s 21ms/step - loss: 5.2536e-04 - accuracy: 1.0000 - precision: 0.8217 - recall: 0.8217 - val_loss: 0.2410 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00024: val_loss did not improve from 0.19192\nEpoch 25/30\n600/600 [==============================] - 13s 21ms/step - loss: 8.4290e-04 - accuracy: 0.9995 - precision: 0.8605 - recall: 0.8600 - val_loss: 0.2410 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00025: val_loss did not improve from 0.19192\nEpoch 26/30\n600/600 [==============================] - 12s 20ms/step - loss: 6.1520e-04 - accuracy: 0.9997 - precision: 0.8362 - recall: 0.8366 - val_loss: 0.2413 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00026: val_loss did not improve from 0.19192\nEpoch 27/30\n600/600 [==============================] - 12s 21ms/step - loss: 4.8839e-04 - accuracy: 1.0000 - precision: 0.8593 - recall: 0.8593 - val_loss: 0.2422 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00027: val_loss did not improve from 0.19192\nEpoch 28/30\n600/600 [==============================] - 12s 21ms/step - loss: 2.8466e-04 - accuracy: 1.0000 - precision: 0.8769 - recall: 0.8769 - val_loss: 0.2427 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00028: val_loss did not improve from 0.19192\nEpoch 29/30\n600/600 [==============================] - 12s 21ms/step - loss: 7.5625e-04 - accuracy: 1.0000 - precision: 0.8707 - recall: 0.8707 - val_loss: 0.2435 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00029: val_loss did not improve from 0.19192\nEpoch 30/30\n600/600 [==============================] - 12s 21ms/step - loss: 1.3306e-04 - accuracy: 1.0000 - precision: 0.8493 - recall: 0.8493 - val_loss: 0.2437 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00030: val_loss did not improve from 0.19192\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:05:47.619945Z",
          "iopub.execute_input": "2021-08-31T20:05:47.620435Z",
          "iopub.status.idle": "2021-08-31T20:07:53.484665Z",
          "shell.execute_reply.started": "2021-08-31T20:05:47.620396Z",
          "shell.execute_reply": "2021-08-31T20:07:53.483562Z"
        },
        "trusted": true,
        "id": "rX8TwkBIIIyA",
        "outputId": "24e61315-d342-4fed-8037-d050154a7256"
      },
      "source": [
        "model_checkpoint1 = keras.callbacks.ModelCheckpoint('Model_Weights1.hdf5', monitor='val_accuracy',verbose=1, mode='max',save_best_only=True)\n",
        "\n",
        "# Train\n",
        "history1 = model1.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 10, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger   ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n600/600 [==============================] - 12s 21ms/step - loss: 0.1696 - accuracy: 0.9483 - precision: 0.8192 - recall: 0.8367 - val_loss: 0.1585 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00001: val_accuracy improved from -inf to 0.97333, saving model to Model_Weights1.hdf5\nEpoch 2/10\n600/600 [==============================] - 12s 20ms/step - loss: 0.1691 - accuracy: 0.9483 - precision: 0.8267 - recall: 0.8492 - val_loss: 0.1539 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00002: val_accuracy did not improve from 0.97333\nEpoch 3/10\n600/600 [==============================] - 12s 20ms/step - loss: 0.1718 - accuracy: 0.9475 - precision: 0.8317 - recall: 0.8542 - val_loss: 0.1484 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00003: val_accuracy improved from 0.97333 to 0.98000, saving model to Model_Weights1.hdf5\nEpoch 4/10\n600/600 [==============================] - 12s 21ms/step - loss: 0.1681 - accuracy: 0.9508 - precision: 0.8217 - recall: 0.8508 - val_loss: 0.1450 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00004: val_accuracy did not improve from 0.98000\nEpoch 5/10\n600/600 [==============================] - 12s 21ms/step - loss: 0.1683 - accuracy: 0.9500 - precision: 0.8150 - recall: 0.8408 - val_loss: 0.1427 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00005: val_accuracy did not improve from 0.98000\nEpoch 6/10\n600/600 [==============================] - 13s 21ms/step - loss: 0.1645 - accuracy: 0.9508 - precision: 0.8375 - recall: 0.8600 - val_loss: 0.1415 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00006: val_accuracy did not improve from 0.98000\nEpoch 7/10\n600/600 [==============================] - 12s 21ms/step - loss: 0.1594 - accuracy: 0.9583 - precision: 0.8375 - recall: 0.8592 - val_loss: 0.1368 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00007: val_accuracy did not improve from 0.98000\nEpoch 8/10\n600/600 [==============================] - 12s 21ms/step - loss: 0.1575 - accuracy: 0.9566 - precision: 0.8350 - recall: 0.8650 - val_loss: 0.1354 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00008: val_accuracy did not improve from 0.98000\nEpoch 9/10\n600/600 [==============================] - 12s 20ms/step - loss: 0.1464 - accuracy: 0.9566 - precision: 0.8500 - recall: 0.8658 - val_loss: 0.1349 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00009: val_accuracy did not improve from 0.98000\nEpoch 10/10\n600/600 [==============================] - 12s 20ms/step - loss: 0.1551 - accuracy: 0.9500 - precision: 0.8358 - recall: 0.8592 - val_loss: 0.1327 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00010: val_accuracy did not improve from 0.98000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j07qUHfHIIyA"
      },
      "source": [
        "### Accuracy of Model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw-Fzi7-KPsS",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:01:53.445015Z",
          "iopub.execute_input": "2021-08-31T20:01:53.445339Z",
          "iopub.status.idle": "2021-08-31T20:01:56.214132Z",
          "shell.execute_reply.started": "2021-08-31T20:01:53.445309Z",
          "shell.execute_reply": "2021-08-31T20:01:56.213275Z"
        },
        "trusted": true,
        "outputId": "9921432b-9ee8-4311-f68a-1e6316c9e3d8"
      },
      "source": [
        "#model1.load_weights(\"./Model_Weights1.hdf5\")\n",
        "print(\"Train_Accuracy\" )\n",
        "train_results = model1.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = model1.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "test_results = model1.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 1s 27ms/step - loss: 3.6036e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\nVal_Accuracy\n5/5 [==============================] - 0s 50ms/step - loss: 0.2437 - accuracy: 0.9800 - precision: 0.9818 - recall: 0.9923\nTest_Accuracy\n5/5 [==============================] - 0s 22ms/step - loss: 0.3861 - accuracy: 0.9667 - precision: 0.9533 - recall: 0.9895\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:09:03.236445Z",
          "iopub.execute_input": "2021-08-31T20:09:03.236775Z",
          "iopub.status.idle": "2021-08-31T20:09:05.545553Z",
          "shell.execute_reply.started": "2021-08-31T20:09:03.236745Z",
          "shell.execute_reply": "2021-08-31T20:09:05.544769Z"
        },
        "trusted": true,
        "id": "bZoIiA1SIIyB",
        "outputId": "1a31ee3d-ffd4-4a92-bbec-b236be9220a2"
      },
      "source": [
        "model1.load_weights(\"./Model_Weights1.hdf5\")\n",
        "print(\"Train_Accuracy\" )\n",
        "train_results = model1.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = model1.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "test_results = model1.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 1s 23ms/step - loss: 0.1565 - accuracy: 0.9591 - precision: 0.9426 - recall: 0.9960\nVal_Accuracy\n5/5 [==============================] - 0s 21ms/step - loss: 0.1484 - accuracy: 0.9800 - precision: 0.9818 - recall: 0.9923\nTest_Accuracy\n5/5 [==============================] - 0s 20ms/step - loss: 0.1686 - accuracy: 0.9533 - precision: 0.9222 - recall: 1.0000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4prtxJ0IIyC"
      },
      "source": [
        "## Predication of Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilYvZF5xKW8d",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:10:36.135383Z",
          "iopub.execute_input": "2021-08-31T20:10:36.135715Z",
          "iopub.status.idle": "2021-08-31T20:10:36.470231Z",
          "shell.execute_reply.started": "2021-08-31T20:10:36.135683Z",
          "shell.execute_reply": "2021-08-31T20:10:36.469409Z"
        },
        "trusted": true,
        "outputId": "b2898d43-490e-401a-ca15-de15b2407985"
      },
      "source": [
        "model1_pred = model1.predict(test_images)\n",
        "pred = [1 if x > 0.5 else 0 for x in list(model1_pred[: , 0])]\n",
        "model1_pred = np.array(pred)\n",
        "model1_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 103,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVn_Vjy-IIyD"
      },
      "source": [
        "## Loss and Accuracy at each Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2s6yqo7AFpG"
      },
      "source": [
        "# **MODEL_2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnbWRezxHc3s",
        "execution": {
          "iopub.status.busy": "2021-08-31T21:00:33.188385Z",
          "iopub.execute_input": "2021-08-31T21:00:33.188909Z",
          "iopub.status.idle": "2021-08-31T21:00:33.635334Z",
          "shell.execute_reply.started": "2021-08-31T21:00:33.188766Z",
          "shell.execute_reply": "2021-08-31T21:00:33.634530Z"
        },
        "trusted": true,
        "outputId": "6014ab75-a6ec-4ed6-b4df-ce910a218a04"
      },
      "source": [
        "## Res2Net Model with Regularizers\n",
        "IMG_SIZE = 256\n",
        "h_heuns_method=0.5\n",
        "\n",
        "def res_block(x, nb_filters, strides):\n",
        "    res_path = BatchNormalization()(x)\n",
        "    res_path = Activation(activation='relu')(res_path)\n",
        "    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0]  )(res_path)\n",
        "\n",
        "    #res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0] , kernel_regularizer=l2(0.01) )(res_path)\n",
        "\n",
        "    res_path = BatchNormalization()(res_path)\n",
        "    res_path = Activation(activation='relu')(res_path)\n",
        "    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1] )(res_path)\n",
        "\n",
        "    #res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1], kernel_regularizer=l2(0.01) )(res_path)\n",
        "    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n",
        "    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0]  )(x)\n",
        "\n",
        "    #shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0] , kernel_regularizer=l2(0.01) )(x)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    res_path = add([shortcut, hpath])#suma corta\n",
        "    return res_path\n",
        "\n",
        "def res_block2(x,y,nb_filters, strides):\n",
        "    res_path = BatchNormalization()(x)\n",
        "    res_path = Activation(activation='relu')(res_path)\n",
        "    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0] )(res_path)\n",
        "    #res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0] , kernel_regularizer=l2(0.01) )(res_path)\n",
        "    res_path = BatchNormalization()(res_path)\n",
        "    res_path = Activation(activation='relu')(res_path)\n",
        "    #res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1] , kernel_regularizer=l2(0.01) )(res_path)\n",
        "    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1]  )(res_path)\n",
        "\n",
        "    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n",
        "    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0]  )(x)\n",
        "\n",
        "    #shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0] , kernel_regularizer=l2(0.01) )(x)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    res_path = add([shortcut, hpath])#suma corta\n",
        "\n",
        "    res_path = average([y, res_path])#suma doble \n",
        "    return res_path\n",
        "\n",
        "\n",
        "def encoder(x):\n",
        "    features_extracted = []\n",
        "\n",
        "    #main_path = Conv2D(filters= 64, kernel_size=(3, 3), padding='same', strides=(1, 1) , kernel_regularizer=l2(0.01) )(x)\n",
        "    main_path = Conv2D(filters= 64, kernel_size=(3, 3), padding='same', strides=(1, 1) )(x)\n",
        "    main_path = BatchNormalization()(main_path)\n",
        "    main_path = Activation(activation='relu')(main_path)\n",
        "    \n",
        "    #main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1) , kernel_regularizer=l2(0.01) )(main_path)\n",
        "    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1) )(main_path)\n",
        "    hpath = Lambda(lambda x: x * h_heuns_method)(main_path)\n",
        "    shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1)  )(x)\n",
        "\n",
        "    #shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1) , kernel_regularizer=l2(0.01) )(x)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    main_path = add([shortcut, hpath])#suma corta\n",
        "\n",
        "    features_extracted.append(main_path)\n",
        "\n",
        "\n",
        "    s1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2) )(x)\n",
        "    #s1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2) , kernel_regularizer=l2(0.01))(x)\n",
        "\n",
        "    s1 = BatchNormalization()(s1)\n",
        "    s1 = Activation(activation='relu')(s1)\n",
        "    s1 = Dropout(0.3)(s1)\n",
        "    main_path = res_block2(main_path,s1, [128, 128], [(2, 2), (1, 1)]) \n",
        "    features_extracted.append(main_path)\n",
        "\n",
        "    main_path = res_block(main_path, [256, 256], [(2, 2), (1, 1)])\n",
        "    features_extracted.append(main_path)\n",
        "\n",
        "    #s2 = Conv2D(filters=512, kernel_size=(1, 1), strides=(4, 4) , kernel_regularizer=l2(0.01) )(to_decoder[1])\n",
        "    s2 = Conv2D(filters=512, kernel_size=(1, 1), strides=(4, 4)  )(features_extracted[1])\n",
        "    s2 = BatchNormalization()(s2)\n",
        "    s2 = Activation(activation='relu')(s2)\n",
        "    s2 = Dropout(0.3)(s2)\n",
        "\n",
        "    main_path = res_block2(main_path,s2, [512, 512], [(2, 2), (1, 1)])\n",
        "    features_extracted.append(main_path)\n",
        "\n",
        "    \n",
        "\n",
        "    return features_extracted\n",
        "    \n",
        "\n",
        "def res2unet(lrate=8.00E-05,pretrained_weights=None):\n",
        "    print(lrate)\n",
        "    input_size=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    inputs = Input(shape=input_size)\n",
        "\n",
        "    features_extracted = encoder(inputs)\n",
        "\n",
        "    path = res_block(features_extracted[-1], [1024, 1024], [(2, 2), (1, 1)])####bridge\n",
        "\n",
        "    # FC layer \n",
        "    x = Flatten()(path)\n",
        "    #x = Dense(units = 1024 , activation = 'relu')(x)\n",
        "    #x = Dropout(0.7)(x)\n",
        "    x = Dense(units = 512 , activation = 'relu' , kernel_regularizer=l2(0.01) )(x)\n",
        "    x = Dropout(0.7)(x)\n",
        "    x = Dense(units = 128 , activation = 'relu' ,  kernel_regularizer=l2(0.01) )(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x=  Dense(units = 64 , activation = 'relu' ,  kernel_regularizer=l2(0.01) )(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "\n",
        "    #path = decoder(path, from_encoder=to_decoder)\n",
        "\n",
        "\n",
        "    #path = Conv2D(2, kernel_size=(3, 3),activation='relu', padding='same', strides=(1, 1))(path)\n",
        "    #path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path)\n",
        "    \n",
        "    # Output layer\n",
        "    output  = Dense(units = 1 , activation = 'sigmoid')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=output )\n",
        "    model.compile(optimizer=Adam(lr=lrate), loss = 'binary_crossentropy', metrics = ['accuracy',precision,recall])\n",
        "    if (pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "    return model\n",
        "    \n",
        "\n",
        "model2 = res2unet(lrate=7.00E-05)\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=5, verbose = 1, mode='min', restore_best_weights = True)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "    monitor = 'val_accuracy', \n",
        "    patience = 3, \n",
        "    verbose = 1, \n",
        "    factor = 0.3, \n",
        "    min_lr = 0.000001\n",
        "    )\n",
        "\n",
        "\n",
        "model_checkpoint1 = keras.callbacks.ModelCheckpoint('Model_Weights2.hdf5', monitor='val_accuracy',verbose=1, mode='max',save_best_only=True)\n",
        "csv_logger = CSVLogger('training_model_metrics_values.log', append=True, separator=';')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "7e-05\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 256, 256, 64) 1792        input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 256, 256, 64) 256         conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 256, 256, 64) 0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 256, 256, 64) 256         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n                                                                 lambda[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 256, 256, 64) 256         add[0][0]                        \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 128, 128, 128 73856       activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 128, 128, 128 512         input_1[0][0]                    \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 128, 128, 128 8320        add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_3[0][0]               \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 128, 128, 128 0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 128, 128, 128 0           conv2d_5[0][0]                   \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 128, 128, 128 0           activation_1[0][0]               \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n                                                                 lambda_1[0][0]                   \n__________________________________________________________________________________________________\naverage (Average)               (None, 128, 128, 128 0           dropout[0][0]                    \n                                                                 add_1[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 128, 128, 128 512         average[0][0]                    \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 64, 64, 256)  295168      activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 64, 64, 256)  33024       average[0][0]                    \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 64, 64, 256)  590080      activation_5[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 64, 64, 256)  1024        conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 64, 64, 256)  0           conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 64, 64, 256)  0           batch_normalization_8[0][0]      \n                                                                 lambda_2[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        add_2[0][0]                      \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 32, 32, 512)  1180160     activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 32, 32, 512)  2048        conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 32, 32, 512)  66048       average[0][0]                    \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 32, 32, 512)  0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 32, 32, 512)  131584      add_2[0][0]                      \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     activation_8[0][0]               \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 32, 512)  0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 32, 32, 512)  0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 32, 32, 512)  0           activation_6[0][0]               \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 32, 32, 512)  0           batch_normalization_12[0][0]     \n                                                                 lambda_3[0][0]                   \n__________________________________________________________________________________________________\naverage_1 (Average)             (None, 32, 32, 512)  0           dropout_1[0][0]                  \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 32, 32, 512)  2048        average_1[0][0]                  \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 32, 32, 512)  0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 16, 16, 1024) 4719616     activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 16, 16, 1024) 4096        conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 16, 16, 1024) 0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 16, 16, 1024) 525312      average_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 16, 16, 1024) 9438208     activation_10[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 16, 16, 1024) 4096        conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nlambda_4 (Lambda)               (None, 16, 16, 1024) 0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 16, 16, 1024) 0           batch_normalization_15[0][0]     \n                                                                 lambda_4[0][0]                   \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 262144)       0           add_4[0][0]                      \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 512)          134218240   flatten[0][0]                    \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 512)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 128)          65664       dropout_2[0][0]                  \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 1)            65          dropout_4[0][0]                  \n==================================================================================================\nTotal params: 153,922,753\nTrainable params: 153,911,617\nNon-trainable params: 11,136\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrsVvDm9CFy5",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:16:32.802150Z",
          "iopub.execute_input": "2021-08-31T20:16:32.802468Z",
          "iopub.status.idle": "2021-08-31T20:43:18.682175Z",
          "shell.execute_reply.started": "2021-08-31T20:16:32.802439Z",
          "shell.execute_reply": "2021-08-31T20:43:18.681251Z"
        },
        "trusted": true,
        "outputId": "9e91c264-dadc-4c3b-b4a4-99bb4219a9c3"
      },
      "source": [
        "# Train\n",
        "\n",
        "history2 = model2.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 30, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger  ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/30\n600/600 [==============================] - 53s 84ms/step - loss: 17.6346 - accuracy: 0.5852 - precision: 0.5702 - recall: 0.5539 - val_loss: 14.9579 - val_accuracy: 0.8000 - val_precision: 0.7133 - val_recall: 0.7133\n\nEpoch 00001: val_accuracy improved from -inf to 0.80000, saving model to Model_Weights2.hdf5\nEpoch 2/30\n600/600 [==============================] - 50s 83ms/step - loss: 21.2585 - accuracy: 0.5926 - precision: 0.5899 - recall: 0.6056 - val_loss: 16.2048 - val_accuracy: 0.8000 - val_precision: 0.7000 - val_recall: 0.6533\n\nEpoch 00002: val_accuracy did not improve from 0.80000\nEpoch 3/30\n600/600 [==============================] - 50s 83ms/step - loss: 22.3722 - accuracy: 0.6277 - precision: 0.6340 - recall: 0.6304 - val_loss: 17.1999 - val_accuracy: 0.8667 - val_precision: 0.7667 - val_recall: 0.7600\n\nEpoch 00003: val_accuracy improved from 0.80000 to 0.86667, saving model to Model_Weights2.hdf5\nEpoch 4/30\n600/600 [==============================] - 50s 84ms/step - loss: 22.2762 - accuracy: 0.6153 - precision: 0.5928 - recall: 0.5685 - val_loss: 17.9327 - val_accuracy: 0.8600 - val_precision: 0.7933 - val_recall: 0.8400\n\nEpoch 00004: val_accuracy did not improve from 0.86667\nEpoch 5/30\n600/600 [==============================] - 50s 83ms/step - loss: 21.1585 - accuracy: 0.6676 - precision: 0.6539 - recall: 0.6535 - val_loss: 18.0719 - val_accuracy: 0.8200 - val_precision: 0.7600 - val_recall: 0.7933\n\nEpoch 00005: val_accuracy did not improve from 0.86667\nEpoch 6/30\n600/600 [==============================] - 50s 83ms/step - loss: 20.7478 - accuracy: 0.6718 - precision: 0.6437 - recall: 0.6333 - val_loss: 17.7956 - val_accuracy: 0.8400 - val_precision: 0.7867 - val_recall: 0.7533\n\nEpoch 00006: val_accuracy did not improve from 0.86667\nEpoch 7/30\n600/600 [==============================] - 50s 83ms/step - loss: 20.4570 - accuracy: 0.6813 - precision: 0.6428 - recall: 0.6194 - val_loss: 18.2824 - val_accuracy: 0.8000 - val_precision: 0.7600 - val_recall: 0.8333\n\nEpoch 00007: val_accuracy did not improve from 0.86667\nEpoch 8/30\n600/600 [==============================] - 50s 83ms/step - loss: 20.4248 - accuracy: 0.6881 - precision: 0.6612 - recall: 0.6504 - val_loss: 17.8697 - val_accuracy: 0.8133 - val_precision: 0.7667 - val_recall: 0.8733\n\nEpoch 00008: val_accuracy did not improve from 0.86667\nEpoch 9/30\n600/600 [==============================] - 50s 83ms/step - loss: 19.2953 - accuracy: 0.7106 - precision: 0.6607 - recall: 0.6761 - val_loss: 16.9444 - val_accuracy: 0.7600 - val_precision: 0.6333 - val_recall: 0.5533\n\nEpoch 00009: val_accuracy did not improve from 0.86667\nEpoch 10/30\n600/600 [==============================] - 50s 83ms/step - loss: 17.9265 - accuracy: 0.7080 - precision: 0.6796 - recall: 0.6690 - val_loss: 15.6798 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8067\n\nEpoch 00010: val_accuracy did not improve from 0.86667\nEpoch 11/30\n600/600 [==============================] - 50s 83ms/step - loss: 16.9086 - accuracy: 0.7214 - precision: 0.6744 - recall: 0.6558 - val_loss: 14.6315 - val_accuracy: 0.8800 - val_precision: 0.7733 - val_recall: 0.7667\n\nEpoch 00011: val_accuracy improved from 0.86667 to 0.88000, saving model to Model_Weights2.hdf5\nEpoch 12/30\n600/600 [==============================] - 50s 83ms/step - loss: 15.8406 - accuracy: 0.7265 - precision: 0.6767 - recall: 0.6742 - val_loss: 13.7355 - val_accuracy: 0.8800 - val_precision: 0.8000 - val_recall: 0.8467\n\nEpoch 00012: val_accuracy did not improve from 0.88000\nEpoch 13/30\n600/600 [==============================] - 50s 83ms/step - loss: 14.5546 - accuracy: 0.7729 - precision: 0.6892 - recall: 0.6827 - val_loss: 12.9272 - val_accuracy: 0.8200 - val_precision: 0.7667 - val_recall: 0.8467\n\nEpoch 00013: val_accuracy did not improve from 0.88000\nEpoch 14/30\n600/600 [==============================] - 50s 83ms/step - loss: 13.4941 - accuracy: 0.7600 - precision: 0.7066 - recall: 0.7024 - val_loss: 12.1013 - val_accuracy: 0.8067 - val_precision: 0.7467 - val_recall: 0.8600\n\nEpoch 00014: val_accuracy did not improve from 0.88000\nEpoch 15/30\n600/600 [==============================] - 50s 83ms/step - loss: 12.3270 - accuracy: 0.8013 - precision: 0.7482 - recall: 0.7231 - val_loss: 11.3043 - val_accuracy: 0.8933 - val_precision: 0.8000 - val_recall: 0.8333\n\nEpoch 00015: val_accuracy improved from 0.88000 to 0.89333, saving model to Model_Weights2.hdf5\nEpoch 16/30\n600/600 [==============================] - 50s 83ms/step - loss: 12.1635 - accuracy: 0.8009 - precision: 0.7509 - recall: 0.7344 - val_loss: 11.0323 - val_accuracy: 0.9067 - val_precision: 0.8133 - val_recall: 0.8067\n\nEpoch 00016: val_accuracy improved from 0.89333 to 0.90667, saving model to Model_Weights2.hdf5\nEpoch 17/30\n600/600 [==============================] - 50s 83ms/step - loss: 12.0365 - accuracy: 0.7677 - precision: 0.7143 - recall: 0.7083 - val_loss: 12.0035 - val_accuracy: 0.8333 - val_precision: 0.7800 - val_recall: 0.7467\n\nEpoch 00017: val_accuracy did not improve from 0.90667\nEpoch 18/30\n600/600 [==============================] - 50s 83ms/step - loss: 11.6646 - accuracy: 0.8194 - precision: 0.7819 - recall: 0.7498 - val_loss: 10.6053 - val_accuracy: 0.8533 - val_precision: 0.7733 - val_recall: 0.7267\n\nEpoch 00018: val_accuracy did not improve from 0.90667\nEpoch 19/30\n600/600 [==============================] - 50s 83ms/step - loss: 10.4589 - accuracy: 0.8163 - precision: 0.7595 - recall: 0.7603 - val_loss: 9.4928 - val_accuracy: 0.9267 - val_precision: 0.8467 - val_recall: 0.8733\n\nEpoch 00019: val_accuracy improved from 0.90667 to 0.92667, saving model to Model_Weights2.hdf5\nEpoch 20/30\n600/600 [==============================] - 50s 83ms/step - loss: 9.6933 - accuracy: 0.8493 - precision: 0.7775 - recall: 0.7703 - val_loss: 8.6987 - val_accuracy: 0.9133 - val_precision: 0.8267 - val_recall: 0.7733\n\nEpoch 00020: val_accuracy did not improve from 0.92667\nEpoch 21/30\n600/600 [==============================] - 50s 83ms/step - loss: 9.0573 - accuracy: 0.8346 - precision: 0.7441 - recall: 0.7379 - val_loss: 8.0199 - val_accuracy: 0.9400 - val_precision: 0.8267 - val_recall: 0.8000\n\nEpoch 00021: val_accuracy improved from 0.92667 to 0.94000, saving model to Model_Weights2.hdf5\nEpoch 22/30\n600/600 [==============================] - 50s 83ms/step - loss: 8.3649 - accuracy: 0.8494 - precision: 0.7531 - recall: 0.7330 - val_loss: 7.5591 - val_accuracy: 0.9133 - val_precision: 0.7867 - val_recall: 0.7467\n\nEpoch 00022: val_accuracy did not improve from 0.94000\nEpoch 23/30\n600/600 [==============================] - 50s 83ms/step - loss: 8.0106 - accuracy: 0.8400 - precision: 0.7994 - recall: 0.7859 - val_loss: 8.4304 - val_accuracy: 0.8733 - val_precision: 0.7867 - val_recall: 0.7267\n\nEpoch 00023: val_accuracy did not improve from 0.94000\nEpoch 24/30\n600/600 [==============================] - 50s 83ms/step - loss: 8.0653 - accuracy: 0.8825 - precision: 0.7994 - recall: 0.7945 - val_loss: 6.9434 - val_accuracy: 0.9200 - val_precision: 0.8267 - val_recall: 0.7867\n\nEpoch 00024: val_accuracy did not improve from 0.94000\nEpoch 25/30\n600/600 [==============================] - 50s 83ms/step - loss: 6.9428 - accuracy: 0.8880 - precision: 0.8180 - recall: 0.8069 - val_loss: 6.3451 - val_accuracy: 0.9733 - val_precision: 0.8800 - val_recall: 0.8800\n\nEpoch 00025: val_accuracy improved from 0.94000 to 0.97333, saving model to Model_Weights2.hdf5\nEpoch 26/30\n600/600 [==============================] - 50s 83ms/step - loss: 6.3468 - accuracy: 0.9105 - precision: 0.8352 - recall: 0.8327 - val_loss: 6.3401 - val_accuracy: 0.9400 - val_precision: 0.8600 - val_recall: 0.8733\n\nEpoch 00026: val_accuracy did not improve from 0.97333\nEpoch 27/30\n600/600 [==============================] - 50s 83ms/step - loss: 6.5084 - accuracy: 0.8958 - precision: 0.7652 - recall: 0.7820 - val_loss: 6.0247 - val_accuracy: 0.8867 - val_precision: 0.8000 - val_recall: 0.8133\n\nEpoch 00027: val_accuracy did not improve from 0.97333\nEpoch 28/30\n600/600 [==============================] - 50s 83ms/step - loss: 6.0655 - accuracy: 0.9054 - precision: 0.8172 - recall: 0.8180 - val_loss: 5.8516 - val_accuracy: 0.9400 - val_precision: 0.8667 - val_recall: 0.8267\n\nEpoch 00028: val_accuracy did not improve from 0.97333\nEpoch 29/30\n600/600 [==============================] - 50s 83ms/step - loss: 5.9999 - accuracy: 0.8942 - precision: 0.7600 - recall: 0.7670 - val_loss: 5.2982 - val_accuracy: 0.9800 - val_precision: 0.8733 - val_recall: 0.8733\n\nEpoch 00029: val_accuracy improved from 0.97333 to 0.98000, saving model to Model_Weights2.hdf5\nEpoch 30/30\n600/600 [==============================] - 50s 83ms/step - loss: 5.0670 - accuracy: 0.9477 - precision: 0.8363 - recall: 0.8360 - val_loss: 4.5355 - val_accuracy: 0.9600 - val_precision: 0.8533 - val_recall: 0.8333\n\nEpoch 00030: val_accuracy did not improve from 0.98000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T21:00:54.329212Z",
          "iopub.execute_input": "2021-08-31T21:00:54.329610Z",
          "iopub.status.idle": "2021-08-31T21:09:37.522371Z",
          "shell.execute_reply.started": "2021-08-31T21:00:54.329575Z",
          "shell.execute_reply": "2021-08-31T21:09:37.521386Z"
        },
        "trusted": true,
        "id": "NpJoorKuIIyF",
        "outputId": "90f265d7-7ac9-4776-fe9e-c395c2ef6637"
      },
      "source": [
        "model2.load_weights(\"./Model_Weights2.hdf5\")\n",
        "history2 = model2.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    batch_size = 2, \n",
        "    epochs = 10, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    callbacks=[ model_checkpoint1 ,csv_logger  ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n600/600 [==============================] - 61s 85ms/step - loss: 3.3257 - accuracy: 0.9267 - precision: 0.8124 - recall: 0.8042 - val_loss: 3.6445 - val_accuracy: 0.9733 - val_precision: 0.8800 - val_recall: 0.8733\n\nEpoch 00001: val_accuracy improved from -inf to 0.97333, saving model to Model_Weights2.hdf5\nEpoch 2/10\n600/600 [==============================] - 50s 83ms/step - loss: 4.2292 - accuracy: 0.8898 - precision: 0.8067 - recall: 0.7996 - val_loss: 4.4232 - val_accuracy: 0.9333 - val_precision: 0.8467 - val_recall: 0.8200\n\nEpoch 00002: val_accuracy did not improve from 0.97333\nEpoch 3/10\n600/600 [==============================] - 50s 83ms/step - loss: 4.2245 - accuracy: 0.9292 - precision: 0.8524 - recall: 0.8517 - val_loss: 3.3039 - val_accuracy: 0.9667 - val_precision: 0.8667 - val_recall: 0.8533\n\nEpoch 00003: val_accuracy did not improve from 0.97333\nEpoch 4/10\n600/600 [==============================] - 50s 83ms/step - loss: 3.1891 - accuracy: 0.9571 - precision: 0.8044 - recall: 0.8078 - val_loss: 2.9942 - val_accuracy: 0.9733 - val_precision: 0.8667 - val_recall: 0.8600\n\nEpoch 00004: val_accuracy did not improve from 0.97333\nEpoch 5/10\n600/600 [==============================] - 50s 83ms/step - loss: 2.9317 - accuracy: 0.9381 - precision: 0.8519 - recall: 0.8470 - val_loss: 2.9179 - val_accuracy: 0.9600 - val_precision: 0.8600 - val_recall: 0.8533\n\nEpoch 00005: val_accuracy did not improve from 0.97333\nEpoch 6/10\n600/600 [==============================] - 50s 84ms/step - loss: 3.0116 - accuracy: 0.9368 - precision: 0.8237 - recall: 0.8275 - val_loss: 4.8264 - val_accuracy: 0.9733 - val_precision: 0.8600 - val_recall: 0.8600\n\nEpoch 00006: val_accuracy did not improve from 0.97333\nEpoch 7/10\n600/600 [==============================] - 50s 83ms/step - loss: 4.4481 - accuracy: 0.9327 - precision: 0.8305 - recall: 0.8292 - val_loss: 3.7210 - val_accuracy: 0.9467 - val_precision: 0.8400 - val_recall: 0.8533\n\nEpoch 00007: val_accuracy did not improve from 0.97333\nEpoch 8/10\n600/600 [==============================] - 50s 83ms/step - loss: 3.7067 - accuracy: 0.9350 - precision: 0.8395 - recall: 0.8448 - val_loss: 2.9197 - val_accuracy: 0.9467 - val_precision: 0.8333 - val_recall: 0.8400\n\nEpoch 00008: val_accuracy did not improve from 0.97333\nEpoch 9/10\n600/600 [==============================] - 50s 83ms/step - loss: 2.7174 - accuracy: 0.9483 - precision: 0.8428 - recall: 0.8508 - val_loss: 2.3708 - val_accuracy: 0.9800 - val_precision: 0.8533 - val_recall: 0.8533\n\nEpoch 00009: val_accuracy improved from 0.97333 to 0.98000, saving model to Model_Weights2.hdf5\nEpoch 10/10\n600/600 [==============================] - 50s 83ms/step - loss: 2.3628 - accuracy: 0.9522 - precision: 0.8352 - recall: 0.8485 - val_loss: 2.4705 - val_accuracy: 0.9467 - val_precision: 0.8467 - val_recall: 0.8400\n\nEpoch 00010: val_accuracy did not improve from 0.98000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEZC7FpnIIyG"
      },
      "source": [
        "### Accuracy of Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T21:11:04.981572Z",
          "iopub.execute_input": "2021-08-31T21:11:04.981977Z",
          "iopub.status.idle": "2021-08-31T21:11:13.939989Z",
          "shell.execute_reply.started": "2021-08-31T21:11:04.981941Z",
          "shell.execute_reply": "2021-08-31T21:11:13.939164Z"
        },
        "trusted": true,
        "id": "zkkBjST1IIyG",
        "outputId": "a3371f34-1512-4a61-b8ab-ab19ac399374"
      },
      "source": [
        "#model2.load_weights(\"./Model_Weights2.hdf5\")\n",
        "\n",
        "print(\"Train_Accuracy\" )\n",
        "train_results = model2.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = model2.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "test_results = model2.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 6s 164ms/step - loss: 2.3459 - accuracy: 0.9817 - precision: 0.9738 - recall: 0.9989\nVal_Accuracy\n5/5 [==============================] - 1s 154ms/step - loss: 2.3708 - accuracy: 0.9800 - precision: 0.9895 - recall: 0.9780\nTest_Accuracy\n5/5 [==============================] - 1s 178ms/step - loss: 2.3758 - accuracy: 0.9667 - precision: 0.9539 - recall: 0.9895\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKwZiiVJIIyH"
      },
      "source": [
        "### Predications by Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T21:11:18.890115Z",
          "iopub.execute_input": "2021-08-31T21:11:18.890493Z",
          "iopub.status.idle": "2021-08-31T21:11:19.775444Z",
          "shell.execute_reply.started": "2021-08-31T21:11:18.890455Z",
          "shell.execute_reply": "2021-08-31T21:11:19.774607Z"
        },
        "trusted": true,
        "id": "nC08K-fbIIyH",
        "outputId": "f156ee7e-60b8-4e18-bf92-4070a4c03aaf"
      },
      "source": [
        "model2_pred = model2.predict(test_images)\n",
        "pred = [1 if x > 0.5 else 0 for x in list(model2_pred[: , 0])]\n",
        "model2_pred = np.array(pred)\n",
        "model2_pred\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T21:13:15.138688Z",
          "iopub.execute_input": "2021-08-31T21:13:15.139127Z",
          "iopub.status.idle": "2021-08-31T21:13:15.406166Z",
          "shell.execute_reply.started": "2021-08-31T21:13:15.139088Z",
          "shell.execute_reply": "2021-08-31T21:13:15.405339Z"
        },
        "trusted": true,
        "id": "XIbjwUTCIIyI",
        "outputId": "4d34967a-233e-47d3-8272-6adbd9738f26"
      },
      "source": [
        "cm = confusion_matrix(model2_pred, test_labels)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxF4aX9jIIyI"
      },
      "source": [
        "### Loss and Accuracy for each Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:31:33.396284Z",
          "iopub.status.idle": "2021-08-31T18:31:33.396872Z"
        },
        "trusted": true,
        "id": "JxHauRfqIIyI"
      },
      "source": [
        "#plot the training and validation loss at each epoch\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:31:33.398147Z",
          "iopub.status.idle": "2021-08-31T18:31:33.398713Z"
        },
        "trusted": true,
        "id": "hNS5uyi8IIyJ"
      },
      "source": [
        "#plot the training and validation loss at each epoch\n",
        "loss = history2.history['accuracy']\n",
        "val_loss = history2.history['val_accuracy']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBgZvjZh7BQr"
      },
      "source": [
        "# ****Model 3****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9gu8PNm7FY5",
        "execution": {
          "iopub.status.busy": "2021-08-31T20:48:52.032677Z",
          "iopub.execute_input": "2021-08-31T20:48:52.033050Z",
          "iopub.status.idle": "2021-08-31T20:48:52.440432Z",
          "shell.execute_reply.started": "2021-08-31T20:48:52.033017Z",
          "shell.execute_reply": "2021-08-31T20:48:52.439513Z"
        },
        "trusted": true,
        "outputId": "ed4cc1de-21fb-46b3-8fe6-59d5135ed31b"
      },
      "source": [
        "def res2unet_SepConv(lrate=8.00E-05,pretrained_weights=None):\n",
        "    print(lrate)\n",
        "    input_size=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    inputs = Input(shape=input_size)\n",
        "\n",
        "    Feature_Extracted = encoder(inputs)\n",
        "\n",
        "    #path = res_block(to_decoder[-1], [1024, 1024], [(2, 2), (1, 1)])####bridge\n",
        "    path = SeparableConv2D(512, (3,3), activation = 'relu', padding = 'same'  )(Feature_Extracted[-1])\n",
        "    path = SeparableConv2D(512, (3,3), activation = 'relu', padding = 'same'  )(path)\n",
        "    path = BatchNormalization()(path)\n",
        "    path = MaxPooling2D(pool_size = (2,2))(path)\n",
        "    #path = Dropout(0.2)(path)\n",
        "\n",
        "\n",
        "    # FC layer \n",
        "    x = Flatten()(path)\n",
        "    \n",
        "    x = Dense(units = 512 , activation = 'relu'  )(x)\n",
        "    x = Dropout(0.7)(x)\n",
        "    x = Dense(units = 128 , activation = 'relu'  )(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x=  Dense(units = 64 , activation = 'relu' )(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    # Output layer\n",
        "    # For dense = 1  or for binary classification, we use activation = \"linear\"\n",
        "    output  = Dense(units = 1 ,kernel_regularizer = tf.keras.regularizers.l2(0.01), activation = 'linear')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=output )\n",
        "    \n",
        "    #model.compile(optimizer=Adam(lr=lrate), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy',precision,recall])\n",
        "    # For SVM as last layer we use Different Loss Function \"squared_hinge\" for multi-class and \"hinge\" loss for binary class \n",
        "    \n",
        "    model.compile(optimizer=Adam(lr=lrate), loss = 'hinge', metrics = ['accuracy',precision,recall])\n",
        "\n",
        "    model.summary()\n",
        "    if (pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "    return model\n",
        "    \n",
        "\n",
        "model3 = res2unet_SepConv(lrate=7.00E-05)\n",
        "#model.compile(optimizer = \"adam\" , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=5, verbose = 1, mode='min', restore_best_weights = True)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "    monitor = 'val_accuracy', \n",
        "    patience = 3, \n",
        "    verbose = 1, \n",
        "    factor = 0.3, \n",
        "    #min_lr = 0.000001\n",
        "    )\n",
        "\n",
        "\n",
        "model_checkpoint1 = keras.callbacks.ModelCheckpoint('Model_Weights3.hdf5', monitor='val_accuracy',verbose=1, mode='max',save_best_only=True)\n",
        "csv_logger = CSVLogger('training_model_metrics_values.log', append=True, separator=';')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "7e-05\nModel: \"model_19\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_13 (InputLayer)           [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_134 (Conv2D)             (None, 256, 256, 64) 1792        input_13[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_132 (BatchN (None, 256, 256, 64) 256         conv2d_134[0][0]                 \n__________________________________________________________________________________________________\nactivation_116 (Activation)     (None, 256, 256, 64) 0           batch_normalization_132[0][0]    \n__________________________________________________________________________________________________\nconv2d_136 (Conv2D)             (None, 256, 256, 64) 256         input_13[0][0]                   \n__________________________________________________________________________________________________\nconv2d_135 (Conv2D)             (None, 256, 256, 64) 36928       activation_116[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_133 (BatchN (None, 256, 256, 64) 256         conv2d_136[0][0]                 \n__________________________________________________________________________________________________\nlambda_10 (Lambda)              (None, 256, 256, 64) 0           conv2d_135[0][0]                 \n__________________________________________________________________________________________________\nadd_22 (Add)                    (None, 256, 256, 64) 0           batch_normalization_133[0][0]    \n                                                                 lambda_10[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_135 (BatchN (None, 256, 256, 64) 256         add_22[0][0]                     \n__________________________________________________________________________________________________\nactivation_118 (Activation)     (None, 256, 256, 64) 0           batch_normalization_135[0][0]    \n__________________________________________________________________________________________________\nconv2d_138 (Conv2D)             (None, 128, 128, 128 73856       activation_118[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_136 (BatchN (None, 128, 128, 128 512         conv2d_138[0][0]                 \n__________________________________________________________________________________________________\nconv2d_137 (Conv2D)             (None, 128, 128, 128 512         input_13[0][0]                   \n__________________________________________________________________________________________________\nactivation_119 (Activation)     (None, 128, 128, 128 0           batch_normalization_136[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_134 (BatchN (None, 128, 128, 128 512         conv2d_137[0][0]                 \n__________________________________________________________________________________________________\nconv2d_140 (Conv2D)             (None, 128, 128, 128 8320        add_22[0][0]                     \n__________________________________________________________________________________________________\nconv2d_139 (Conv2D)             (None, 128, 128, 128 147584      activation_119[0][0]             \n__________________________________________________________________________________________________\nactivation_117 (Activation)     (None, 128, 128, 128 0           batch_normalization_134[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_137 (BatchN (None, 128, 128, 128 512         conv2d_140[0][0]                 \n__________________________________________________________________________________________________\nlambda_11 (Lambda)              (None, 128, 128, 128 0           conv2d_139[0][0]                 \n__________________________________________________________________________________________________\ndropout_30 (Dropout)            (None, 128, 128, 128 0           activation_117[0][0]             \n__________________________________________________________________________________________________\nadd_23 (Add)                    (None, 128, 128, 128 0           batch_normalization_137[0][0]    \n                                                                 lambda_11[0][0]                  \n__________________________________________________________________________________________________\naverage_4 (Average)             (None, 128, 128, 128 0           dropout_30[0][0]                 \n                                                                 add_23[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_138 (BatchN (None, 128, 128, 128 512         average_4[0][0]                  \n__________________________________________________________________________________________________\nactivation_120 (Activation)     (None, 128, 128, 128 0           batch_normalization_138[0][0]    \n__________________________________________________________________________________________________\nconv2d_141 (Conv2D)             (None, 64, 64, 256)  295168      activation_120[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_139 (BatchN (None, 64, 64, 256)  1024        conv2d_141[0][0]                 \n__________________________________________________________________________________________________\nactivation_121 (Activation)     (None, 64, 64, 256)  0           batch_normalization_139[0][0]    \n__________________________________________________________________________________________________\nconv2d_143 (Conv2D)             (None, 64, 64, 256)  33024       average_4[0][0]                  \n__________________________________________________________________________________________________\nconv2d_142 (Conv2D)             (None, 64, 64, 256)  590080      activation_121[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_140 (BatchN (None, 64, 64, 256)  1024        conv2d_143[0][0]                 \n__________________________________________________________________________________________________\nlambda_12 (Lambda)              (None, 64, 64, 256)  0           conv2d_142[0][0]                 \n__________________________________________________________________________________________________\nadd_24 (Add)                    (None, 64, 64, 256)  0           batch_normalization_140[0][0]    \n                                                                 lambda_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_142 (BatchN (None, 64, 64, 256)  1024        add_24[0][0]                     \n__________________________________________________________________________________________________\nactivation_123 (Activation)     (None, 64, 64, 256)  0           batch_normalization_142[0][0]    \n__________________________________________________________________________________________________\nconv2d_145 (Conv2D)             (None, 32, 32, 512)  1180160     activation_123[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_143 (BatchN (None, 32, 32, 512)  2048        conv2d_145[0][0]                 \n__________________________________________________________________________________________________\nconv2d_144 (Conv2D)             (None, 32, 32, 512)  66048       average_4[0][0]                  \n__________________________________________________________________________________________________\nactivation_124 (Activation)     (None, 32, 32, 512)  0           batch_normalization_143[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_141 (BatchN (None, 32, 32, 512)  2048        conv2d_144[0][0]                 \n__________________________________________________________________________________________________\nconv2d_147 (Conv2D)             (None, 32, 32, 512)  131584      add_24[0][0]                     \n__________________________________________________________________________________________________\nconv2d_146 (Conv2D)             (None, 32, 32, 512)  2359808     activation_124[0][0]             \n__________________________________________________________________________________________________\nactivation_122 (Activation)     (None, 32, 32, 512)  0           batch_normalization_141[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_144 (BatchN (None, 32, 32, 512)  2048        conv2d_147[0][0]                 \n__________________________________________________________________________________________________\nlambda_13 (Lambda)              (None, 32, 32, 512)  0           conv2d_146[0][0]                 \n__________________________________________________________________________________________________\ndropout_31 (Dropout)            (None, 32, 32, 512)  0           activation_122[0][0]             \n__________________________________________________________________________________________________\nadd_25 (Add)                    (None, 32, 32, 512)  0           batch_normalization_144[0][0]    \n                                                                 lambda_13[0][0]                  \n__________________________________________________________________________________________________\naverage_5 (Average)             (None, 32, 32, 512)  0           dropout_31[0][0]                 \n                                                                 add_25[0][0]                     \n__________________________________________________________________________________________________\nseparable_conv2d_4 (SeparableCo (None, 32, 32, 512)  267264      average_5[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv2d_5 (SeparableCo (None, 32, 32, 512)  267264      separable_conv2d_4[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_145 (BatchN (None, 32, 32, 512)  2048        separable_conv2d_5[0][0]         \n__________________________________________________________________________________________________\nmax_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0           batch_normalization_145[0][0]    \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 131072)       0           max_pooling2d_7[0][0]            \n__________________________________________________________________________________________________\ndense_32 (Dense)                (None, 512)          67109376    flatten_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_32 (Dropout)            (None, 512)          0           dense_32[0][0]                   \n__________________________________________________________________________________________________\ndense_33 (Dense)                (None, 128)          65664       dropout_32[0][0]                 \n__________________________________________________________________________________________________\ndropout_33 (Dropout)            (None, 128)          0           dense_33[0][0]                   \n__________________________________________________________________________________________________\ndense_34 (Dense)                (None, 64)           8256        dropout_33[0][0]                 \n__________________________________________________________________________________________________\ndropout_34 (Dropout)            (None, 64)           0           dense_34[0][0]                   \n__________________________________________________________________________________________________\ndense_35 (Dense)                (None, 1)            65          dropout_34[0][0]                 \n==================================================================================================\nTotal params: 72,657,089\nTrainable params: 72,650,049\nNon-trainable params: 7,040\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:49:18.436515Z",
          "iopub.execute_input": "2021-08-31T20:49:18.436850Z",
          "iopub.status.idle": "2021-08-31T20:49:22.494912Z",
          "shell.execute_reply.started": "2021-08-31T20:49:18.436819Z",
          "shell.execute_reply": "2021-08-31T20:49:22.494051Z"
        },
        "trusted": true,
        "id": "mU5tungFIIyK",
        "outputId": "c8d17063-7676-4596-dfb2-06d389651b96"
      },
      "source": [
        "model3a =res2unet_SepConv(lrate=8.00E-05,pretrained_weights=\"../input/model3-weights/Model_Weights3.hdf5\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "8e-05\nModel: \"model_20\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_14 (InputLayer)           [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_148 (Conv2D)             (None, 256, 256, 64) 1792        input_14[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_146 (BatchN (None, 256, 256, 64) 256         conv2d_148[0][0]                 \n__________________________________________________________________________________________________\nactivation_125 (Activation)     (None, 256, 256, 64) 0           batch_normalization_146[0][0]    \n__________________________________________________________________________________________________\nconv2d_150 (Conv2D)             (None, 256, 256, 64) 256         input_14[0][0]                   \n__________________________________________________________________________________________________\nconv2d_149 (Conv2D)             (None, 256, 256, 64) 36928       activation_125[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_147 (BatchN (None, 256, 256, 64) 256         conv2d_150[0][0]                 \n__________________________________________________________________________________________________\nlambda_14 (Lambda)              (None, 256, 256, 64) 0           conv2d_149[0][0]                 \n__________________________________________________________________________________________________\nadd_26 (Add)                    (None, 256, 256, 64) 0           batch_normalization_147[0][0]    \n                                                                 lambda_14[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_149 (BatchN (None, 256, 256, 64) 256         add_26[0][0]                     \n__________________________________________________________________________________________________\nactivation_127 (Activation)     (None, 256, 256, 64) 0           batch_normalization_149[0][0]    \n__________________________________________________________________________________________________\nconv2d_152 (Conv2D)             (None, 128, 128, 128 73856       activation_127[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_150 (BatchN (None, 128, 128, 128 512         conv2d_152[0][0]                 \n__________________________________________________________________________________________________\nconv2d_151 (Conv2D)             (None, 128, 128, 128 512         input_14[0][0]                   \n__________________________________________________________________________________________________\nactivation_128 (Activation)     (None, 128, 128, 128 0           batch_normalization_150[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_148 (BatchN (None, 128, 128, 128 512         conv2d_151[0][0]                 \n__________________________________________________________________________________________________\nconv2d_154 (Conv2D)             (None, 128, 128, 128 8320        add_26[0][0]                     \n__________________________________________________________________________________________________\nconv2d_153 (Conv2D)             (None, 128, 128, 128 147584      activation_128[0][0]             \n__________________________________________________________________________________________________\nactivation_126 (Activation)     (None, 128, 128, 128 0           batch_normalization_148[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_151 (BatchN (None, 128, 128, 128 512         conv2d_154[0][0]                 \n__________________________________________________________________________________________________\nlambda_15 (Lambda)              (None, 128, 128, 128 0           conv2d_153[0][0]                 \n__________________________________________________________________________________________________\ndropout_35 (Dropout)            (None, 128, 128, 128 0           activation_126[0][0]             \n__________________________________________________________________________________________________\nadd_27 (Add)                    (None, 128, 128, 128 0           batch_normalization_151[0][0]    \n                                                                 lambda_15[0][0]                  \n__________________________________________________________________________________________________\naverage_6 (Average)             (None, 128, 128, 128 0           dropout_35[0][0]                 \n                                                                 add_27[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_152 (BatchN (None, 128, 128, 128 512         average_6[0][0]                  \n__________________________________________________________________________________________________\nactivation_129 (Activation)     (None, 128, 128, 128 0           batch_normalization_152[0][0]    \n__________________________________________________________________________________________________\nconv2d_155 (Conv2D)             (None, 64, 64, 256)  295168      activation_129[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_153 (BatchN (None, 64, 64, 256)  1024        conv2d_155[0][0]                 \n__________________________________________________________________________________________________\nactivation_130 (Activation)     (None, 64, 64, 256)  0           batch_normalization_153[0][0]    \n__________________________________________________________________________________________________\nconv2d_157 (Conv2D)             (None, 64, 64, 256)  33024       average_6[0][0]                  \n__________________________________________________________________________________________________\nconv2d_156 (Conv2D)             (None, 64, 64, 256)  590080      activation_130[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_154 (BatchN (None, 64, 64, 256)  1024        conv2d_157[0][0]                 \n__________________________________________________________________________________________________\nlambda_16 (Lambda)              (None, 64, 64, 256)  0           conv2d_156[0][0]                 \n__________________________________________________________________________________________________\nadd_28 (Add)                    (None, 64, 64, 256)  0           batch_normalization_154[0][0]    \n                                                                 lambda_16[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_156 (BatchN (None, 64, 64, 256)  1024        add_28[0][0]                     \n__________________________________________________________________________________________________\nactivation_132 (Activation)     (None, 64, 64, 256)  0           batch_normalization_156[0][0]    \n__________________________________________________________________________________________________\nconv2d_159 (Conv2D)             (None, 32, 32, 512)  1180160     activation_132[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_157 (BatchN (None, 32, 32, 512)  2048        conv2d_159[0][0]                 \n__________________________________________________________________________________________________\nconv2d_158 (Conv2D)             (None, 32, 32, 512)  66048       average_6[0][0]                  \n__________________________________________________________________________________________________\nactivation_133 (Activation)     (None, 32, 32, 512)  0           batch_normalization_157[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_155 (BatchN (None, 32, 32, 512)  2048        conv2d_158[0][0]                 \n__________________________________________________________________________________________________\nconv2d_161 (Conv2D)             (None, 32, 32, 512)  131584      add_28[0][0]                     \n__________________________________________________________________________________________________\nconv2d_160 (Conv2D)             (None, 32, 32, 512)  2359808     activation_133[0][0]             \n__________________________________________________________________________________________________\nactivation_131 (Activation)     (None, 32, 32, 512)  0           batch_normalization_155[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_158 (BatchN (None, 32, 32, 512)  2048        conv2d_161[0][0]                 \n__________________________________________________________________________________________________\nlambda_17 (Lambda)              (None, 32, 32, 512)  0           conv2d_160[0][0]                 \n__________________________________________________________________________________________________\ndropout_36 (Dropout)            (None, 32, 32, 512)  0           activation_131[0][0]             \n__________________________________________________________________________________________________\nadd_29 (Add)                    (None, 32, 32, 512)  0           batch_normalization_158[0][0]    \n                                                                 lambda_17[0][0]                  \n__________________________________________________________________________________________________\naverage_7 (Average)             (None, 32, 32, 512)  0           dropout_36[0][0]                 \n                                                                 add_29[0][0]                     \n__________________________________________________________________________________________________\nseparable_conv2d_6 (SeparableCo (None, 32, 32, 512)  267264      average_7[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv2d_7 (SeparableCo (None, 32, 32, 512)  267264      separable_conv2d_6[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_159 (BatchN (None, 32, 32, 512)  2048        separable_conv2d_7[0][0]         \n__________________________________________________________________________________________________\nmax_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 512)  0           batch_normalization_159[0][0]    \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 131072)       0           max_pooling2d_8[0][0]            \n__________________________________________________________________________________________________\ndense_36 (Dense)                (None, 512)          67109376    flatten_4[0][0]                  \n__________________________________________________________________________________________________\ndropout_37 (Dropout)            (None, 512)          0           dense_36[0][0]                   \n__________________________________________________________________________________________________\ndense_37 (Dense)                (None, 128)          65664       dropout_37[0][0]                 \n__________________________________________________________________________________________________\ndropout_38 (Dropout)            (None, 128)          0           dense_37[0][0]                   \n__________________________________________________________________________________________________\ndense_38 (Dense)                (None, 64)           8256        dropout_38[0][0]                 \n__________________________________________________________________________________________________\ndropout_39 (Dropout)            (None, 64)           0           dense_38[0][0]                   \n__________________________________________________________________________________________________\ndense_39 (Dense)                (None, 1)            65          dropout_39[0][0]                 \n==================================================================================================\nTotal params: 72,657,089\nTrainable params: 72,650,049\nNon-trainable params: 7,040\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ltCZhCIIyL"
      },
      "source": [
        "## Accuracy Of Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:49:29.152098Z",
          "iopub.execute_input": "2021-08-31T20:49:29.152496Z",
          "iopub.status.idle": "2021-08-31T20:49:38.283782Z",
          "shell.execute_reply.started": "2021-08-31T20:49:29.152457Z",
          "shell.execute_reply": "2021-08-31T20:49:38.282978Z"
        },
        "trusted": true,
        "id": "XAebp2vRIIyL",
        "outputId": "0fb861fa-e9d5-4c18-d5eb-5b685a587126"
      },
      "source": [
        "\n",
        "print(\"Train_Accuracy\" )\n",
        "train_results = model3a.evaluate(train_images, train_labels)\n",
        "\n",
        "print(\"Val_Accuracy\" )\n",
        "val_results = model3a.evaluate(val_images, val_labels)\n",
        "\n",
        "print(\"Test_Accuracy\" )\n",
        "test_results = model3a.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train_Accuracy\n38/38 [==============================] - 7s 149ms/step - loss: 0.0349 - accuracy: 0.9956 - precision: 0.9936 - recall: 0.9994\nVal_Accuracy\n5/5 [==============================] - 1s 144ms/step - loss: 0.0120 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\nTest_Accuracy\n5/5 [==============================] - 1s 138ms/step - loss: 0.0120 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLhPCvXSIIyM"
      },
      "source": [
        "### Predication of Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:50:20.826961Z",
          "iopub.execute_input": "2021-08-31T20:50:20.827299Z",
          "iopub.status.idle": "2021-08-31T20:50:21.931910Z",
          "shell.execute_reply.started": "2021-08-31T20:50:20.827269Z",
          "shell.execute_reply": "2021-08-31T20:50:21.931088Z"
        },
        "trusted": true,
        "id": "XO9nEjuxIIyN",
        "outputId": "66b80b76-8c02-4a74-f52e-b7e4c1328d38"
      },
      "source": [
        "model3_pred = model3a.predict(test_images)\n",
        "pred = [1 if x > 0.5 else 0 for x in list(model3_pred[: , 0])]\n",
        "model3_pred = np.array(pred)\n",
        "model3_pred\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 117,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:51:15.769726Z",
          "iopub.execute_input": "2021-08-31T20:51:15.770079Z",
          "iopub.status.idle": "2021-08-31T20:51:15.778573Z",
          "shell.execute_reply.started": "2021-08-31T20:51:15.770050Z",
          "shell.execute_reply": "2021-08-31T20:51:15.777576Z"
        },
        "trusted": true,
        "id": "D-3u-NJpIIyS",
        "outputId": "6ad9850d-25a9-4c62-9e75-4744290466d9"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 118,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1], dtype=int32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T20:51:22.234215Z",
          "iopub.execute_input": "2021-08-31T20:51:22.234538Z",
          "iopub.status.idle": "2021-08-31T20:51:22.467614Z",
          "shell.execute_reply.started": "2021-08-31T20:51:22.234506Z",
          "shell.execute_reply": "2021-08-31T20:51:22.466861Z"
        },
        "trusted": true,
        "id": "OkqypnllIIyS",
        "outputId": "5cd96ec3-ba05-469f-c5cc-6ace364d4557"
      },
      "source": [
        "cm = confusion_matrix(model3_pred, test_labels)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 119,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T18:31:33.409750Z",
          "iopub.status.idle": "2021-08-31T18:31:33.410411Z"
        },
        "trusted": true,
        "id": "1C4i7g-_IIyT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eei7uqnMdfmn",
        "trusted": true
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}